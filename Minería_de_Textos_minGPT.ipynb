{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lTgJSTKuzsM"
      },
      "source": [
        "# minGPT\n",
        "\n",
        "**Note:** The `autoreload` extension allows the interpreter to reload modules every time a cell is executed. This is useful when editing the code in a module. The following cell enables the extension and downloads the minGPT package from Github. You can now double-click on a file like model.py, edit its contents, and press Ctrl+S to save it. If you then re-run the notebook cells, including those that create an object of the corresponding class, you will see the changes reflected. Note that the next cell should *only be executed once*, as running `pip install` again will overwrite the modified contents of the module.\n",
        "\n",
        "Recall that changes in the files (except the notebook itself) are not persistent unless you connect them to your Google Drive account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEghw4-QA6oY",
        "outputId": "cbb70c42-df3d-42dd-8df1-43e663f09c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining mingpt from git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26#egg=mingpt\n",
            "  Cloning https://github.com/karpathy/minGPT.git (to revision 37baab71b9abea1b76ab957409a1cc2fbfba8a26) to ./.venv/src/mingpt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/karpathy/minGPT.git /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/src/mingpt\n",
            "  Running command git rev-parse -q --verify 'sha^37baab71b9abea1b76ab957409a1cc2fbfba8a26'\n",
            "  Running command git fetch -q https://github.com/karpathy/minGPT.git 37baab71b9abea1b76ab957409a1cc2fbfba8a26\n",
            "  Resolved https://github.com/karpathy/minGPT.git to commit 37baab71b9abea1b76ab957409a1cc2fbfba8a26\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from mingpt) (2.9.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (4.15.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (2025.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.12/site-packages (from torch->mingpt) (3.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->mingpt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->mingpt) (3.0.3)\n",
            "Building wheels for collected packages: mingpt\n",
            "  Building editable for mingpt (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for mingpt: filename=mingpt-0.0.1-0.editable-py3-none-any.whl size=3597 sha256=a1f8c699c4ffb40066f884608efc6214f047b59949bf9470c470f6d6965d4c0c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b75hez0r/wheels/00/63/d9/a8cbf56faebea087e4c2e61b7041cb6af80e18d658b27c351e\n",
            "Successfully built mingpt\n",
            "Installing collected packages: mingpt\n",
            "  Attempting uninstall: mingpt\n",
            "    Found existing installation: minGPT 0.0.1\n",
            "    Uninstalling minGPT-0.0.1:\n",
            "      Successfully uninstalled minGPT-0.0.1\n",
            "Successfully installed mingpt-0.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%pip install -e 'git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26#egg=mingpt'\n",
        "\n",
        "# Fix this issue: https://github.com/karpathy/minGPT/issues/120\n",
        "#!sed -i '200s/.*/        assert len(keys) == len([k for k in sd if not k.endswith(\".attn.bias\")])/' /content/src/mingpt/mingpt/model.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkm4BPSu17LG"
      },
      "source": [
        "Add module's location to PYTHONPATH, which tells your Python interpreter where to search modules for. The previous `pip install -e` changes the variable in a subshell and the interpreter is therefore not aware of the updated value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26\n",
            "  Using cached mingpt-0.0.1-py3-none-any.whl\n",
            "Collecting torch (from mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting filelock (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached filelock-3.20.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->mingpt@ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26)\n",
            "  Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Using cached torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached filelock-3.20.2-py3-none-any.whl (16 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, mingpt\n",
            "Successfully installed MarkupSafe-3.0.3 filelock-3.20.2 fsspec-2025.12.0 jinja2-3.1.6 mingpt-0.0.1 mpmath-1.3.0 networkx-3.6.1 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 setuptools-80.9.0 sympy-1.14.0 torch-2.9.1 triton-3.5.1 typing-extensions-4.15.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade --force-reinstall \"mingpt @ git+https://github.com/karpathy/minGPT.git@37baab71b9abea1b76ab957409a1cc2fbfba8a26\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SWZ69BeU1v49"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/src/mingpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMaLovlTyIZs",
        "outputId": "a69bba5f-09f9-465d-dcbf-51b30e68a25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.20.2)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Using cached numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
            "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
            "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "Using cached numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "Using cached regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
            "Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, hf-xet, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed certifi-2026.1.4 charset_normalizer-3.4.4 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 numpy-2.4.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 tokenizers-0.22.2 tqdm-4.67.1 transformers-4.57.3 urllib3-2.6.3\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/bin/python\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-otHTa0guzsT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from mingpt.model import GPT\n",
        "from mingpt.utils import set_seed\n",
        "from mingpt.bpe import BPETokenizer\n",
        "set_seed(3407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yyjR2C7BuzsW"
      },
      "outputs": [],
      "source": [
        "use_mingpt = True # use minGPT or huggingface/transformers model?\n",
        "model_type = 'gpt2'\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311,
          "referenced_widgets": [
            "74d877d849d1498fbf87968a79b436d5",
            "d95517340925450d9544a147d0064f8f",
            "795a4f3580c5469f86d0bcb96edc1f13",
            "648a553be0bf49cba777f0eaaac741b2",
            "37af4bb362b94e87b7c128e6966534f9",
            "1209e810b3fc41808b444108a87afca1",
            "3ce2905b2f8e41adbc9eb724aeb2f62a",
            "5cbfa6b49da84ee781492abacea18884",
            "f9bcaec9f9c5467aa6e35316d3296302",
            "0c789b9007024556915b3f9e3cabe35e",
            "f6620c81dc4e4285a332cc40b7655caf",
            "784c12d3beb34f25a3c3387217b9a80a",
            "20ea57fda15f42d18d60048c165cb019",
            "8f25e6d89124473688b788bf69c1bfba",
            "bc9fe7054cc849e0ae9a0d69393de9d2",
            "b858fc0c1caa4872b91ec7638d6dbf68",
            "d0449079fc7a48a3a941c34c7cf2fdc9",
            "9a67d3d3a8744fd881b8a2d5359e78ab",
            "a08a849c10e24dffb645cfe75c4bb66a",
            "efb3d94f64314da6a0e9b3e4d1e123e4",
            "a9d6ce4b456f4b6b872a832ffe858e06",
            "52f6eb03404a425aabda1a87b86afe15",
            "80c335cb65a5408dae9ecd4ec9eda4ba",
            "3ba0334c76344e0a824177d3572e6dd7",
            "eff3788657d8436e96a328e73cab52cc",
            "260906d3854c4ff78c2cda042bae0a2e",
            "aa21a3379eb44eb28a52028cc5a0590b",
            "16ca502911134178a532cda1cf139ca4",
            "ca37e879895f4707bb2e39d9229c65dd",
            "44854839f29f4de08577daf5c4db4c63",
            "5eec0e26428c4034867633d70b4b3915",
            "048b2b328d174740a7f4eb64fd2f8b7f",
            "c033d8e19c084b90bd8a88a3e5bdb5b8"
          ]
        },
        "id": "7zgx5CsVuzsW",
        "outputId": "d82696bb-980b-427b-8dac-d85c19137a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 124.44M\n"
          ]
        }
      ],
      "source": [
        "if use_mingpt:\n",
        "    model = GPT.from_pretrained(model_type)\n",
        "else:\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "    model.config.pad_token_id = model.config.eos_token_id # suppress a warning\n",
        "\n",
        "# ship model to device and set to eval mode\n",
        "model.to(device)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vizgt_f4uzsY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate(prompt='', num_samples=10, steps=20, do_sample=True):\n",
        "\n",
        "    # tokenize the input prompt into integer input sequence\n",
        "    if use_mingpt:\n",
        "        tokenizer = BPETokenizer()\n",
        "        if prompt == '':\n",
        "            # to create unconditional samples...\n",
        "            # manually create a tensor with only the special <|endoftext|> token\n",
        "            # similar to what openai's code does here https://github.com/openai/gpt-2/blob/master/src/generate_unconditional_samples.py\n",
        "            x = torch.tensor([[tokenizer.encoder.encoder['<|endoftext|>']]], dtype=torch.long)\n",
        "        else:\n",
        "            x = tokenizer(prompt).to(device)\n",
        "    else:\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(model_type)\n",
        "        if prompt == '':\n",
        "            # to create unconditional samples...\n",
        "            # huggingface/transformers tokenizer special cases these strings\n",
        "            prompt = '<|endoftext|>'\n",
        "        encoded_input = tokenizer(prompt, return_tensors='pt').to(device)\n",
        "        x = encoded_input['input_ids']\n",
        "\n",
        "    # we'll process all desired num_samples in a batch, so expand out the batch dim\n",
        "    x = x.expand(num_samples, -1)\n",
        "\n",
        "    # forward the model `steps` times to get samples, in a batch\n",
        "    y = model.generate(x, max_new_tokens=steps, do_sample=do_sample, top_k=40)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        out = tokenizer.decode(y[i].cpu().squeeze())\n",
        "        print('-'*80)\n",
        "        print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxpoqSOWuzsZ",
        "outputId": "ee342ba7-57a5-48d5-96da-800bffc3b8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on NASA's Juno mission, will also receive this year's award.\n",
            "\n",
            "While his experience shows that\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on Russia's delegation to the G20 summit, spoke about his work to end climate change in his blog\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the United Nations Security Council who was asked on Monday to take a position on climate change in order to\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the UN climate conference in Paris where he was one of the leading climate advocates, said the decision to\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the panel of the U.N. Climate Change Conference on Nov. 17 (UNCIT),\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on an expedition to the moon,\" Karpathy said in an interview with SPACE.com, referring to\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the committee, said, \"We are not convinced that the planet is as good as it should be\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the NASA Goddard Centre for Astrophysics project and a senior fellow at NASA's Goddard Institute for Space\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the Council of Ministers, has declared that there is no possibility of any major change in the trajectory of\n",
            "--------------------------------------------------------------------------------\n",
            "Andrej Karpathy, the Earth representative on the Energetic System, agrees with his co-organizer and is hopeful the process will prove\n"
          ]
        }
      ],
      "source": [
        "generate(prompt='Andrej Karpathy, the Earth representative on', num_samples=10, steps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting repo_orientation.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile repo_orientation.py\n",
        "\"\"\"\n",
        "What this script does:\n",
        "- Prints where mingpt is installed.\n",
        "- Locates mingpt/model.py.\n",
        "- Extracts/prints the key lines of GPT.forward that matter for the assignment:\n",
        "  embeddings -> transformer blocks -> ln_f -> lm_head -> logits\n",
        "- Provides programmatic checks used by unit tests.\n",
        "\n",
        "This does NOT implement activation caching/patching yet. \n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import inspect\n",
        "import pathlib\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import mingpt\n",
        "import mingpt.model\n",
        "from mingpt.model import GPT\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ForwardLandmarks:\n",
        "    has_tok_emb: bool\n",
        "    has_pos_emb: bool\n",
        "    has_blocks_loop: bool\n",
        "    has_ln_f: bool\n",
        "    has_lm_head: bool\n",
        "\n",
        "\n",
        "def get_paths() -> Dict[str, str]:\n",
        "    pkg_path = pathlib.Path(mingpt.__file__).resolve()\n",
        "    model_path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    return {\n",
        "        \"mingpt.__file__\": str(pkg_path),\n",
        "        \"mingpt.model.__file__\": str(model_path),\n",
        "    }\n",
        "\n",
        "\n",
        "def read_model_source() -> str:\n",
        "    model_path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    return model_path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def attn_bias_fix_present(model_source: str) -> bool:\n",
        "    # Required fix: assert len(keys) == len([k for k in sd if not k.endswith(\".attn.bias\")])\n",
        "    return 'len([k for k in sd if not k.endswith(\".attn.bias\")])' in model_source\n",
        "\n",
        "\n",
        "def forward_source() -> str:\n",
        "    return inspect.getsource(GPT.forward)\n",
        "\n",
        "\n",
        "def find_forward_landmarks(src: str) -> ForwardLandmarks:\n",
        "    has_tok_emb = (\"tok_emb\" in src) and (\"wte\" in src)\n",
        "    has_pos_emb = (\"pos_emb\" in src) and (\"wpe\" in src)\n",
        "\n",
        "    has_blocks_loop = (\n",
        "        re.search(r\"\\bfor\\b\\s+.+\\s+\\bin\\b\\s+.*self\\.transformer\\.h\", src) is not None\n",
        "        or re.search(r\"\\bfor\\b\\s+.+\\s+\\bin\\b\\s+.*self\\.transformer\\['h'\\]\", src) is not None\n",
        "    )\n",
        "\n",
        "    has_ln_f = \"ln_f\" in src\n",
        "    has_lm_head = (\"lm_head\" in src) and (\"logits\" in src)\n",
        "\n",
        "    return ForwardLandmarks(\n",
        "        has_tok_emb=has_tok_emb,\n",
        "        has_pos_emb=has_pos_emb,\n",
        "        has_blocks_loop=has_blocks_loop,\n",
        "        has_ln_f=has_ln_f,\n",
        "        has_lm_head=has_lm_head,\n",
        "    )\n",
        "\n",
        "\n",
        "def print_forward_snippet(src: str, max_lines: int = 80) -> None:\n",
        "    lines = src.splitlines()\n",
        "    print(\"=== GPT.forward (snippet) ===\")\n",
        "    for i, line in enumerate(lines[:max_lines], start=1):\n",
        "        print(f\"{i:03d}: {line}\")\n",
        "    if len(lines) > max_lines:\n",
        "        print(f\"... ({len(lines)-max_lines} more lines)\")\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    paths = get_paths()\n",
        "    print(\"=== Installed paths ===\")\n",
        "    for k, v in paths.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "\n",
        "    model_src = read_model_source()\n",
        "    print(\"\\n=== .attn.bias fix present? ===\")\n",
        "    print(attn_bias_fix_present(model_src))\n",
        "\n",
        "    fwd_src = forward_source()\n",
        "    landmarks = find_forward_landmarks(fwd_src)\n",
        "    print(\"\\n=== Forward pipeline landmarks ===\")\n",
        "    print(landmarks)\n",
        "\n",
        "    print()\n",
        "    print_forward_snippet(fwd_src)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Installed paths ===\n",
            "mingpt.__file__: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/src/mingpt/mingpt/__init__.py\n",
            "mingpt.model.__file__: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/src/mingpt/mingpt/model.py\n",
            "\n",
            "=== .attn.bias fix present? ===\n",
            "True\n",
            "\n",
            "=== Forward pipeline landmarks ===\n",
            "ForwardLandmarks(has_tok_emb=True, has_pos_emb=True, has_blocks_loop=True, has_ln_f=True, has_lm_head=True)\n",
            "\n",
            "=== GPT.forward (snippet) ===\n",
            "001:     def forward(self, idx, targets=None):\n",
            "002:         device = idx.device\n",
            "003:         b, t = idx.size()\n",
            "004:         assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.block_size}\"\n",
            "005:         pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
            "006: \n",
            "007:         # forward the GPT model itself\n",
            "008:         tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
            "009:         pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
            "010:         x = self.transformer.drop(tok_emb + pos_emb)\n",
            "011:         for block in self.transformer.h:\n",
            "012:             x = block(x)\n",
            "013:         x = self.transformer.ln_f(x)\n",
            "014:         logits = self.lm_head(x)\n",
            "015: \n",
            "016:         # if we are given some desired targets also calculate the loss\n",
            "017:         loss = None\n",
            "018:         if targets is not None:\n",
            "019:             loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
            "020: \n",
            "021:         return logits, loss\n"
          ]
        }
      ],
      "source": [
        "!python repo_orientation.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting generate_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile generate_driver.py\n",
        "\"\"\"\n",
        "Right now this only:\n",
        "- loads GPT-2 small via GPT.from_pretrained('gpt2')\n",
        "- tokenizes a prompt with BPETokenizer\n",
        "- runs a single forward pass to confirm logits shape\n",
        "- runs model.generate to confirm decoding loop works\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    set_seed(3407)\n",
        "\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    bpe = BPETokenizer()\n",
        "    prompt = \"Andrej Karpathy, the Earth representative on\"\n",
        "    idx = bpe(prompt).to(device)  # shape (1, T)\n",
        "\n",
        "    # forward pass (logits for each position)\n",
        "    logits, loss = model(idx)\n",
        "    print(\"Input shape:\", tuple(idx.shape))\n",
        "    print(\"Logits shape:\", tuple(logits.shape))\n",
        "    assert logits.ndim == 3, \"Expected (B, T, V) logits\"\n",
        "    assert logits.shape[0] == idx.shape[0] and logits.shape[1] == idx.shape[1], \"B,T must match input\"\n",
        "\n",
        "    # generate a short continuation (just to prove decoding loop works)\n",
        "    out_idx = model.generate(idx, max_new_tokens=20, do_sample=True, top_k=40)\n",
        "    out_text = bpe.decode(out_idx[0].cpu())\n",
        "    print(\"\\n=== Generated ===\")\n",
        "    print(out_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "Input shape: (1, 10)\n",
            "Logits shape: (1, 10, 50257)\n",
            "\n",
            "=== Generated ===\n",
            "Andrej Karpathy, the Earth representative on NASA's Mars Exploration Rover Curiosity, talks about the success of the science rover Curiosity, which now has\n"
          ]
        }
      ],
      "source": [
        "!python generate_driver.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_2.py\n",
        "import os\n",
        "import pathlib\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "import mingpt\n",
        "import mingpt.model\n",
        "from mingpt.model import GPT\n",
        "\n",
        "import repo_orientation as ro\n",
        "\n",
        "\n",
        "def test_mingpt_importable_and_paths_exist():\n",
        "    paths = ro.get_paths()\n",
        "    assert \"mingpt.__file__\" in paths and \"mingpt.model.__file__\" in paths\n",
        "\n",
        "    pkg_path = pathlib.Path(paths[\"mingpt.__file__\"])\n",
        "    model_path = pathlib.Path(paths[\"mingpt.model.__file__\"])\n",
        "    assert pkg_path.exists(), f\"mingpt package file not found: {pkg_path}\"\n",
        "    assert model_path.exists(), f\"mingpt.model file not found: {model_path}\"\n",
        "\n",
        "\n",
        "def test_attn_bias_fix_present_or_applied():\n",
        "    src = ro.read_model_source()\n",
        "    assert ro.attn_bias_fix_present(src), (\n",
        "        \"Required fix not found in mingpt/model.py. \"\n",
        "        \"Expected assert to ignore keys ending with .attn.bias.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def test_forward_pipeline_landmarks_present():\n",
        "    fwd_src = ro.forward_source()\n",
        "    lm = ro.find_forward_landmarks(fwd_src)\n",
        "    assert lm.has_tok_emb, \"Expected token embedding (wte/tok_emb) usage in forward.\"\n",
        "    assert lm.has_pos_emb, \"Expected positional embedding (wpe/pos_emb) usage in forward.\"\n",
        "    assert lm.has_blocks_loop, \"Expected loop over transformer blocks in forward.\"\n",
        "    assert lm.has_ln_f, \"Expected final layer norm ln_f in forward.\"\n",
        "    assert lm.has_lm_head, \"Expected lm_head/logits in forward.\"\n",
        "\n",
        "\n",
        "def test_fast_forward_and_generate_from_scratch():\n",
        "    # Fast test: avoid downloading HF weights.\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"  # tiny\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "    assert logits.shape == (1, 10, cfg.vocab_size)\n",
        "    assert loss is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(idx, max_new_tokens=5, do_sample=False)\n",
        "    assert out.shape[1] == 15\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_slow_from_pretrained_gpt2_loads_and_runs():\n",
        "    # Slow test: tries to download and load GPT-2 weights.\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    try:\n",
        "        model = GPT.from_pretrained(\"gpt2\")\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping from_pretrained test due to load/download error: {e}\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, 50257, (1, 8), dtype=torch.long, device=device)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "\n",
        "    assert logits.shape == (1, 8, 50257)\n",
        "    assert loss is None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting pytest.ini\n"
          ]
        }
      ],
      "source": [
        "%%writefile pytest.ini\n",
        "[pytest]\n",
        "markers =\n",
        "    slow: marks tests as slow (deselect with '-m \"not slow\"')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting tokenization_protocol.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tokenization_protocol.py\n",
        "\"\"\"\n",
        "Tokenization Protocol and \"Same Number of Tokens\" Guarantee.\n",
        "\n",
        "This module provides:\n",
        "- Tokenization reports (token ids, per-token decoded strings, token count)\n",
        "- Pair comparison (same-length check, diff positions, one-token-diff check)\n",
        "- Report-friendly Markdown export for token-by-token decomposition\n",
        "- Heuristic suggestions to fix token length mismatches\n",
        "\n",
        "Designed for minGPT's BPETokenizer (mingpt/bpe.py).\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Sequence, Tuple, Dict\n",
        "\n",
        "import torch\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "\n",
        "# Data structures\n",
        "@dataclass(frozen=True)\n",
        "class TokenizationReport:\n",
        "    text: str\n",
        "    token_ids: List[int]\n",
        "    token_strs: List[str]  # decoded per-token strings (may include leading spaces)\n",
        "    seq_len: int\n",
        "    decoded_roundtrip: str\n",
        "\n",
        "    def short_preview(self, max_chars: int = 120) -> str:\n",
        "        s = self.text.replace(\"\\n\", \"\\\\n\")\n",
        "        return s if len(s) <= max_chars else s[: max_chars - 3] + \"...\"\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class PairComparison:\n",
        "    clean: TokenizationReport\n",
        "    corrupt: TokenizationReport\n",
        "    same_length: bool\n",
        "    diff_positions: List[int]\n",
        "    diff_count: int\n",
        "\n",
        "    @property\n",
        "    def one_token_diff(self) -> bool:\n",
        "        return self.same_length and self.diff_count == 1\n",
        "\n",
        "\n",
        "# Core tokenization helpers\n",
        "def tokenize_2d(bpe: BPETokenizer, text: str, device: Optional[str] = None) -> torch.LongTensor:\n",
        "    \"\"\"\n",
        "    Returns token ids as a 2D tensor of shape (1, T) as BPETokenizer does.\n",
        "    \"\"\"\n",
        "    ids_2d = bpe(text)  # (1, T)\n",
        "    if device is not None:\n",
        "        ids_2d = ids_2d.to(device)\n",
        "    return ids_2d\n",
        "\n",
        "\n",
        "def tokenize_1d_ids(bpe: BPETokenizer, text: str) -> List[int]:\n",
        "    \"\"\"\n",
        "    Returns token ids as a python list[int] (1D).\n",
        "    \"\"\"\n",
        "    ids = bpe(text)[0].tolist()\n",
        "    return [int(x) for x in ids]\n",
        "\n",
        "\n",
        "def decode_token_id(bpe: BPETokenizer, token_id: int) -> str:\n",
        "    \"\"\"\n",
        "    Decode a single token id into its string form.\n",
        "    \"\"\"\n",
        "    t = torch.tensor([token_id], dtype=torch.long)\n",
        "    return bpe.decode(t)\n",
        "\n",
        "\n",
        "def decode_tokens_1d(bpe: BPETokenizer, token_ids: Sequence[int]) -> str:\n",
        "    \"\"\"\n",
        "    Decode a sequence of token ids back into a string.\n",
        "    \"\"\"\n",
        "    t = torch.tensor(list(token_ids), dtype=torch.long)\n",
        "    return bpe.decode(t)\n",
        "\n",
        "\n",
        "def per_token_strings(bpe: BPETokenizer, token_ids: Sequence[int]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Per-token decoded strings (important for inspecting leading spaces).\n",
        "    \"\"\"\n",
        "    return [decode_token_id(bpe, int(tid)) for tid in token_ids]\n",
        "\n",
        "\n",
        "def build_report(bpe: BPETokenizer, text: str) -> TokenizationReport:\n",
        "    \"\"\"\n",
        "    Build a complete tokenization report for one text.\n",
        "    \"\"\"\n",
        "    token_ids = tokenize_1d_ids(bpe, text)\n",
        "    token_strs = per_token_strings(bpe, token_ids)\n",
        "    decoded = decode_tokens_1d(bpe, token_ids)\n",
        "    return TokenizationReport(\n",
        "        text=text,\n",
        "        token_ids=token_ids,\n",
        "        token_strs=token_strs,\n",
        "        seq_len=len(token_ids),\n",
        "        decoded_roundtrip=decoded,\n",
        "    )\n",
        "\n",
        "\n",
        "# Comparison and validations\n",
        "def diff_positions(a: Sequence[int], b: Sequence[int]) -> List[int]:\n",
        "    \"\"\"\n",
        "    Returns a list of positions where sequences differ.\n",
        "    If lengths differ, extra positions beyond min length are included as diffs.\n",
        "    \"\"\"\n",
        "    la, lb = len(a), len(b)\n",
        "    m = min(la, lb)\n",
        "    diffs = [i for i in range(m) if int(a[i]) != int(b[i])]\n",
        "    if la != lb:\n",
        "        diffs.extend(list(range(m, max(la, lb))))\n",
        "    return diffs\n",
        "\n",
        "\n",
        "def compare_clean_corrupt(clean: TokenizationReport, corrupt: TokenizationReport) -> PairComparison:\n",
        "    diffs = diff_positions(clean.token_ids, corrupt.token_ids)\n",
        "    same_len = (clean.seq_len == corrupt.seq_len)\n",
        "    return PairComparison(\n",
        "        clean=clean,\n",
        "        corrupt=corrupt,\n",
        "        same_length=same_len,\n",
        "        diff_positions=diffs,\n",
        "        diff_count=len(diffs),\n",
        "    )\n",
        "\n",
        "\n",
        "def assert_same_length(clean: TokenizationReport, corrupt: TokenizationReport) -> None:\n",
        "    if clean.seq_len != corrupt.seq_len:\n",
        "        raise ValueError(\n",
        "            f\"Token length mismatch: clean={clean.seq_len}, corrupt={corrupt.seq_len}.\\n\"\n",
        "            f\"Clean preview: {clean.short_preview()}\\n\"\n",
        "            f\"Corrupt preview: {corrupt.short_preview()}\"\n",
        "        )\n",
        "\n",
        "\n",
        "def assert_one_token_difference(comp: PairComparison) -> None:\n",
        "    if not comp.same_length:\n",
        "        raise ValueError(\n",
        "            f\"Cannot check one-token-diff: lengths differ (clean={comp.clean.seq_len}, corrupt={comp.corrupt.seq_len}).\"\n",
        "        )\n",
        "    if comp.diff_count != 1:\n",
        "        raise ValueError(\n",
        "            f\"Expected exactly 1 differing token position, found {comp.diff_count}: {comp.diff_positions}\\n\"\n",
        "            f\"Tip: inspect the per-token strings and adjust the text until only one BPE token changes.\"\n",
        "        )\n",
        "\n",
        "\n",
        "def validate_pair(\n",
        "    bpe: BPETokenizer,\n",
        "    clean_text: str,\n",
        "    corrupt_text: str,\n",
        "    require_same_length: bool = True,\n",
        "    require_one_token_diff: bool = True,\n",
        ") -> PairComparison:\n",
        "    \"\"\"\n",
        "    Tokenize both texts, compare, and (optionally) enforce constraints by raising errors.\n",
        "    \"\"\"\n",
        "    clean = build_report(bpe, clean_text)\n",
        "    corrupt = build_report(bpe, corrupt_text)\n",
        "    comp = compare_clean_corrupt(clean, corrupt)\n",
        "\n",
        "    if require_same_length:\n",
        "        assert_same_length(clean, corrupt)\n",
        "    if require_one_token_diff:\n",
        "        assert_one_token_difference(comp)\n",
        "    return comp\n",
        "\n",
        "\n",
        "def format_token_list_for_console(rep: TokenizationReport) -> str:\n",
        "    \"\"\"\n",
        "    Console-friendly token list.\n",
        "    Shows position, token_id, and repr(token_str) to make spaces visible.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    for i, (tid, s) in enumerate(zip(rep.token_ids, rep.token_strs)):\n",
        "        lines.append(f\"{i:02d} | {tid:5d} | {repr(s)}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def format_pair_diff_markdown(comp: PairComparison) -> str:\n",
        "    \"\"\"\n",
        "    Markdown table: position-wise clean vs corrupt tokens.\n",
        "    Great for pasting into the report.\n",
        "    \"\"\"\n",
        "    clean = comp.clean\n",
        "    corrupt = comp.corrupt\n",
        "    max_len = max(clean.seq_len, corrupt.seq_len)\n",
        "\n",
        "    header = \"| pos | clean_id | clean_tok | corrupt_id | corrupt_tok | diff? |\\n|---:|---:|---|---:|---|:---:|\\n\"\n",
        "    rows = []\n",
        "    for i in range(max_len):\n",
        "        c_id = clean.token_ids[i] if i < clean.seq_len else None\n",
        "        k_id = corrupt.token_ids[i] if i < corrupt.seq_len else None\n",
        "        c_tok = clean.token_strs[i] if i < clean.seq_len else \"\"\n",
        "        k_tok = corrupt.token_strs[i] if i < corrupt.seq_len else \"\"\n",
        "        diff = \"\" if i in comp.diff_positions else \"\"\n",
        "        rows.append(\n",
        "            f\"| {i} | {'' if c_id is None else c_id} | {repr(c_tok)} | {'' if k_id is None else k_id} | {repr(k_tok)} | {diff} |\"\n",
        "        )\n",
        "    return header + \"\\n\".join(rows) + \"\\n\"\n",
        "\n",
        "\n",
        "def describe_pair(comp: PairComparison) -> str:\n",
        "    \"\"\"\n",
        "    Human-readable summary.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        \"=== Pair summary ===\\n\"\n",
        "        f\"Clean tokens:   {comp.clean.seq_len}\\n\"\n",
        "        f\"Corrupt tokens: {comp.corrupt.seq_len}\\n\"\n",
        "        f\"Same length?    {comp.same_length}\\n\"\n",
        "        f\"Diff count:     {comp.diff_count}\\n\"\n",
        "        f\"Diff positions: {comp.diff_positions}\\n\"\n",
        "        f\"One-token diff? {comp.one_token_diff}\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "def suggest_fixes(clean: TokenizationReport, corrupt: TokenizationReport) -> List[str]:\n",
        "    \"\"\"\n",
        "    Heuristics to help the user fix length mismatches / multi-token mismatches.\n",
        "    Not an automatic fixer; it gives actionable suggestions.\n",
        "    \"\"\"\n",
        "    suggestions: List[str] = []\n",
        "\n",
        "    if clean.seq_len != corrupt.seq_len:\n",
        "        suggestions.append(\n",
        "            \"Token length mismatch detected. Common causes: whitespace differences, punctuation attachment, \"\n",
        "            \"or swapping a word that tokenizes into a different number of BPE tokens.\"\n",
        "        )\n",
        "        suggestions.append(\n",
        "            \"Try keeping punctuation identical (e.g., 'student.' vs 'student .') and keep spaces consistent around the changed word.\"\n",
        "        )\n",
        "        suggestions.append(\n",
        "            \"Proper nouns are often unstable: try swapping to a more common single-token alternative and re-check.\"\n",
        "        )\n",
        "\n",
        "    diffs = diff_positions(clean.token_ids, corrupt.token_ids)\n",
        "    if clean.seq_len == corrupt.seq_len and len(diffs) != 1:\n",
        "        suggestions.append(\n",
        "            f\"More than one token differs ({len(diffs)}). You want exactly 1 differing BPE token position.\"\n",
        "        )\n",
        "        suggestions.append(\n",
        "            \"Inspect per-token strings around the diff positions; often a punctuation or whitespace token is also changing.\"\n",
        "        )\n",
        "\n",
        "    suggestions.append(\n",
        "        \"Remember GPT-2 BPE: tokens in the middle often include a leading space. \"\n",
        "        \"If you care about the token 'Jones', the actual token is usually ' Jones'.\"\n",
        "    )\n",
        "\n",
        "    return suggestions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting tokenization_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile tokenization_driver.py\n",
        "\"\"\"\n",
        "Tokenize clean/corrupt prompts, enforce same-length and one-token-diff,\n",
        "print per-token decomposition, and export a Markdown token table for the report.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "import tokenization_protocol as tp\n",
        "\n",
        "CLEAN_TEXT = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--clean\", type=str, default=CLEAN_TEXT, help=\"Clean prompt text\")\n",
        "    p.add_argument(\"--corrupt\", type=str, default=CORRUPT_TEXT, help=\"Corrupted prompt text\")\n",
        "    p.add_argument(\"--no-require-one-diff\", action=\"store_true\", help=\"Do not require exactly 1 token difference\")\n",
        "    p.add_argument(\"--out_md\", type=str, default=\"token_table.md\", help=\"Output markdown file for token table\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    args = parse_args()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    clean_rep = tp.build_report(bpe, args.clean)\n",
        "    corrupt_rep = tp.build_report(bpe, args.corrupt)\n",
        "    comp = tp.compare_clean_corrupt(clean_rep, corrupt_rep)\n",
        "\n",
        "    print(tp.describe_pair(comp))\n",
        "\n",
        "    print(\"=== Clean prompt ===\")\n",
        "    print(clean_rep.text)\n",
        "    print(\"\\n=== Clean tokens (pos | id | repr(token)) ===\")\n",
        "    print(tp.format_token_list_for_console(clean_rep))\n",
        "\n",
        "    print(\"\\n=== Corrupt prompt ===\")\n",
        "    print(corrupt_rep.text)\n",
        "    print(\"\\n=== Corrupt tokens (pos | id | repr(token)) ===\")\n",
        "    print(tp.format_token_list_for_console(corrupt_rep))\n",
        "\n",
        "    require_one = not args.no_require_one_diff\n",
        "    try:\n",
        "        _ = tp.validate_pair(\n",
        "            bpe=bpe,\n",
        "            clean_text=args.clean,\n",
        "            corrupt_text=args.corrupt,\n",
        "            require_same_length=True,\n",
        "            require_one_token_diff=require_one,\n",
        "        )\n",
        "        print(\"\\n Validation passed.\")\n",
        "    except Exception as e:\n",
        "        print(\"\\n Validation failed:\")\n",
        "        print(e)\n",
        "        print(\"\\nSuggestions:\")\n",
        "        for s in tp.suggest_fixes(clean_rep, corrupt_rep):\n",
        "            print(\"-\", s)\n",
        "\n",
        "    md = tp.format_pair_diff_markdown(comp)\n",
        "    out_path = Path(args.out_md)\n",
        "    out_path.write_text(md, encoding=\"utf-8\")\n",
        "    print(f\"\\nWrote Markdown token table to: {out_path.resolve()}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Pair summary ===\n",
            "Clean tokens:   11\n",
            "Corrupt tokens: 11\n",
            "Same length?    True\n",
            "Diff count:     1\n",
            "Diff positions: [1]\n",
            "One-token diff? True\n",
            "\n",
            "=== Clean prompt ===\n",
            "Michelle Jones was a top-notch student. Michelle\n",
            "\n",
            "=== Clean tokens (pos | id | repr(token)) ===\n",
            "00 | 48736 | 'Michelle'\n",
            "01 |  5437 | ' Jones'\n",
            "02 |   373 | ' was'\n",
            "03 |   257 | ' a'\n",
            "04 |  1353 | ' top'\n",
            "05 |    12 | '-'\n",
            "06 |  1662 | 'not'\n",
            "07 |   354 | 'ch'\n",
            "08 |  3710 | ' student'\n",
            "09 |    13 | '.'\n",
            "10 | 16738 | ' Michelle'\n",
            "\n",
            "=== Corrupt prompt ===\n",
            "Michelle Smith was a top-notch student. Michelle\n",
            "\n",
            "=== Corrupt tokens (pos | id | repr(token)) ===\n",
            "00 | 48736 | 'Michelle'\n",
            "01 |  4176 | ' Smith'\n",
            "02 |   373 | ' was'\n",
            "03 |   257 | ' a'\n",
            "04 |  1353 | ' top'\n",
            "05 |    12 | '-'\n",
            "06 |  1662 | 'not'\n",
            "07 |   354 | 'ch'\n",
            "08 |  3710 | ' student'\n",
            "09 |    13 | '.'\n",
            "10 | 16738 | ' Michelle'\n",
            "\n",
            " Validation passed.\n",
            "\n",
            "Wrote Markdown token table to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/token_table.md\n"
          ]
        }
      ],
      "source": [
        "!python tokenization_driver.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| pos | clean_id | clean_tok | corrupt_id | corrupt_tok | diff? |\n",
            "|---:|---:|---|---:|---|:---:|\n",
            "| 0 | 48736 | 'Michelle' | 48736 | 'Michelle' |  |\n",
            "| 1 | 5437 | ' Jones' | 4176 | ' Smith' |  |\n",
            "| 2 | 373 | ' was' | 373 | ' was' |  |\n",
            "| 3 | 257 | ' a' | 257 | ' a' |  |\n",
            "| 4 | 1353 | ' top' | 1353 | ' top' |  |\n",
            "| 5 | 12 | '-' | 12 | '-' |  |\n",
            "| 6 | 1662 | 'not' | 1662 | 'not' |  |\n",
            "| 7 | 354 | 'ch' | 354 | 'ch' |  |\n",
            "| 8 | 3710 | ' student' | 3710 | ' student' |  |\n",
            "| 9 | 13 | '.' | 13 | '.' |  |\n",
            "| 10 | 16738 | ' Michelle' | 16738 | ' Michelle' |  |\n"
          ]
        }
      ],
      "source": [
        "!sed -n '1,120p' token_table.md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_3.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_3.py\n",
        "import pathlib\n",
        "import sys\n",
        "\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "COLAB_MINGPT_PATH = pathlib.Path(\"/content/src/mingpt\")\n",
        "if COLAB_MINGPT_PATH.exists():\n",
        "    sys.path.append(str(COLAB_MINGPT_PATH))\n",
        "\n",
        "import mingpt\n",
        "import mingpt.model\n",
        "from mingpt.model import GPT\n",
        "\n",
        "import repo_orientation as ro\n",
        "import tokenization_protocol as tp\n",
        "\n",
        "def test_mingpt_importable_and_paths_exist():\n",
        "    paths = ro.get_paths()\n",
        "    assert \"mingpt.__file__\" in paths and \"mingpt.model.__file__\" in paths\n",
        "\n",
        "    pkg_path = pathlib.Path(paths[\"mingpt.__file__\"])\n",
        "    model_path = pathlib.Path(paths[\"mingpt.model.__file__\"])\n",
        "    assert pkg_path.exists(), f\"mingpt package file not found: {pkg_path}\"\n",
        "    assert model_path.exists(), f\"mingpt.model file not found: {model_path}\"\n",
        "\n",
        "\n",
        "def test_attn_bias_fix_present_or_applied():\n",
        "    src = ro.read_model_source()\n",
        "    assert ro.attn_bias_fix_present(src), (\n",
        "        \"Required fix not found in mingpt/model.py. \"\n",
        "        \"Expected assert to ignore keys ending with .attn.bias.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def test_forward_pipeline_landmarks_present():\n",
        "    fwd_src = ro.forward_source()\n",
        "    lm = ro.find_forward_landmarks(fwd_src)\n",
        "    assert lm.has_tok_emb, \"Expected token embedding (wte/tok_emb) usage in forward.\"\n",
        "    assert lm.has_pos_emb, \"Expected positional embedding (wpe/pos_emb) usage in forward.\"\n",
        "    assert lm.has_blocks_loop, \"Expected loop over transformer blocks in forward.\"\n",
        "    assert lm.has_ln_f, \"Expected final layer norm ln_f in forward.\"\n",
        "    assert lm.has_lm_head, \"Expected lm_head/logits in forward.\"\n",
        "\n",
        "\n",
        "def test_fast_forward_and_generate_from_scratch():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"  # tiny\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "    assert logits.shape == (1, 10, cfg.vocab_size)\n",
        "    assert loss is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(idx, max_new_tokens=5, do_sample=False)\n",
        "    assert out.shape[1] == 15\n",
        "\n",
        "\n",
        "def test_diff_positions_length_mismatch_includes_tail():\n",
        "    a = [1, 2, 3]\n",
        "    b = [1, 2, 3, 4, 5]\n",
        "    diffs = tp.diff_positions(a, b)\n",
        "    assert diffs == [3, 4]\n",
        "\n",
        "\n",
        "def test_compare_reports_detects_one_token_diff_synthetic():\n",
        "    clean = tp.TokenizationReport(\n",
        "        text=\"clean\",\n",
        "        token_ids=[10, 20, 30],\n",
        "        token_strs=[\"a\", \"b\", \"c\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"abc\",\n",
        "    )\n",
        "    corrupt = tp.TokenizationReport(\n",
        "        text=\"corrupt\",\n",
        "        token_ids=[10, 99, 30],\n",
        "        token_strs=[\"a\", \"X\", \"c\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"aXc\",\n",
        "    )\n",
        "    comp = tp.compare_clean_corrupt(clean, corrupt)\n",
        "    assert comp.same_length is True\n",
        "    assert comp.diff_positions == [1]\n",
        "    assert comp.diff_count == 1\n",
        "    assert comp.one_token_diff is True\n",
        "\n",
        "\n",
        "def test_assert_one_token_difference_raises_when_multi_diff():\n",
        "    clean = tp.TokenizationReport(\n",
        "        text=\"clean\",\n",
        "        token_ids=[1, 2, 3],\n",
        "        token_strs=[\"a\", \"b\", \"c\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"abc\",\n",
        "    )\n",
        "    corrupt = tp.TokenizationReport(\n",
        "        text=\"corrupt\",\n",
        "        token_ids=[9, 2, 8],\n",
        "        token_strs=[\"X\", \"b\", \"Y\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"XbY\",\n",
        "    )\n",
        "    comp = tp.compare_clean_corrupt(clean, corrupt)\n",
        "    assert comp.diff_count == 2\n",
        "    with pytest.raises(ValueError):\n",
        "        tp.assert_one_token_difference(comp)\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_bpe_tokenization_roundtrip_and_lengths():\n",
        "    \"\"\"\n",
        "    Slow-ish test because BPETokenizer may download merges/vocab on first use in a fresh runtime.\n",
        "    \"\"\"\n",
        "    from mingpt.bpe import BPETokenizer\n",
        "\n",
        "    try:\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping BPETokenizer test due to tokenizer init/download error: {e}\")\n",
        "\n",
        "    text = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    rep = tp.build_report(bpe, text)\n",
        "\n",
        "    assert rep.seq_len > 0\n",
        "    assert len(rep.token_ids) == rep.seq_len\n",
        "    assert len(rep.token_strs) == rep.seq_len\n",
        "\n",
        "    assert \"Michelle\" in rep.decoded_roundtrip\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_bpe_pair_validation_example_michelle_jones_smith():\n",
        "    \"\"\"\n",
        "    Uses the assignment's canonical-style example to ensure:\n",
        "    - same token length\n",
        "    - ideally a one-token difference (it usually is, but tokenizer quirks can vary)\n",
        "    \"\"\"\n",
        "    from mingpt.bpe import BPETokenizer\n",
        "\n",
        "    try:\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping BPETokenizer test due to tokenizer init/download error: {e}\")\n",
        "\n",
        "    clean = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    corrupt = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "    clean_rep = tp.build_report(bpe, clean)\n",
        "    corrupt_rep = tp.build_report(bpe, corrupt)\n",
        "    comp = tp.compare_clean_corrupt(clean_rep, corrupt_rep)\n",
        "\n",
        "    assert comp.same_length is True, f\"Expected same token length; got {clean_rep.seq_len} vs {corrupt_rep.seq_len}\"\n",
        "\n",
        "    assert comp.diff_count >= 1\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_slow_from_pretrained_gpt2_loads_and_runs():\n",
        "    \"\"\"\n",
        "    Slow test: downloads and loads GPT-2 weights.\n",
        "    If network/cache issues happen in Colab, we skip rather than fail hard.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    try:\n",
        "        model = GPT.from_pretrained(\"gpt2\")\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping from_pretrained test due to load/download error: {e}\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, 50257, (1, 8), dtype=torch.long, device=device)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "\n",
        "    assert logits.shape == (1, 8, 50257)\n",
        "    assert loss is None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                               [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 12.91s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!{sys.executable} -m pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting experiment_design.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile experiment_design.py\n",
        "\"\"\"\n",
        "Experimental Design (clean/corrupted prompts + target tokens + hypothesis)\n",
        "\n",
        "This module provides:\n",
        "- A structured ExperimentSpec (clean/corrupt prompts, target tokens A/B, hypothesis)\n",
        "- Validation utilities:\n",
        "  - clean/corrupt differ by EXACTLY one BPE token\n",
        "  - same number of tokens\n",
        "  - target tokens A/B are SINGLE BPE tokens (usually with leading space)\n",
        "- Convenience: candidate specs + \"pick the first valid one\" to avoid tokenization surprises.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "import tokenization_protocol as tp\n",
        "\n",
        "\n",
        "# Data structures\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ExperimentSpec:\n",
        "    \"\"\"\n",
        "    Contract\" for the experiment.\n",
        "\n",
        "    clean_text and corrupt_text:\n",
        "      - must have same BPE token length\n",
        "      - must differ by exactly one BPE token\n",
        "\n",
        "    token_a_str and token_b_str:\n",
        "      - intended to be single BPE tokens for the next-token prediction\n",
        "      - recommended to include leading space (e.g., \" Paris\", \" def\")\n",
        "    \"\"\"\n",
        "    clean_text: str\n",
        "    corrupt_text: str\n",
        "    token_a_str: str\n",
        "    token_b_str: str\n",
        "    hypothesis: str\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ValidatedExperiment:\n",
        "    spec: ExperimentSpec\n",
        "    comparison: tp.PairComparison\n",
        "    changed_position: int\n",
        "    token_a_id: int\n",
        "    token_b_id: int\n",
        "\n",
        "\n",
        "# Token helpers (Token A / Token B)\n",
        "def ensure_leading_space(token_str: str) -> str:\n",
        "    \"\"\"\n",
        "    GPT-2 BPE typically encodes mid-sequence words with a leading space.\n",
        "    This helper makes it harder to forget that, but does NOT guarantee single-token.\n",
        "    \"\"\"\n",
        "    if token_str.startswith(\" \"):\n",
        "        return token_str\n",
        "    return \" \" + token_str\n",
        "\n",
        "\n",
        "def single_token_id(bpe: BPETokenizer, token_str: str) -> int:\n",
        "    \"\"\"\n",
        "    Convert a string (e.g., \" def\") into a SINGLE BPE token id.\n",
        "    Raises ValueError if the string tokenizes into multiple tokens.\n",
        "    \"\"\"\n",
        "    ids_2d = bpe(token_str)  # (1, T)\n",
        "    ids = ids_2d[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(\n",
        "            f\"Target token string must be a single BPE token, but got {len(ids)} tokens for {repr(token_str)}: {ids}\"\n",
        "        )\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "# Core validation utilities\n",
        "def changed_token_position(comp: tp.PairComparison) -> int:\n",
        "    \"\"\"\n",
        "    Returns the unique position where clean vs corrupt differ.\n",
        "    Raises if not exactly one differing token.\n",
        "    \"\"\"\n",
        "    tp.assert_one_token_difference(comp)\n",
        "    return int(comp.diff_positions[0])\n",
        "\n",
        "\n",
        "def default_hypothesis(changed_pos: int) -> str:\n",
        "    \"\"\"\n",
        "    A report-ready hypothesis for GPT-2 small activation patching heatmaps.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        f\"Hypothesis: The changed token position (position {changed_pos}) should matter most, \"\n",
        "        \"so patching activations at this position across early-to-mid layers should strongly restore the clean-consistent continuation. \"\n",
        "        \"Middle layers are expected to dominate because they often integrate and route the key conditioning fact/entity forward through the residual stream. \"\n",
        "        \"Late layers may also show a secondary effect near the final token position because they directly refine the next-token logits.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def validate_experiment(bpe: BPETokenizer, spec: ExperimentSpec) -> ValidatedExperiment:\n",
        "    \"\"\"\n",
        "    Full validation for this section:\n",
        "    - clean/corrupt must be same length AND differ by exactly one BPE token\n",
        "    - token A and token B must each be single BPE tokens (usually with leading space)\n",
        "    \"\"\"\n",
        "    comp = tp.validate_pair(\n",
        "        bpe=bpe,\n",
        "        clean_text=spec.clean_text,\n",
        "        corrupt_text=spec.corrupt_text,\n",
        "        require_same_length=True,\n",
        "        require_one_token_diff=True,\n",
        "    )\n",
        "    pos = changed_token_position(comp)\n",
        "\n",
        "    token_a_id = single_token_id(bpe, spec.token_a_str)\n",
        "    token_b_id = single_token_id(bpe, spec.token_b_str)\n",
        "\n",
        "    return ValidatedExperiment(\n",
        "        spec=spec,\n",
        "        comparison=comp,\n",
        "        changed_position=pos,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "    )\n",
        "\n",
        "def candidate_experiments() -> List[ExperimentSpec]:\n",
        "    \"\"\"\n",
        "    A small pool of \"creative but simple\" candidates.\n",
        "    We DO NOT assume these always pass one-token-diff constraints;\n",
        "    that's why pick_first_valid_experiment() exists.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        ExperimentSpec(\n",
        "            clean_text=\"In Python, the keyword to define a function is\",\n",
        "            corrupt_text=\"In JavaScript, the keyword to define a function is\",\n",
        "            token_a_str=\" def\",\n",
        "            token_b_str=\" function\",\n",
        "            hypothesis=\"(auto)\",\n",
        "        ),\n",
        "        ExperimentSpec(\n",
        "            clean_text=\"The capital of France is\",\n",
        "            corrupt_text=\"The capital of Germany is\",\n",
        "            token_a_str=\" Paris\",\n",
        "            token_b_str=\" Berlin\",\n",
        "            hypothesis=\"(auto)\",\n",
        "        ),\n",
        "        ExperimentSpec(\n",
        "            clean_text=\"The chemical symbol for water is\",\n",
        "            corrupt_text=\"The chemical symbol for salt is\",\n",
        "            token_a_str=\" H\",\n",
        "            token_b_str=\" Na\",\n",
        "            hypothesis=\"(auto)\",\n",
        "        ),\n",
        "        ExperimentSpec(\n",
        "            clean_text=\"A triangle has three sides. A\",\n",
        "            corrupt_text=\"A square has three sides. A\",\n",
        "            token_a_str=\" triangle\",\n",
        "            token_b_str=\" square\",\n",
        "            hypothesis=\"(auto)\",\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "\n",
        "def pick_first_valid_experiment(bpe: BPETokenizer, specs: Optional[List[ExperimentSpec]] = None) -> ValidatedExperiment:\n",
        "    \"\"\"\n",
        "    Tries a list of candidate ExperimentSpec and returns the first one that:\n",
        "    - differs by exactly one BPE token\n",
        "    - has equal BPE length\n",
        "    - has single-token target tokens A/B\n",
        "\n",
        "    If none works, raises ValueError with a helpful message.\n",
        "    \"\"\"\n",
        "    specs = specs or candidate_experiments()\n",
        "    errors: List[str] = []\n",
        "\n",
        "    for i, s in enumerate(specs):\n",
        "        try:\n",
        "            tmp = validate_experiment(bpe, s if s.hypothesis != \"(auto)\" else s)\n",
        "            if tmp.spec.hypothesis == \"(auto)\":\n",
        "                auto_h = default_hypothesis(tmp.changed_position)\n",
        "                s2 = ExperimentSpec(\n",
        "                    clean_text=s.clean_text,\n",
        "                    corrupt_text=s.corrupt_text,\n",
        "                    token_a_str=s.token_a_str,\n",
        "                    token_b_str=s.token_b_str,\n",
        "                    hypothesis=auto_h,\n",
        "                )\n",
        "                tmp = validate_experiment(bpe, s2)\n",
        "            return tmp\n",
        "        except Exception as e:\n",
        "            errors.append(f\"[Candidate {i}] {e}\")\n",
        "\n",
        "    raise ValueError(\n",
        "        \"None of the candidate experiments passed the strict Section 4 constraints.\\n\"\n",
        "        \"This is normal: GPT-2 BPE tokenization can be surprising.\\n\\n\"\n",
        "        \"What to do:\\n\"\n",
        "        \"1) Provide your own clean/corrupt prompts and re-run the driver with --clean/--corrupt.\\n\"\n",
        "        \"2) Ensure the two prompts differ by only one BPE token (see token tables).\\n\"\n",
        "        \"3) Ensure token A/B are single BPE tokens (often with leading spaces).\\n\\n\"\n",
        "        \"Errors from candidates:\\n\" + \"\\n\".join(errors)\n",
        "    )\n",
        "\n",
        "def section4_markdown(valid: ValidatedExperiment) -> str:\n",
        "    \"\"\"\n",
        "    Produces a compact Markdown block you can paste into the PDF report (Section 4).\n",
        "    Includes prompts, token stats, target tokens, and the hypothesis.\n",
        "    \"\"\"\n",
        "    comp = valid.comparison\n",
        "    md_table = tp.format_pair_diff_markdown(comp)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\"## 4) Experimental Design: Clean/Corrupted Pair + Hypothesis\\n\")\n",
        "    lines.append(\"**Clean prompt:**\")\n",
        "    lines.append(f\"`{valid.spec.clean_text}`\\n\")\n",
        "    lines.append(\"**Corrupted prompt:**\")\n",
        "    lines.append(f\"`{valid.spec.corrupt_text}`\\n\")\n",
        "\n",
        "    lines.append(f\"**Tokenization constraint:** both prompts have **{comp.clean.seq_len}** BPE tokens and differ at exactly **one** token position: **{valid.changed_position}**.\\n\")\n",
        "    lines.append(\"**Token-by-token comparison (diff highlighted):**\\n\")\n",
        "    lines.append(md_table)\n",
        "\n",
        "    lines.append(\"**Target competing tokens (next-token prediction at the last position):**\")\n",
        "    lines.append(f\"- Token A (clean-consistent): `{valid.spec.token_a_str}`  (token id: {valid.token_a_id})\")\n",
        "    lines.append(f\"- Token B (corrupted-consistent): `{valid.spec.token_b_str}`  (token id: {valid.token_b_id})\\n\")\n",
        "\n",
        "    lines.append(\"**Metric used later (matches the handout):**\")\n",
        "    lines.append(\"`logit(Token B)  logit(Token A)` from the last-position logits.\\n\")\n",
        "\n",
        "    lines.append(\"**Hypothesis:**\")\n",
        "    lines.append(valid.spec.hypothesis + \"\\n\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting experiment_design_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile experiment_design_driver.py\n",
        "\"\"\"\n",
        "What this does:\n",
        "- Builds/validates an ExperimentSpec:\n",
        "  - clean/corrupt prompts: same length and exactly 1 token difference\n",
        "  - target tokens A/B: each must be a single BPE token id\n",
        "- Prints all evidence needed for the report\n",
        "- Writes a report-ready Markdown file section4.md\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "import tokenization_protocol as tp\n",
        "import experiment_design as ed\n",
        "\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--clean\", type=str, default=None, help=\"Clean prompt text (optional)\")\n",
        "    p.add_argument(\"--corrupt\", type=str, default=None, help=\"Corrupted prompt text (optional)\")\n",
        "    p.add_argument(\"--token_a\", type=str, default=None, help=\"Token A string (optional, usually with leading space)\")\n",
        "    p.add_argument(\"--token_b\", type=str, default=None, help=\"Token B string (optional, usually with leading space)\")\n",
        "    p.add_argument(\"--out_md\", type=str, default=\"section4.md\", help=\"Output markdown file for Section 4\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    args = parse_args()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    if args.clean and args.corrupt and args.token_a and args.token_b:\n",
        "        spec = ed.ExperimentSpec(\n",
        "            clean_text=args.clean,\n",
        "            corrupt_text=args.corrupt,\n",
        "            token_a_str=args.token_a,\n",
        "            token_b_str=args.token_b,\n",
        "            hypothesis=\"(auto)\",  # we will fill after validation\n",
        "        )\n",
        "        valid = ed.validate_experiment(bpe, spec)\n",
        "        # Fill automatic hypothesis (now that we know changed position)\n",
        "        spec2 = ed.ExperimentSpec(\n",
        "            clean_text=spec.clean_text,\n",
        "            corrupt_text=spec.corrupt_text,\n",
        "            token_a_str=spec.token_a_str,\n",
        "            token_b_str=spec.token_b_str,\n",
        "            hypothesis=ed.default_hypothesis(valid.changed_position),\n",
        "        )\n",
        "        valid = ed.validate_experiment(bpe, spec2)\n",
        "    else:\n",
        "        # Auto-pick the first candidate that satisfies strict constraints\n",
        "        valid = ed.pick_first_valid_experiment(bpe)\n",
        "\n",
        "    comp = valid.comparison\n",
        "\n",
        "    print(tp.describe_pair(comp))\n",
        "    print(f\"Changed token position: {valid.changed_position}\")\n",
        "\n",
        "    print(\"\\n=== Clean prompt ===\")\n",
        "    print(valid.spec.clean_text)\n",
        "    print(\"\\n=== Corrupted prompt ===\")\n",
        "    print(valid.spec.corrupt_text)\n",
        "\n",
        "    print(\"\\n=== Token-by-token (clean) ===\")\n",
        "    print(tp.format_token_list_for_console(comp.clean))\n",
        "\n",
        "    print(\"\\n=== Token-by-token (corrupt) ===\")\n",
        "    print(tp.format_token_list_for_console(comp.corrupt))\n",
        "\n",
        "    print(\"\\n=== Target tokens ===\")\n",
        "    print(f\"Token A (clean-consistent): {repr(valid.spec.token_a_str)} -> id {valid.token_a_id}\")\n",
        "    print(f\"Token B (corrupted-consistent): {repr(valid.spec.token_b_str)} -> id {valid.token_b_id}\")\n",
        "\n",
        "    print(\"\\n=== Hypothesis ===\")\n",
        "    print(valid.spec.hypothesis)\n",
        "\n",
        "    md = ed.section4_markdown(valid)\n",
        "    out_path = Path(args.out_md)\n",
        "    out_path.write_text(md, encoding=\"utf-8\")\n",
        "    print(f\"\\nWrote Section 4 Markdown to: {out_path.resolve()}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_4.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_4.py\n",
        "import pathlib\n",
        "import sys\n",
        "\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "# Colab-friendly: ensure mingpt editable install path is visible during pytest subprocess\n",
        "COLAB_MINGPT_PATH = pathlib.Path(\"/content/src/mingpt\")\n",
        "if COLAB_MINGPT_PATH.exists():\n",
        "    sys.path.append(str(COLAB_MINGPT_PATH))\n",
        "\n",
        "import mingpt\n",
        "import mingpt.model\n",
        "from mingpt.model import GPT\n",
        "\n",
        "import repo_orientation as ro\n",
        "import tokenization_protocol as tp\n",
        "import experiment_design as ed\n",
        "\n",
        "\n",
        "# Section 2 tests (repo orientation)\n",
        "\n",
        "def test_mingpt_importable_and_paths_exist():\n",
        "    paths = ro.get_paths()\n",
        "    assert \"mingpt.__file__\" in paths and \"mingpt.model.__file__\" in paths\n",
        "\n",
        "    pkg_path = pathlib.Path(paths[\"mingpt.__file__\"])\n",
        "    model_path = pathlib.Path(paths[\"mingpt.model.__file__\"])\n",
        "    assert pkg_path.exists(), f\"mingpt package file not found: {pkg_path}\"\n",
        "    assert model_path.exists(), f\"mingpt.model file not found: {model_path}\"\n",
        "\n",
        "\n",
        "def test_attn_bias_fix_present_or_applied():\n",
        "    src = ro.read_model_source()\n",
        "    assert ro.attn_bias_fix_present(src), (\n",
        "        \"Required fix not found in mingpt/model.py. \"\n",
        "        \"Expected assert to ignore keys ending with .attn.bias.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def test_forward_pipeline_landmarks_present():\n",
        "    fwd_src = ro.forward_source()\n",
        "    lm = ro.find_forward_landmarks(fwd_src)\n",
        "    assert lm.has_tok_emb, \"Expected token embedding (wte/tok_emb) usage in forward.\"\n",
        "    assert lm.has_pos_emb, \"Expected positional embedding (wpe/pos_emb) usage in forward.\"\n",
        "    assert lm.has_blocks_loop, \"Expected loop over transformer blocks in forward.\"\n",
        "    assert lm.has_ln_f, \"Expected final layer norm ln_f in forward.\"\n",
        "    assert lm.has_lm_head, \"Expected lm_head/logits in forward.\"\n",
        "\n",
        "\n",
        "def test_fast_forward_and_generate_from_scratch():\n",
        "    # Fast test: avoid downloading HF weights.\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"  # tiny\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "    assert logits.shape == (1, 10, cfg.vocab_size)\n",
        "    assert loss is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(idx, max_new_tokens=5, do_sample=False)\n",
        "    assert out.shape[1] == 15\n",
        "\n",
        "\n",
        "# Section 3 tests (tokenization protocol)\n",
        "\n",
        "def test_diff_positions_length_mismatch_includes_tail():\n",
        "    a = [1, 2, 3]\n",
        "    b = [1, 2, 3, 4, 5]\n",
        "    diffs = tp.diff_positions(a, b)\n",
        "    assert diffs == [3, 4]\n",
        "\n",
        "\n",
        "def test_compare_reports_detects_one_token_diff_synthetic():\n",
        "    clean = tp.TokenizationReport(\n",
        "        text=\"clean\",\n",
        "        token_ids=[10, 20, 30],\n",
        "        token_strs=[\"a\", \"b\", \"c\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"abc\",\n",
        "    )\n",
        "    corrupt = tp.TokenizationReport(\n",
        "        text=\"corrupt\",\n",
        "        token_ids=[10, 99, 30],\n",
        "        token_strs=[\"a\", \"X\", \"c\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"aXc\",\n",
        "    )\n",
        "    comp = tp.compare_clean_corrupt(clean, corrupt)\n",
        "    assert comp.same_length is True\n",
        "    assert comp.diff_positions == [1]\n",
        "    assert comp.diff_count == 1\n",
        "    assert comp.one_token_diff is True\n",
        "\n",
        "\n",
        "def test_assert_one_token_difference_raises_when_multi_diff():\n",
        "    clean = tp.TokenizationReport(\n",
        "        text=\"clean\",\n",
        "        token_ids=[1, 2, 3],\n",
        "        token_strs=[\"a\", \"b\", \"c\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"abc\",\n",
        "    )\n",
        "    corrupt = tp.TokenizationReport(\n",
        "        text=\"corrupt\",\n",
        "        token_ids=[9, 2, 8],\n",
        "        token_strs=[\"X\", \"b\", \"Y\"],\n",
        "        seq_len=3,\n",
        "        decoded_roundtrip=\"XbY\",\n",
        "    )\n",
        "    comp = tp.compare_clean_corrupt(clean, corrupt)\n",
        "    assert comp.diff_count == 2\n",
        "    with pytest.raises(ValueError):\n",
        "        tp.assert_one_token_difference(comp)\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_bpe_tokenization_roundtrip_and_lengths():\n",
        "    \"\"\"\n",
        "    Slow-ish test because BPETokenizer may download merges/vocab on first use in a fresh runtime.\n",
        "    \"\"\"\n",
        "    from mingpt.bpe import BPETokenizer\n",
        "\n",
        "    try:\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping BPETokenizer test due to tokenizer init/download error: {e}\")\n",
        "\n",
        "    text = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    rep = tp.build_report(bpe, text)\n",
        "\n",
        "    # Basic sanity\n",
        "    assert rep.seq_len > 0\n",
        "    assert len(rep.token_ids) == rep.seq_len\n",
        "    assert len(rep.token_strs) == rep.seq_len\n",
        "\n",
        "    # Roundtrip should contain the key content (exact equality may vary by whitespace normalization)\n",
        "    assert \"Michelle\" in rep.decoded_roundtrip\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_bpe_pair_validation_example_michelle_jones_smith():\n",
        "    \"\"\"\n",
        "    Uses the assignment's canonical-style example to ensure:\n",
        "    - same token length\n",
        "    - at least one differing token (ideally one)\n",
        "    \"\"\"\n",
        "    from mingpt.bpe import BPETokenizer\n",
        "\n",
        "    try:\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping BPETokenizer test due to tokenizer init/download error: {e}\")\n",
        "\n",
        "    clean = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    corrupt = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "    clean_rep = tp.build_report(bpe, clean)\n",
        "    corrupt_rep = tp.build_report(bpe, corrupt)\n",
        "    comp = tp.compare_clean_corrupt(clean_rep, corrupt_rep)\n",
        "\n",
        "    assert comp.same_length is True, f\"Expected same token length; got {clean_rep.seq_len} vs {corrupt_rep.seq_len}\"\n",
        "    assert comp.diff_count >= 1\n",
        "\n",
        "\n",
        "# Section 4 tests (experiment design)\n",
        "def test_changed_token_position_returns_correct_pos_synthetic():\n",
        "    clean = tp.TokenizationReport(\n",
        "        text=\"clean\",\n",
        "        token_ids=[1, 2, 3, 4],\n",
        "        token_strs=[\"a\", \"b\", \"c\", \"d\"],\n",
        "        seq_len=4,\n",
        "        decoded_roundtrip=\"abcd\",\n",
        "    )\n",
        "    corrupt = tp.TokenizationReport(\n",
        "        text=\"corrupt\",\n",
        "        token_ids=[1, 99, 3, 4],\n",
        "        token_strs=[\"a\", \"X\", \"c\", \"d\"],\n",
        "        seq_len=4,\n",
        "        decoded_roundtrip=\"aXcd\",\n",
        "    )\n",
        "    comp = tp.compare_clean_corrupt(clean, corrupt)\n",
        "    assert comp.one_token_diff is True\n",
        "    assert ed.changed_token_position(comp) == 1\n",
        "\n",
        "\n",
        "def test_default_hypothesis_mentions_changed_position():\n",
        "    h = ed.default_hypothesis(7)\n",
        "    assert \"position 7\" in h\n",
        "\n",
        "\n",
        "def test_ensure_leading_space_adds_space_when_missing():\n",
        "    assert ed.ensure_leading_space(\"Paris\") == \" Paris\"\n",
        "    assert ed.ensure_leading_space(\" Paris\") == \" Paris\"\n",
        "\n",
        "\n",
        "def test_single_token_id_raises_for_multi_token_string_with_dummy_tokenizer():\n",
        "    class DummyBPE:\n",
        "        def __call__(self, s: str):\n",
        "            # Return (1, T) tensor\n",
        "            if s == \" def\":\n",
        "                return torch.tensor([[10]], dtype=torch.long)\n",
        "            if s == \" function\":\n",
        "                return torch.tensor([[20]], dtype=torch.long)\n",
        "            if s == \" JavaScript\":\n",
        "                return torch.tensor([[1, 2]], dtype=torch.long)  # multi-token\n",
        "            return torch.tensor([[999]], dtype=torch.long)\n",
        "\n",
        "    bpe = DummyBPE()\n",
        "    assert ed.single_token_id(bpe, \" def\") == 10\n",
        "    assert ed.single_token_id(bpe, \" function\") == 20\n",
        "    with pytest.raises(ValueError):\n",
        "        _ = ed.single_token_id(bpe, \" JavaScript\")\n",
        "\n",
        "\n",
        "@pytest.mark.slow\n",
        "def test_pick_first_valid_experiment_runs_or_skips():\n",
        "    \"\"\"\n",
        "    This validates the *real* Section 4 pipeline using BPETokenizer.\n",
        "    It may skip if tokenizer initialization/download fails OR if none of the candidates satisfy\n",
        "    the strict one-token-diff constraint in this environment.\n",
        "    \"\"\"\n",
        "    from mingpt.bpe import BPETokenizer\n",
        "\n",
        "    try:\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping Section 4 BPETokenizer test due to tokenizer init/download error: {e}\")\n",
        "\n",
        "    try:\n",
        "        valid = ed.pick_first_valid_experiment(bpe)\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping because no candidate spec validated under strict constraints: {e}\")\n",
        "\n",
        "    assert valid.comparison.one_token_diff is True\n",
        "    assert isinstance(valid.changed_position, int)\n",
        "    assert isinstance(valid.token_a_id, int)\n",
        "    assert isinstance(valid.token_b_id, int)\n",
        "\n",
        "\n",
        "# Slow model-weight test (optional)\n",
        "@pytest.mark.slow\n",
        "def test_slow_from_pretrained_gpt2_loads_and_runs():\n",
        "    \"\"\"\n",
        "    Slow test: downloads and loads GPT-2 weights.\n",
        "    If network/cache issues happen in Colab, we skip rather than fail hard.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    try:\n",
        "        model = GPT.from_pretrained(\"gpt2\")\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping from_pretrained test due to load/download error: {e}\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, 50257, (1, 8), dtype=torch.long, device=device)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "\n",
        "    assert logits.shape == (1, 8, 50257)\n",
        "    assert loss is None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Pair summary ===\n",
            "Clean tokens:   10\n",
            "Corrupt tokens: 10\n",
            "Same length?    True\n",
            "Diff count:     1\n",
            "Diff positions: [1]\n",
            "One-token diff? True\n",
            "\n",
            "Changed token position: 1\n",
            "\n",
            "=== Clean prompt ===\n",
            "In Python, the keyword to define a function is\n",
            "\n",
            "=== Corrupted prompt ===\n",
            "In JavaScript, the keyword to define a function is\n",
            "\n",
            "=== Token-by-token (clean) ===\n",
            "00 |   818 | 'In'\n",
            "01 | 11361 | ' Python'\n",
            "02 |    11 | ','\n",
            "03 |   262 | ' the'\n",
            "04 | 21179 | ' keyword'\n",
            "05 |   284 | ' to'\n",
            "06 |  8160 | ' define'\n",
            "07 |   257 | ' a'\n",
            "08 |  2163 | ' function'\n",
            "09 |   318 | ' is'\n",
            "\n",
            "=== Token-by-token (corrupt) ===\n",
            "00 |   818 | 'In'\n",
            "01 | 11933 | ' JavaScript'\n",
            "02 |    11 | ','\n",
            "03 |   262 | ' the'\n",
            "04 | 21179 | ' keyword'\n",
            "05 |   284 | ' to'\n",
            "06 |  8160 | ' define'\n",
            "07 |   257 | ' a'\n",
            "08 |  2163 | ' function'\n",
            "09 |   318 | ' is'\n",
            "\n",
            "=== Target tokens ===\n",
            "Token A (clean-consistent): ' def' -> id 825\n",
            "Token B (corrupted-consistent): ' function' -> id 2163\n",
            "\n",
            "=== Hypothesis ===\n",
            "Hypothesis: The changed token position (position 1) should matter most, so patching activations at this position across early-to-mid layers should strongly restore the clean-consistent continuation. Middle layers are expected to dominate because they often integrate and route the key conditioning fact/entity forward through the residual stream. Late layers may also show a secondary effect near the final token position because they directly refine the next-token logits.\n",
            "\n",
            "Wrote Section 4 Markdown to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/section4.md\n"
          ]
        }
      ],
      "source": [
        "!python experiment_design_driver.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Pair summary ===\n",
            "Clean tokens:   10\n",
            "Corrupt tokens: 10\n",
            "Same length?    True\n",
            "Diff count:     1\n",
            "Diff positions: [1]\n",
            "One-token diff? True\n",
            "\n",
            "Changed token position: 1\n",
            "\n",
            "=== Clean prompt ===\n",
            "In Python, the keyword to define a function is\n",
            "\n",
            "=== Corrupted prompt ===\n",
            "In JavaScript, the keyword to define a function is\n",
            "\n",
            "=== Token-by-token (clean) ===\n",
            "00 |   818 | 'In'\n",
            "01 | 11361 | ' Python'\n",
            "02 |    11 | ','\n",
            "03 |   262 | ' the'\n",
            "04 | 21179 | ' keyword'\n",
            "05 |   284 | ' to'\n",
            "06 |  8160 | ' define'\n",
            "07 |   257 | ' a'\n",
            "08 |  2163 | ' function'\n",
            "09 |   318 | ' is'\n",
            "\n",
            "=== Token-by-token (corrupt) ===\n",
            "00 |   818 | 'In'\n",
            "01 | 11933 | ' JavaScript'\n",
            "02 |    11 | ','\n",
            "03 |   262 | ' the'\n",
            "04 | 21179 | ' keyword'\n",
            "05 |   284 | ' to'\n",
            "06 |  8160 | ' define'\n",
            "07 |   257 | ' a'\n",
            "08 |  2163 | ' function'\n",
            "09 |   318 | ' is'\n",
            "\n",
            "=== Target tokens ===\n",
            "Token A (clean-consistent): ' def' -> id 825\n",
            "Token B (corrupted-consistent): ' function' -> id 2163\n",
            "\n",
            "=== Hypothesis ===\n",
            "Hypothesis: The changed token position (position 1) should matter most, so patching activations at this position across early-to-mid layers should strongly restore the clean-consistent continuation. Middle layers are expected to dominate because they often integrate and route the key conditioning fact/entity forward through the residual stream. Late layers may also show a secondary effect near the final token position because they directly refine the next-token logits.\n",
            "\n",
            "Wrote Section 4 Markdown to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/section4.md\n"
          ]
        }
      ],
      "source": [
        "!python experiment_design_driver.py \\\n",
        "  --clean \"In Python, the keyword to define a function is\" \\\n",
        "  --corrupt \"In JavaScript, the keyword to define a function is\" \\\n",
        "  --token_a \" def\" \\\n",
        "  --token_b \" function\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                          [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 13.23s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m pytest -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apply_section5_patch.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile apply_section5_patch.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import pathlib\n",
        "import re\n",
        "\n",
        "import mingpt.model\n",
        "\n",
        "\n",
        "def ensure_typing_import(src: str) -> str:\n",
        "    \"\"\"\n",
        "    Ensure we have: from typing import Any, Dict, List, Optional\n",
        "    We insert it right after the torch imports if not present.\n",
        "    \"\"\"\n",
        "    need_line = \"from typing import Any, Dict, List, Optional\"\n",
        "    if need_line in src:\n",
        "        return src\n",
        "\n",
        "    # Try inserting after torch imports (stable in minGPT)\n",
        "    pattern = r\"(import torch\\s*\\nimport torch\\.nn as nn\\s*\\n)\"\n",
        "    m = re.search(pattern, src)\n",
        "    if not m:\n",
        "        # Fallback: insert after \"import math\"\n",
        "        pattern2 = r\"(import math\\s*\\n)\"\n",
        "        m2 = re.search(pattern2, src)\n",
        "        if not m2:\n",
        "            raise RuntimeError(\"Could not find a safe place to insert typing imports.\")\n",
        "        insert_at = m2.end(1)\n",
        "        return src[:insert_at] + \"\\n\" + need_line + \"\\n\" + src[insert_at:]\n",
        "\n",
        "    insert_at = m.end(1)\n",
        "    return src[:insert_at] + need_line + \"\\n\" + src[insert_at:]\n",
        "\n",
        "\n",
        "def insert_instrumentation_attributes(src: str) -> str:\n",
        "    \"\"\"\n",
        "    Insert instrumentation attributes into GPT.__init__ (only once).\n",
        "    We place them right after the parameter count print.\n",
        "    \"\"\"\n",
        "    if \"self.clean_activations\" in src:\n",
        "        return src\n",
        "\n",
        "    marker = 'print(\"number of parameters: %.2fM\" % (n_params/1e6,))'\n",
        "    if marker not in src:\n",
        "        raise RuntimeError(\"Could not find the parameter-count print marker in GPT.__init__.\")\n",
        "\n",
        "    inject = (\n",
        "        marker\n",
        "        + \"\\n\\n\"\n",
        "        + \"        # --- Mechanistic interpretability instrumentation (Section 5) ---\\n\"\n",
        "        + \"        # clean cache: list[layer][position] -> Tensor(d_model) for batch element 0\\n\"\n",
        "        + \"        self.clean_activations: Optional[List[List[torch.Tensor]]] = None\\n\"\n",
        "        + \"        self.clean_activation_meta: Optional[Dict[str, int]] = None\\n\"\n",
        "        + \"        # last recorded activations (debug/inspection; does NOT overwrite clean cache)\\n\"\n",
        "        + \"        self.last_activations: Optional[List[List[torch.Tensor]]] = None\\n\"\n",
        "    )\n",
        "    return src.replace(marker, inject)\n",
        "\n",
        "\n",
        "def insert_clear_method_if_missing(src: str) -> str:\n",
        "    \"\"\"\n",
        "    Add a small helper method to clear clean cache (only once).\n",
        "    We insert it right before forward() definition.\n",
        "    \"\"\"\n",
        "    if \"def clear_clean_activations\" in src:\n",
        "        return src\n",
        "\n",
        "    # Insert before the forward definition (original minGPT has `def forward(self, idx, targets=None):`)\n",
        "    anchor = \"    def forward(self, idx, targets=None):\"\n",
        "    if anchor not in src:\n",
        "        # Maybe forward already patched; insert before `def forward(` anyway\n",
        "        m = re.search(r\"\\n\\s*def forward\\(\", src)\n",
        "        if not m:\n",
        "            raise RuntimeError(\"Could not find forward() to insert clear_clean_activations() before.\")\n",
        "        insert_at = m.start()\n",
        "        helper = (\n",
        "            \"\\n\"\n",
        "            \"    def clear_clean_activations(self) -> None:\\n\"\n",
        "            \"        \\\"\\\"\\\"Clear the stored clean activation cache (Section 5).\\\"\\\"\\\"\\n\"\n",
        "            \"        self.clean_activations = None\\n\"\n",
        "            \"        self.clean_activation_meta = None\\n\"\n",
        "            \"\\n\"\n",
        "        )\n",
        "        return src[:insert_at] + helper + src[insert_at:]\n",
        "\n",
        "    helper = (\n",
        "        \"\\n\"\n",
        "        \"    def clear_clean_activations(self) -> None:\\n\"\n",
        "        \"        \\\"\\\"\\\"Clear the stored clean activation cache (Section 5).\\\"\\\"\\\"\\n\"\n",
        "        \"        self.clean_activations = None\\n\"\n",
        "        \"        self.clean_activation_meta = None\\n\"\n",
        "        \"\\n\"\n",
        "    )\n",
        "    return src.replace(anchor, helper + anchor)\n",
        "\n",
        "\n",
        "def replace_forward_with_instrumented(src: str) -> str:\n",
        "    \"\"\"\n",
        "    Replace GPT.forward with an instrumented version that can record activations:\n",
        "      - after each transformer block\n",
        "      - for each token position\n",
        "    Stored as: list[layer][position] -> Tensor(d_model), for batch element 0\n",
        "    \"\"\"\n",
        "    new_forward = r'''\n",
        "    def forward(\n",
        "        self,\n",
        "        idx,\n",
        "        targets=None,\n",
        "        *,\n",
        "        record_activations: bool = False,\n",
        "        cache_activations: bool = False,\n",
        "        overwrite_cache: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Forward pass with optional activation recording (Section 5).\n",
        "\n",
        "        Activation definition (standardized for this assignment):\n",
        "          - residual stream output AFTER each transformer block\n",
        "          - recorded for each token position\n",
        "          - stored for batch element 0 only\n",
        "          - deep-copied via detach().clone()\n",
        "\n",
        "        Storage:\n",
        "          - self.clean_activations: persistent \"clean run cache\" (read later for patching)\n",
        "          - self.last_activations: last recorded activations (debug/inspection)\n",
        "        \"\"\"\n",
        "        # If we're caching, we must record\n",
        "        record_activations = bool(record_activations or cache_activations)\n",
        "\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0)  # (1, t)\n",
        "\n",
        "        # Clear last_activations to avoid stale reads\n",
        "        self.last_activations = None\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx)  # (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos)  # (1, t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "\n",
        "        acts = None\n",
        "        if record_activations:\n",
        "            acts = []  # list[layer][pos] -> Tensor(d_model)\n",
        "\n",
        "        for layer_idx, block in enumerate(self.transformer.h):\n",
        "            x = block(x)\n",
        "\n",
        "            if record_activations:\n",
        "                # store ONLY batch element 0\n",
        "                layer_acts = []\n",
        "                for p in range(t):\n",
        "                    # defensive copy: detach + clone\n",
        "                    layer_acts.append(x[0, p, :].detach().clone())\n",
        "                acts.append(layer_acts)\n",
        "\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "\n",
        "        # finalize activation storage\n",
        "        if record_activations:\n",
        "            self.last_activations = acts\n",
        "\n",
        "        if cache_activations:\n",
        "            if (self.clean_activations is not None) and (not overwrite_cache):\n",
        "                raise RuntimeError(\n",
        "                    \"Clean activation cache already exists. \"\n",
        "                    \"Pass overwrite_cache=True (or call model.clear_clean_activations()) \"\n",
        "                    \"to replace it for a new clean prompt.\"\n",
        "                )\n",
        "\n",
        "            self.clean_activations = acts\n",
        "            self.clean_activation_meta = {\n",
        "                \"seq_len\": int(t),\n",
        "                \"n_layer\": int(len(self.transformer.h)),\n",
        "                \"d_model\": int(logits.shape[-1] if False else x.shape[-1]),  # x is (b,t,d_model) here pre-ln_f? ln_f preserves size\n",
        "            }\n",
        "\n",
        "        return logits, loss\n",
        "'''.strip(\"\\n\")\n",
        "\n",
        "    # Replace ONLY the forward() definition inside GPT, stopping before generate()\n",
        "    # We match from `def forward(self, idx, targets=None):` up to just before `@torch.no_grad()` of generate.\n",
        "    pattern = r\"\\n\\s*def forward\\(self, idx, targets=None\\):\\n(?:.|\\n)*?(?=\\n\\s*@torch\\.no_grad\\(\\)\\n\\s*def generate)\"\n",
        "    if not re.search(pattern, src):\n",
        "        # If forward signature already changed, match more generally:\n",
        "        pattern2 = r\"\\n\\s*def forward\\([^\\)]*\\):\\n(?:.|\\n)*?(?=\\n\\s*@torch\\.no_grad\\(\\)\\n\\s*def generate)\"\n",
        "        if not re.search(pattern2, src):\n",
        "            raise RuntimeError(\"Could not find GPT.forward block to replace (before generate).\")\n",
        "        src, n = re.subn(pattern2, \"\\n\" + new_forward + \"\\n\", src, count=1)\n",
        "        if n != 1:\n",
        "            raise RuntimeError(\"Unexpected number of replacements for forward().\")\n",
        "        return src\n",
        "\n",
        "    src, n = re.subn(pattern, \"\\n\" + new_forward + \"\\n\", src, count=1)\n",
        "    if n != 1:\n",
        "        raise RuntimeError(\"Unexpected number of replacements for forward().\")\n",
        "    return src\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    src = path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "    src = ensure_typing_import(src)\n",
        "    src = insert_instrumentation_attributes(src)\n",
        "    src = insert_clear_method_if_missing(src)\n",
        "    src = replace_forward_with_instrumented(src)\n",
        "\n",
        "    path.write_text(src, encoding=\"utf-8\")\n",
        "    print(f\" Section 5 patch applied to: {path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Section 5 patch applied to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/src/mingpt/mingpt/model.py\n"
          ]
        }
      ],
      "source": [
        "!python apply_section5_patch.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 0.14M\n",
            "layers cached: 3\n",
            "positions cached (layer 0): 10\n",
            "one activation shape: (48,)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "set_seed(123)\n",
        "\n",
        "cfg = GPT.get_default_config()\n",
        "cfg.model_type = \"gpt-nano\"\n",
        "cfg.vocab_size = 1000\n",
        "cfg.block_size = 64\n",
        "\n",
        "m = GPT(cfg).eval()\n",
        "idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits, _ = m(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "print(\"layers cached:\", len(m.clean_activations))\n",
        "print(\"positions cached (layer 0):\", len(m.clean_activations[0]))\n",
        "print(\"one activation shape:\", tuple(m.clean_activations[0][0].shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_5.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_5.py\n",
        "import pathlib\n",
        "import sys\n",
        "\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "COLAB_MINGPT_PATH = pathlib.Path(\"/content/src/mingpt\")\n",
        "if COLAB_MINGPT_PATH.exists():\n",
        "    sys.path.append(str(COLAB_MINGPT_PATH))\n",
        "\n",
        "import mingpt\n",
        "import mingpt.model\n",
        "from mingpt.model import GPT\n",
        "\n",
        "# Section 2 tests (repo orientation)\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ForwardLandmarks:\n",
        "    has_tok_emb: bool\n",
        "    has_pos_emb: bool\n",
        "    has_blocks_loop: bool\n",
        "    has_ln_f: bool\n",
        "    has_lm_head: bool\n",
        "\n",
        "\n",
        "def get_paths() -> Dict[str, str]:\n",
        "    pkg_path = pathlib.Path(mingpt.__file__).resolve()\n",
        "    model_path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    return {\n",
        "        \"mingpt.__file__\": str(pkg_path),\n",
        "        \"mingpt.model.__file__\": str(model_path),\n",
        "    }\n",
        "\n",
        "\n",
        "def read_model_source() -> str:\n",
        "    model_path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    return model_path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def attn_bias_fix_present(model_source: str) -> bool:\n",
        "    return 'len([k for k in sd if not k.endswith(\".attn.bias\")])' in model_source\n",
        "\n",
        "\n",
        "def forward_source() -> str:\n",
        "    return inspect.getsource(GPT.forward)\n",
        "\n",
        "\n",
        "def find_forward_landmarks(src: str) -> ForwardLandmarks:\n",
        "    has_tok_emb = \"tok_emb\" in src and \"wte\" in src\n",
        "    has_pos_emb = \"pos_emb\" in src and \"wpe\" in src\n",
        "    has_blocks_loop = (\"for block in self.transformer.h\" in src) or (\"for layer_idx, block in enumerate(self.transformer.h\" in src)\n",
        "    has_ln_f = \"ln_f\" in src\n",
        "    has_lm_head = \"lm_head\" in src and \"logits\" in src\n",
        "    return ForwardLandmarks(\n",
        "        has_tok_emb=has_tok_emb,\n",
        "        has_pos_emb=has_pos_emb,\n",
        "        has_blocks_loop=has_blocks_loop,\n",
        "        has_ln_f=has_ln_f,\n",
        "        has_lm_head=has_lm_head,\n",
        "    )\n",
        "\n",
        "\n",
        "def test_mingpt_importable_and_paths_exist():\n",
        "    paths = get_paths()\n",
        "    assert \"mingpt.__file__\" in paths and \"mingpt.model.__file__\" in paths\n",
        "\n",
        "    pkg_path = pathlib.Path(paths[\"mingpt.__file__\"])\n",
        "    model_path = pathlib.Path(paths[\"mingpt.model.__file__\"])\n",
        "    assert pkg_path.exists(), f\"mingpt package file not found: {pkg_path}\"\n",
        "    assert model_path.exists(), f\"mingpt.model file not found: {model_path}\"\n",
        "\n",
        "\n",
        "def test_attn_bias_fix_present_or_applied():\n",
        "    src = read_model_source()\n",
        "    assert attn_bias_fix_present(src), (\n",
        "        \"Required fix not found in mingpt/model.py. \"\n",
        "        \"Expected assert to ignore keys ending with .attn.bias.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def test_forward_pipeline_landmarks_present():\n",
        "    fwd_src = forward_source()\n",
        "    lm = find_forward_landmarks(fwd_src)\n",
        "    assert lm.has_tok_emb, \"Expected token embedding (wte/tok_emb) usage in forward.\"\n",
        "    assert lm.has_pos_emb, \"Expected positional embedding (wpe/pos_emb) usage in forward.\"\n",
        "    assert lm.has_blocks_loop, \"Expected loop over transformer blocks in forward.\"\n",
        "    assert lm.has_ln_f, \"Expected final layer norm ln_f in forward.\"\n",
        "    assert lm.has_lm_head, \"Expected lm_head/logits in forward.\"\n",
        "\n",
        "\n",
        "def test_fast_forward_and_generate_from_scratch():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg)\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "    assert logits.shape == (1, 10, cfg.vocab_size)\n",
        "    assert loss is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(idx, max_new_tokens=5, do_sample=False)\n",
        "    assert out.shape[1] == 15\n",
        "\n",
        "\n",
        "# Section 5 tests (activation recording / clean cache)\n",
        "\n",
        "def _make_tiny_gpt():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg).eval()\n",
        "    return model, cfg\n",
        "\n",
        "\n",
        "def test_section5_cache_structure_and_shapes():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 12\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    assert model.clean_activations is not None\n",
        "    assert isinstance(model.clean_activations, list)\n",
        "    assert len(model.clean_activations) == len(model.transformer.h)  # n_layer\n",
        "    assert len(model.clean_activations[0]) == T\n",
        "\n",
        "    # each [layer][pos] must be (d_model,)\n",
        "    d_model = model.transformer.wte.weight.shape[1]\n",
        "    a00 = model.clean_activations[0][0]\n",
        "    assert tuple(a00.shape) == (d_model,)\n",
        "    assert a00.requires_grad is False\n",
        "\n",
        "\n",
        "def test_section5_cache_uses_detach_clone_not_views():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 6\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # If we had stored views into the same underlying tensor, data_ptr() would often match.\n",
        "    a0 = model.clean_activations[0][0]\n",
        "    a1 = model.clean_activations[0][1]\n",
        "    assert a0.data_ptr() != a1.data_ptr(), \"Expected clone()d per-position tensors with distinct storage.\"\n",
        "\n",
        "\n",
        "def test_section5_logits_identical_with_and_without_recording():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 10\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits1, _ = model(idx)  # normal\n",
        "        logits2, _ = model(idx, record_activations=True, cache_activations=False)  # recording only\n",
        "\n",
        "    assert torch.allclose(logits1, logits2), \"Activation recording must not change logits.\"\n",
        "\n",
        "\n",
        "def test_section5_clean_cache_not_overwritten_unless_requested():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    idx1 = torch.randint(0, cfg.vocab_size, (1, 8), dtype=torch.long)\n",
        "    idx2 = torch.randint(0, cfg.vocab_size, (1, 8), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx1, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # snapshot values\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    # normal forward must not change cache\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx2)\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "    # recording-only must not change clean cache\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx2, record_activations=True, cache_activations=False)\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "    # caching again WITHOUT overwrite must raise\n",
        "    with pytest.raises(RuntimeError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(idx2, cache_activations=True, overwrite_cache=False)\n",
        "\n",
        "\n",
        "def test_section5_batch_behavior_records_only_first_element():\n",
        "    model1, cfg = _make_tiny_gpt()\n",
        "    model2, _ = _make_tiny_gpt()\n",
        "    model2.load_state_dict(model1.state_dict())  # identical weights\n",
        "\n",
        "    T = 9\n",
        "    idx_batch = torch.randint(0, cfg.vocab_size, (2, T), dtype=torch.long)\n",
        "    idx_first = idx_batch[:1, :]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model1(idx_batch, cache_activations=True, overwrite_cache=True)\n",
        "        _ = model2(idx_first, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # caches must match up to floating-point tolerance\n",
        "    for L in range(len(model1.clean_activations)):\n",
        "        for p in range(T):\n",
        "            assert torch.allclose(\n",
        "                model1.clean_activations[L][p],\n",
        "                model2.clean_activations[L][p],\n",
        "                rtol=1e-5,\n",
        "                atol=1e-6,\n",
        "            )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 3.03s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m pytest -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SECTION 5 EXTRA COMPROBATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 0.14M\n",
            "Cached layers: 3\n",
            "Seq len in cache (layer 0): 12\n",
            "One activation shape: (48,)\n",
            "Activation requires_grad: False\n",
            "Logits identical (cache ON vs OFF)?: True\n",
            "Cache unchanged after normal forward?: True\n",
            "Re-cache without overwrite correctly raised RuntimeError:\n",
            "  Clean activation cache already exists. Pass overwrite_cache=True (or call model.clear_clean_activations()) to replace it for a new clean pro ...\n",
            "\n",
            " Section 5 smoke test PASSED under your cache-protection semantics.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "set_seed(3407)\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "cfg = GPT.get_default_config()\n",
        "cfg.model_type = \"gpt-nano\"\n",
        "cfg.vocab_size = 1000\n",
        "cfg.block_size = 64\n",
        "\n",
        "model = GPT(cfg)\n",
        "model.eval()\n",
        "\n",
        "B, T = 1, 12\n",
        "idx = torch.randint(0, cfg.vocab_size, (B, T), dtype=torch.long)\n",
        "\n",
        "logits_cache, _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "print(\"Cached layers:\", len(model.clean_activations))\n",
        "print(\"Seq len in cache (layer 0):\", len(model.clean_activations[0]))\n",
        "print(\"One activation shape:\", tuple(model.clean_activations[0][0].shape))\n",
        "print(\"Activation requires_grad:\", model.clean_activations[0][0].requires_grad)\n",
        "\n",
        "# Structural checks\n",
        "assert len(model.clean_activations) == cfg.n_layer\n",
        "assert all(len(layer) == T for layer in model.clean_activations)\n",
        "assert model.clean_activations[0][0].shape == (cfg.n_embd,)\n",
        "assert model.clean_activations[0][0].requires_grad is False\n",
        "\n",
        "logits_no_cache, _ = model(idx, cache_activations=False)\n",
        "same = torch.allclose(logits_cache, logits_no_cache, rtol=1e-5, atol=1e-6)\n",
        "print(\"Logits identical (cache ON vs OFF)?:\", same)\n",
        "assert same\n",
        "\n",
        "fp_before = (\n",
        "    model.clean_activations[0][0].clone(),\n",
        "    model.clean_activations[-1][-1].clone(),\n",
        ")\n",
        "\n",
        "idx2 = torch.randint(0, cfg.vocab_size, (B, T), dtype=torch.long)\n",
        "_ = model(idx2, cache_activations=False)   \n",
        "\n",
        "fp_after = (\n",
        "    model.clean_activations[0][0].clone(),\n",
        "    model.clean_activations[-1][-1].clone(),\n",
        ")\n",
        "\n",
        "unchanged = torch.allclose(fp_before[0], fp_after[0]) and torch.allclose(fp_before[1], fp_after[1])\n",
        "print(\"Cache unchanged after normal forward?:\", unchanged)\n",
        "assert unchanged\n",
        "\n",
        "raised = False\n",
        "try:\n",
        "    _ = model(idx2, cache_activations=True, overwrite_cache=False)\n",
        "except RuntimeError as e:\n",
        "    raised = True\n",
        "    print(\"Re-cache without overwrite correctly raised RuntimeError:\")\n",
        "    print(\" \", str(e)[:140], \"...\")\n",
        "assert raised\n",
        "\n",
        "print(\"\\n Section 5 smoke test PASSED under your cache-protection semantics.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 124.44M\n",
            "gpt2 layers cached: 12\n",
            "seq_len cached: 11\n",
            "d_model shape: (768,)\n",
            "last logits shape: (1, 50257)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "model = GPT.from_pretrained(\"gpt2\")\n",
        "model.eval()\n",
        "\n",
        "bpe = BPETokenizer()\n",
        "text = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "idx = bpe(text)  # (1, T)\n",
        "\n",
        "logits, _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "print(\"gpt2 layers cached:\", len(model.clean_activations))         # EXPECT: 12\n",
        "print(\"seq_len cached:\", len(model.clean_activations[0]))          # EXPECT: T\n",
        "print(\"d_model shape:\", tuple(model.clean_activations[0][0].shape))# EXPECT: (768,)\n",
        "print(\"last logits shape:\", tuple(logits[:, -1, :].shape))         # EXPECT: (1, 50257)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apply_section6_patch.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile apply_section6_patch.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import pathlib\n",
        "import re\n",
        "\n",
        "import mingpt.model\n",
        "\n",
        "\n",
        "def ensure_typing_import(src: str) -> str:\n",
        "    \"\"\"\n",
        "    Ensure we have: from typing import Any, Dict, List, Optional\n",
        "    Insert it in a stable spot if missing.\n",
        "    \"\"\"\n",
        "    need_line = \"from typing import Any, Dict, List, Optional\"\n",
        "    if need_line in src:\n",
        "        return src\n",
        "\n",
        "    # Prefer inserting after torch imports\n",
        "    pattern = r\"(import torch\\s*\\nimport torch\\.nn as nn\\s*\\n)\"\n",
        "    m = re.search(pattern, src)\n",
        "    if m:\n",
        "        insert_at = m.end(1)\n",
        "        return src[:insert_at] + need_line + \"\\n\" + src[insert_at:]\n",
        "\n",
        "    # Fallback: after import math\n",
        "    pattern2 = r\"(import math\\s*\\n)\"\n",
        "    m2 = re.search(pattern2, src)\n",
        "    if not m2:\n",
        "        raise RuntimeError(\"Could not find a safe place to insert typing imports.\")\n",
        "    insert_at = m2.end(1)\n",
        "    return src[:insert_at] + \"\\n\" + need_line + \"\\n\" + src[insert_at:]\n",
        "\n",
        "\n",
        "def insert_last_logits_attribute(src: str) -> str:\n",
        "    \"\"\"\n",
        "    Add: self.last_logits: Optional[torch.Tensor] = None\n",
        "    Prefer inserting next to Section 5 instrumentation attributes if present.\n",
        "    Idempotent.\n",
        "    \"\"\"\n",
        "    if \"self.last_logits\" in src:\n",
        "        return src\n",
        "\n",
        "    # If Section 5 instrumentation exists, insert after last_activations\n",
        "    pattern = r\"(self\\.last_activations:\\s*Optional\\[List\\[List\\[torch\\.Tensor\\]\\]\\]\\s*=\\s*None\\s*\\n)\"\n",
        "    m = re.search(pattern, src)\n",
        "    if m:\n",
        "        inject = (\n",
        "            m.group(1)\n",
        "            + \"        # last-token logits (Section 6): logits at final prompt position (next-token distribution)\\n\"\n",
        "            + \"        self.last_logits: Optional[torch.Tensor] = None\\n\"\n",
        "        )\n",
        "        return src[:m.start(1)] + inject + src[m.end(1):]\n",
        "\n",
        "    # Fallback: insert after parameter-count print in __init__\n",
        "    marker = 'print(\"number of parameters: %.2fM\" % (n_params/1e6,))'\n",
        "    if marker not in src:\n",
        "        raise RuntimeError(\"Could not find a safe marker in GPT.__init__ to insert last_logits attribute.\")\n",
        "\n",
        "    inject = (\n",
        "        marker\n",
        "        + \"\\n\\n\"\n",
        "        + \"        # --- Mechanistic interpretability instrumentation (Section 6) ---\\n\"\n",
        "        + \"        # logits at final prompt position: shape (B, vocab_size)\\n\"\n",
        "        + \"        self.last_logits: Optional[torch.Tensor] = None\\n\"\n",
        "    )\n",
        "    return src.replace(marker, inject)\n",
        "\n",
        "\n",
        "def insert_last_logits_assignment_in_forward(src: str) -> str:\n",
        "    \"\"\"\n",
        "    After logits = self.lm_head(x), insert:\n",
        "        self.last_logits = logits[:, -1, :].detach().clone()\n",
        "    Idempotent.\n",
        "    \"\"\"\n",
        "    if re.search(r\"self\\.last_logits\\s*=\\s*logits\\[:,\\s*-1,\\s*:\\]\\.detach\\(\\)\\.clone\\(\\)\", src):\n",
        "        return src\n",
        "\n",
        "    # Find logits computation line inside forward\n",
        "    pattern = r\"(\\n(\\s*)logits\\s*=\\s*self\\.lm_head\\(x\\)\\s*\\n)\"\n",
        "    m = re.search(pattern, src)\n",
        "    if not m:\n",
        "        raise RuntimeError(\"Could not find the line `logits = self.lm_head(x)` in GPT.forward.\")\n",
        "\n",
        "    full_match = m.group(1)\n",
        "    indent = m.group(2)\n",
        "\n",
        "    insertion = (\n",
        "        full_match\n",
        "        + f\"{indent}# --- Section 6: store last-position logits (next-token distribution after the prompt) ---\\n\"\n",
        "        + f\"{indent}# Shape: (B, vocab_size). We detach+clone to avoid accidental mutation across runs.\\n\"\n",
        "        + f\"{indent}self.last_logits = logits[:, -1, :].detach().clone()\\n\"\n",
        "    )\n",
        "\n",
        "    return src[:m.start(1)] + insertion + src[m.end(1):]\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    src = path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "    src = ensure_typing_import(src)\n",
        "    src = insert_last_logits_attribute(src)\n",
        "    src = insert_last_logits_assignment_in_forward(src)\n",
        "\n",
        "    path.write_text(src, encoding=\"utf-8\")\n",
        "    print(f\" Section 6 patch applied to: {path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Section 6 patch applied to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/src/mingpt/mingpt/model.py\n"
          ]
        }
      ],
      "source": [
        "!python apply_section6_patch.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting last_logits_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile last_logits_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "\n",
        "def single_token_id(bpe: BPETokenizer, token_str: str) -> int:\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(f\"{repr(token_str)} is not a single BPE token. Got {len(ids)} ids: {ids}\")\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    clean = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    idx = bpe(clean).to(device)  # (1, T)\n",
        "\n",
        "    logits, _ = model(idx)  # forward ONCE\n",
        "    assert model.last_logits is not None, \"model.last_logits was not set!\"\n",
        "    print(\"logits shape:\", tuple(logits.shape))\n",
        "    print(\"last_logits shape:\", tuple(model.last_logits.shape))  # (1, vocab)\n",
        "\n",
        "    # Top-k next tokens from last_logits\n",
        "    k = 10\n",
        "    last = model.last_logits[0]  # (vocab,)\n",
        "    probs = F.softmax(last, dim=-1)\n",
        "    top_p, top_i = torch.topk(probs, k)\n",
        "\n",
        "    print(\"\\n=== Top-k next tokens (from model.last_logits) ===\")\n",
        "    for rank in range(k):\n",
        "        tid = int(top_i[rank])\n",
        "        tok = bpe.decode(torch.tensor([tid]))\n",
        "        print(f\"{rank+1:02d}. id={tid:5d} tok={repr(tok):>12} prob={float(top_p[rank]):.4f}\")\n",
        "\n",
        "    # Metric: logit(TokenB) - logit(TokenA)\n",
        "    token_a = \" Jones\"\n",
        "    token_b = \" Smith\"\n",
        "    id_a = single_token_id(bpe, token_a)\n",
        "    id_b = single_token_id(bpe, token_b)\n",
        "\n",
        "    logit_a = float(model.last_logits[0, id_a])\n",
        "    logit_b = float(model.last_logits[0, id_b])\n",
        "    score = logit_b - logit_a\n",
        "\n",
        "    print(\"\\n=== Logit-diff metric ===\")\n",
        "    print(f\"Token A: {repr(token_a)} id={id_a} logit={logit_a:.4f}\")\n",
        "    print(f\"Token B: {repr(token_b)} id={id_b} logit={logit_b:.4f}\")\n",
        "    print(f\"score = logit(B) - logit(A) = {score:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "logits shape: (1, 11, 50257)\n",
            "last_logits shape: (1, 50257)\n",
            "\n",
            "=== Top-k next tokens (from model.last_logits) ===\n",
            "01. id=  373 tok=      ' was' prob=0.1634\n",
            "02. id= 5437 tok=    ' Jones' prob=0.1396\n",
            "03. id=  338 tok=        \"'s\" prob=0.0806\n",
            "04. id=  550 tok=      ' had' prob=0.0491\n",
            "05. id=  318 tok=       ' is' prob=0.0229\n",
            "06. id=  290 tok=      ' and' prob=0.0227\n",
            "07. id=   11 tok=         ',' prob=0.0222\n",
            "08. id=  531 tok=     ' said' prob=0.0134\n",
            "09. id=  468 tok=      ' has' prob=0.0120\n",
            "10. id=  635 tok=     ' also' prob=0.0117\n",
            "\n",
            "=== Logit-diff metric ===\n",
            "Token A: ' Jones' id=5437 logit=-79.6386\n",
            "Token B: ' Smith' id=4176 logit=-83.7627\n",
            "score = logit(B) - logit(A) = -4.1241\n"
          ]
        }
      ],
      "source": [
        "!python last_logits_driver.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_6.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_6.py\n",
        "import inspect\n",
        "import pathlib\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "# If you happen to be in a Colab-like layout, keep this harmless path add.\n",
        "COLAB_MINGPT_PATH = pathlib.Path(\"/content/src/mingpt\")\n",
        "if COLAB_MINGPT_PATH.exists():\n",
        "    sys.path.append(str(COLAB_MINGPT_PATH))\n",
        "\n",
        "import mingpt\n",
        "import mingpt.model\n",
        "from mingpt.model import GPT\n",
        "\n",
        "\n",
        "# Section 2: repo orientation sanity\n",
        "@dataclass(frozen=True)\n",
        "class ForwardLandmarks:\n",
        "    has_tok_emb: bool\n",
        "    has_pos_emb: bool\n",
        "    has_blocks_loop: bool\n",
        "    has_ln_f: bool\n",
        "    has_lm_head: bool\n",
        "\n",
        "\n",
        "def get_paths() -> Dict[str, str]:\n",
        "    pkg_path = pathlib.Path(mingpt.__file__).resolve()\n",
        "    model_path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    return {\n",
        "        \"mingpt.__file__\": str(pkg_path),\n",
        "        \"mingpt.model.__file__\": str(model_path),\n",
        "    }\n",
        "\n",
        "\n",
        "def read_model_source() -> str:\n",
        "    model_path = pathlib.Path(mingpt.model.__file__).resolve()\n",
        "    return model_path.read_text(encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def attn_bias_fix_present(model_source: str) -> bool:\n",
        "    return 'len([k for k in sd if not k.endswith(\".attn.bias\")])' in model_source\n",
        "\n",
        "\n",
        "def forward_source() -> str:\n",
        "    return inspect.getsource(GPT.forward)\n",
        "\n",
        "\n",
        "def find_forward_landmarks(src: str) -> ForwardLandmarks:\n",
        "    has_tok_emb = (\"tok_emb\" in src) and (\"wte\" in src)\n",
        "    has_pos_emb = (\"pos_emb\" in src) and (\"wpe\" in src)\n",
        "    has_blocks_loop = (\"for block in self.transformer.h\" in src) or (\"enumerate(self.transformer.h\" in src)\n",
        "    has_ln_f = \"ln_f\" in src\n",
        "    has_lm_head = (\"lm_head\" in src) and (\"logits\" in src)\n",
        "    return ForwardLandmarks(\n",
        "        has_tok_emb=has_tok_emb,\n",
        "        has_pos_emb=has_pos_emb,\n",
        "        has_blocks_loop=has_blocks_loop,\n",
        "        has_ln_f=has_ln_f,\n",
        "        has_lm_head=has_lm_head,\n",
        "    )\n",
        "\n",
        "\n",
        "def test_mingpt_importable_and_paths_exist():\n",
        "    paths = get_paths()\n",
        "    assert \"mingpt.__file__\" in paths and \"mingpt.model.__file__\" in paths\n",
        "\n",
        "    pkg_path = pathlib.Path(paths[\"mingpt.__file__\"])\n",
        "    model_path = pathlib.Path(paths[\"mingpt.model.__file__\"])\n",
        "    assert pkg_path.exists(), f\"mingpt package file not found: {pkg_path}\"\n",
        "    assert model_path.exists(), f\"mingpt.model file not found: {model_path}\"\n",
        "\n",
        "\n",
        "def test_attn_bias_fix_present_or_applied():\n",
        "    src = read_model_source()\n",
        "    assert attn_bias_fix_present(src), (\n",
        "        \"Required fix not found in mingpt/model.py. \"\n",
        "        \"Expected assert to ignore keys ending with .attn.bias.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def test_forward_pipeline_landmarks_present():\n",
        "    fwd_src = forward_source()\n",
        "    lm = find_forward_landmarks(fwd_src)\n",
        "    assert lm.has_tok_emb, \"Expected token embedding (wte/tok_emb) usage in forward.\"\n",
        "    assert lm.has_pos_emb, \"Expected positional embedding (wpe/pos_emb) usage in forward.\"\n",
        "    assert lm.has_blocks_loop, \"Expected loop over transformer blocks in forward.\"\n",
        "    assert lm.has_ln_f, \"Expected final layer norm ln_f in forward.\"\n",
        "    assert lm.has_lm_head, \"Expected lm_head/logits in forward.\"\n",
        "\n",
        "\n",
        "def test_fast_forward_and_generate_from_scratch():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg).eval()\n",
        "\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "        logits, loss = model(idx)\n",
        "    assert logits.shape == (1, 10, cfg.vocab_size)\n",
        "    assert loss is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(idx, max_new_tokens=5, do_sample=False)\n",
        "    assert out.shape[1] == 15\n",
        "\n",
        "\n",
        "# Shared helper for Section 5/6 tests\n",
        "def _make_tiny_gpt():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 1000\n",
        "    cfg.block_size = 64\n",
        "    model = GPT(cfg).eval()\n",
        "    return model, cfg\n",
        "\n",
        "\n",
        "# Section 5: activation recording / clean cache\n",
        "def test_section5_cache_structure_and_shapes():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 12\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    assert model.clean_activations is not None\n",
        "    assert isinstance(model.clean_activations, list)\n",
        "    assert len(model.clean_activations) == len(model.transformer.h)  # n_layer\n",
        "    assert len(model.clean_activations[0]) == T\n",
        "\n",
        "    d_model = model.transformer.wte.weight.shape[1]\n",
        "    a00 = model.clean_activations[0][0]\n",
        "    assert tuple(a00.shape) == (d_model,)\n",
        "    assert a00.requires_grad is False\n",
        "\n",
        "\n",
        "def test_section5_cache_uses_detach_clone_not_views():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 6\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    a0 = model.clean_activations[0][0]\n",
        "    a1 = model.clean_activations[0][1]\n",
        "    assert a0.data_ptr() != a1.data_ptr(), \"Expected clone()d per-position tensors with distinct storage.\"\n",
        "\n",
        "\n",
        "def test_section5_logits_identical_with_and_without_recording():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 10\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits1, _ = model(idx)  # normal\n",
        "        logits2, _ = model(idx, record_activations=True, cache_activations=False)  # recording only\n",
        "\n",
        "    assert torch.allclose(logits1, logits2), \"Activation recording must not change logits.\"\n",
        "\n",
        "\n",
        "def test_section5_clean_cache_not_overwritten_unless_requested():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    idx1 = torch.randint(0, cfg.vocab_size, (1, 8), dtype=torch.long)\n",
        "    idx2 = torch.randint(0, cfg.vocab_size, (1, 8), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx1, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx2)\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(idx2, record_activations=True, cache_activations=False)\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "    with pytest.raises(RuntimeError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(idx2, cache_activations=True, overwrite_cache=False)\n",
        "\n",
        "\n",
        "def test_section5_batch_behavior_records_only_first_element():\n",
        "    model1, cfg = _make_tiny_gpt()\n",
        "    model2, _ = _make_tiny_gpt()\n",
        "    model2.load_state_dict(model1.state_dict())  # identical weights\n",
        "\n",
        "    T = 9\n",
        "    idx_batch = torch.randint(0, cfg.vocab_size, (2, T), dtype=torch.long)\n",
        "    idx_first = idx_batch[:1, :]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model1(idx_batch, cache_activations=True, overwrite_cache=True)\n",
        "        _ = model2(idx_first, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    for L in range(len(model1.clean_activations)):\n",
        "        for p in range(T):\n",
        "            assert torch.allclose(\n",
        "                model1.clean_activations[L][p],\n",
        "                model2.clean_activations[L][p],\n",
        "                rtol=1e-5,\n",
        "                atol=1e-6,\n",
        "            )\n",
        "\n",
        "# Section 6: last-token logits extraction (NEW)\n",
        "def test_section6_last_logits_exists_and_matches_last_position_logits():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 11\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(idx)\n",
        "\n",
        "    assert hasattr(model, \"last_logits\"), \"Expected GPT to expose model.last_logits\"\n",
        "    assert model.last_logits is not None, \"model.last_logits was not set by forward()\"\n",
        "    assert tuple(model.last_logits.shape) == (1, cfg.vocab_size)\n",
        "\n",
        "    expected = logits[:, -1, :]\n",
        "    assert torch.allclose(model.last_logits, expected), \"model.last_logits must equal logits[:, -1, :] for the same run\"\n",
        "\n",
        "\n",
        "def test_section6_last_logits_is_detached_and_cloned():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 7\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(idx)\n",
        "\n",
        "    view = logits[:, -1, :]  # view into logits storage\n",
        "    assert model.last_logits.requires_grad is False\n",
        "    # clone must not share underlying storage with the view\n",
        "    assert model.last_logits.data_ptr() != view.data_ptr(), \"Expected last_logits to be a clone(), not a view\"\n",
        "\n",
        "\n",
        "def test_section6_last_logits_computed_even_when_recording_or_caching():\n",
        "    model, cfg = _make_tiny_gpt()\n",
        "    T = 9\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits_a, _ = model(idx, record_activations=True, cache_activations=False)\n",
        "    assert model.last_logits is not None\n",
        "    assert torch.allclose(model.last_logits, logits_a[:, -1, :])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits_b, _ = model(idx, cache_activations=True, overwrite_cache=True)\n",
        "    assert model.last_logits is not None\n",
        "    assert torch.allclose(model.last_logits, logits_b[:, -1, :])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                             [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m12 passed\u001b[0m\u001b[32m in 2.86s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m pytest -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXTRA COMPROBATIONS FOR SECTION 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 124.44M\n",
            "number of parameters: 124.44M\n",
            "score(clean)  = -4.124076843261719\n",
            "score(corrupt)= 5.656242370605469\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "def single_token_id(bpe, s):\n",
        "    ids = bpe(s)[0].tolist()\n",
        "    assert len(ids) == 1, (s, ids)\n",
        "    return int(ids[0])\n",
        "\n",
        "@torch.no_grad()\n",
        "def score_for(prompt, token_a=\" Jones\", token_b=\" Smith\"):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "    idx = bpe(prompt).to(device)\n",
        "    _ = model(idx)\n",
        "    id_a = single_token_id(bpe, token_a)\n",
        "    id_b = single_token_id(bpe, token_b)\n",
        "    return float(model.last_logits[0, id_b] - model.last_logits[0, id_a])\n",
        "\n",
        "clean = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "corrupt = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "s_clean = score_for(clean)\n",
        "s_corrupt = score_for(corrupt)\n",
        "\n",
        "print(\"score(clean)  =\", s_clean)\n",
        "print(\"score(corrupt)=\", s_corrupt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m71 passed\u001b[0m\u001b[32m in 24.29s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting patching_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile patching_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "@torch.no_grad()\n",
        "def main():\n",
        "    set_seed(123)\n",
        "\n",
        "    # tiny model (fast, no downloads)\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 200\n",
        "    cfg.block_size = 32\n",
        "\n",
        "    model = GPT(cfg).eval()\n",
        "\n",
        "    T = 12\n",
        "    clean = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, 3] = (corrupt[0, 3] + 1) % cfg.vocab_size  # minimal corruption\n",
        "\n",
        "    # cache clean activations\n",
        "    _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "    print(\"Cached clean activations:\",\n",
        "          len(model.clean_activations), \"layers x\", len(model.clean_activations[0]), \"positions\")\n",
        "\n",
        "    # corrupted baseline (no patch)\n",
        "    _ = model(corrupt)\n",
        "    base_last = model.last_logits.clone()\n",
        "\n",
        "    # one patched run (layer=0, pos=3)\n",
        "    _ = model(corrupt, layer_to_patch=0, position_to_patch=3)\n",
        "    patched_last = model.last_logits.clone()\n",
        "\n",
        "    print(\"Patch applied:\", model.last_patch)\n",
        "    print(\"Logits changed vs baseline? \", (not torch.allclose(base_last, patched_last)))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_7_all.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_7_all.py\n",
        "import pytest\n",
        "import torch\n",
        "from mingpt.model import GPT\n",
        "\n",
        "def _make_tiny():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 200\n",
        "    cfg.block_size = 32\n",
        "    model = GPT(cfg).eval()\n",
        "    return model, cfg\n",
        "\n",
        "def _make_clean_corrupt(cfg, T=12):\n",
        "    clean = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    # change exactly one token id so activations differ\n",
        "    corrupt[0, 3] = (corrupt[0, 3] + 1) % cfg.vocab_size\n",
        "    return clean, corrupt\n",
        "\n",
        "# Section 5/6 sanity (minimal, to ensure Section 7 didn't break them)\n",
        "\n",
        "def test_last_logits_exists_and_shape():\n",
        "    model, cfg = _make_tiny()\n",
        "    idx = torch.randint(0, cfg.vocab_size, (1, 10), dtype=torch.long)\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(idx)\n",
        "    assert model.last_logits is not None\n",
        "    assert tuple(model.last_logits.shape) == (1, cfg.vocab_size)\n",
        "    assert torch.allclose(model.last_logits, logits[:, -1, :])\n",
        "\n",
        "def test_clean_cache_written_only_when_requested():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=10)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    # normal run must not mutate clean cache\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt)\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "# Section 7 patching tests\n",
        "\n",
        "def test_patch_requires_existing_clean_cache():\n",
        "    model, cfg = _make_tiny()\n",
        "    _, corrupt = _make_clean_corrupt(cfg, T=10)\n",
        "\n",
        "    with pytest.raises(RuntimeError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3)\n",
        "\n",
        "def test_patch_argument_pairing_rules():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=10)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=None)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=None, position_to_patch=3)\n",
        "\n",
        "def test_patch_disallows_cache_write_flags():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=10)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with pytest.raises(RuntimeError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3, cache_activations=True)\n",
        "\n",
        "    with pytest.raises(RuntimeError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3, overwrite_cache=True)\n",
        "\n",
        "def test_patch_applies_at_exact_layer_and_position_and_only_there():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=12)\n",
        "\n",
        "    # Cache clean activations\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # Corrupted baseline with recording (to compare)\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True, cache_activations=False)\n",
        "    baseline_acts = model.last_activations\n",
        "    assert baseline_acts is not None\n",
        "\n",
        "    # Patched run with recording\n",
        "    L = 0\n",
        "    P = 3\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True, layer_to_patch=L, position_to_patch=P)\n",
        "    patched_acts = model.last_activations\n",
        "    assert patched_acts is not None\n",
        "\n",
        "    # patched location equals clean cache at that (layer, pos)\n",
        "    assert torch.allclose(\n",
        "        patched_acts[L][P],\n",
        "        model.clean_activations[L][P],\n",
        "        rtol=1e-5,\n",
        "        atol=1e-6,\n",
        "    )\n",
        "\n",
        "    # baseline at that location differs from clean cache (should, because corrupt differs)\n",
        "    assert not torch.allclose(\n",
        "        baseline_acts[L][P],\n",
        "        model.clean_activations[L][P],\n",
        "        rtol=1e-5,\n",
        "        atol=1e-6,\n",
        "    )\n",
        "\n",
        "    # same layer, other positions are unchanged by patch at that layer output\n",
        "    other_pos = 0 if P != 0 else 1\n",
        "    assert torch.allclose(\n",
        "        patched_acts[L][other_pos],\n",
        "        baseline_acts[L][other_pos],\n",
        "        rtol=1e-5,\n",
        "        atol=1e-6,\n",
        "    )\n",
        "\n",
        "    # bookkeeping says exactly one patch\n",
        "    assert model.last_patch == (L, P)\n",
        "\n",
        "def test_patch_changes_last_logits_vs_corrupted_baseline():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=12)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt)\n",
        "    base_last = model.last_logits.clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, layer_to_patch=0, position_to_patch=3)\n",
        "    patched_last = model.last_logits.clone()\n",
        "\n",
        "    # Almost surely different if patch actually applied\n",
        "    assert not torch.allclose(base_last, patched_last)\n",
        "\n",
        "def test_clean_cache_not_mutated_by_patched_runs():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=12)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, layer_to_patch=0, position_to_patch=3, record_activations=True)\n",
        "\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m  [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m71 passed\u001b[0m\u001b[32m in 30.49s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing baseline_utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile baseline_utils.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Tuple, Dict, Any\n",
        "\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TopKEntry:\n",
        "    rank: int\n",
        "    token_id: int\n",
        "    token_str: str\n",
        "    prob: float\n",
        "    logit: float\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BaselineResult:\n",
        "    prompt: str\n",
        "    seq_len: int\n",
        "    topk: List[TopKEntry]\n",
        "    token_a: str\n",
        "    token_b: str\n",
        "    token_a_id: int\n",
        "    token_b_id: int\n",
        "    logit_a: float\n",
        "    logit_b: float\n",
        "    prob_a: float\n",
        "    prob_b: float\n",
        "    score_logit_diff: float  # logit(B) - logit(A)\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def single_token_id(bpe, token_str: str) -> int:\n",
        "    \"\"\"\n",
        "    Convert token_str into a SINGLE BPE token id.\n",
        "    This matches the assignment warning: mid-sequence words usually need a leading space, e.g. ' Jones'.\n",
        "    \"\"\"\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(\n",
        "            f\"Target token string must map to exactly 1 BPE token. Got {len(ids)} tokens for {repr(token_str)}: {ids}\"\n",
        "        )\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "def topk_from_last_logits(bpe, last_logits_1d: torch.Tensor, k: int = 20) -> List[TopKEntry]:\n",
        "    \"\"\"\n",
        "    last_logits_1d: shape (vocab_size,)\n",
        "    Returns top-k tokens by probability (softmax over logits).\n",
        "    \"\"\"\n",
        "    probs = F.softmax(last_logits_1d, dim=-1)\n",
        "    top_p, top_i = torch.topk(probs, k)\n",
        "\n",
        "    out: List[TopKEntry] = []\n",
        "    for r in range(k):\n",
        "        tid = int(top_i[r])\n",
        "        tok = bpe.decode(torch.tensor([tid], dtype=torch.long))\n",
        "        out.append(\n",
        "            TopKEntry(\n",
        "                rank=r + 1,\n",
        "                token_id=tid,\n",
        "                token_str=tok,\n",
        "                prob=float(top_p[r]),\n",
        "                logit=float(last_logits_1d[tid]),\n",
        "            )\n",
        "        )\n",
        "    return out\n",
        "\n",
        "\n",
        "def compute_logit_diff(last_logits_1d: torch.Tensor, token_b_id: int, token_a_id: int) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Returns (logit_a, logit_b, score = logit_b - logit_a)\n",
        "    \"\"\"\n",
        "    logit_a = float(last_logits_1d[token_a_id])\n",
        "    logit_b = float(last_logits_1d[token_b_id])\n",
        "    return logit_a, logit_b, (logit_b - logit_a)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_clean_baseline(\n",
        "    model,\n",
        "    bpe,\n",
        "    clean_text: str,\n",
        "    token_a_str: str,\n",
        "    token_b_str: str,\n",
        "    *,\n",
        "    device: Optional[str] = None,\n",
        "    top_k: int = 20,\n",
        "    overwrite_cache: bool = True,\n",
        ") -> BaselineResult:\n",
        "    \"\"\"\n",
        "    CLEAN baseline:\n",
        "    - caches clean activations (for later patching)\n",
        "    - stores model.last_logits\n",
        "    - prints/returns top-k continuation distribution\n",
        "    \"\"\"\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    idx = bpe(clean_text).to(device)  # (1, T)\n",
        "    seq_len = int(idx.shape[1])\n",
        "\n",
        "    # Cache clean activations + set last_logits\n",
        "    _logits, _loss = model(idx, cache_activations=True, overwrite_cache=overwrite_cache)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits was not set by forward() during clean baseline.\")\n",
        "    last = model.last_logits[0]  # (vocab,)\n",
        "\n",
        "    token_a_id = single_token_id(bpe, token_a_str)\n",
        "    token_b_id = single_token_id(bpe, token_b_str)\n",
        "    logit_a, logit_b, score = compute_logit_diff(last, token_b_id=token_b_id, token_a_id=token_a_id)\n",
        "\n",
        "    probs = F.softmax(last, dim=-1)\n",
        "    prob_a = float(probs[token_a_id])\n",
        "    prob_b = float(probs[token_b_id])\n",
        "\n",
        "    topk = topk_from_last_logits(bpe, last, k=top_k)\n",
        "\n",
        "    return BaselineResult(\n",
        "        prompt=clean_text,\n",
        "        seq_len=seq_len,\n",
        "        topk=topk,\n",
        "        token_a=token_a_str,\n",
        "        token_b=token_b_str,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        logit_a=logit_a,\n",
        "        logit_b=logit_b,\n",
        "        score_logit_diff=score,\n",
        "    )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_corrupt_baseline(\n",
        "    model,\n",
        "    bpe,\n",
        "    corrupt_text: str,\n",
        "    token_a_str: str,\n",
        "    token_b_str: str,\n",
        "    *,\n",
        "    device: Optional[str] = None,\n",
        "    top_k: int = 20,\n",
        ") -> BaselineResult:\n",
        "    \"\"\"\n",
        "    CORRUPTED baseline (NO patching):\n",
        "    - must NOT overwrite clean cache\n",
        "    - stores model.last_logits\n",
        "    - prints/returns top-k continuation distribution\n",
        "    \"\"\"\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    idx = bpe(corrupt_text).to(device)  # (1, T)\n",
        "    seq_len = int(idx.shape[1])\n",
        "\n",
        "    # No cache flags here => clean cache remains intact\n",
        "    _logits, _loss = model(idx)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits was not set by forward() during corrupt baseline.\")\n",
        "    last = model.last_logits[0]  # (vocab,)\n",
        "\n",
        "    token_a_id = single_token_id(bpe, token_a_str)\n",
        "    token_b_id = single_token_id(bpe, token_b_str)\n",
        "    logit_a, logit_b, score = compute_logit_diff(last, token_b_id=token_b_id, token_a_id=token_a_id)\n",
        "\n",
        "    probs = F.softmax(last, dim=-1)\n",
        "    prob_a = float(probs[token_a_id])\n",
        "    prob_b = float(probs[token_b_id])\n",
        "\n",
        "    topk = topk_from_last_logits(bpe, last, k=top_k)\n",
        "\n",
        "    return BaselineResult(\n",
        "        prompt=clean_text,\n",
        "        seq_len=seq_len,\n",
        "        topk=topk,\n",
        "        token_a=token_a_str,\n",
        "        token_b=token_b_str,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        logit_a=logit_a,\n",
        "        logit_b=logit_b,\n",
        "        prob_a=prob_a,\n",
        "        prob_b=prob_b,\n",
        "        score_logit_diff=score,\n",
        "    )\n",
        "\n",
        "\n",
        "def format_topk_table(res: BaselineResult, *, max_rows: int = 20) -> str:\n",
        "    lines = []\n",
        "    lines.append(f\"Prompt (seq_len={res.seq_len}): {res.prompt}\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(f\"Metric tokens:\")\n",
        "    lines.append(f\"  Token A (clean-consistent):   {repr(res.token_a)}  id={res.token_a_id}  logit={res.logit_a:.4f}\")\n",
        "    lines.append(f\"  Token B (corrupt-consistent): {repr(res.token_b)}  id={res.token_b_id}  logit={res.logit_b:.4f}\")\n",
        "    lines.append(f\"  score = logit(B) - logit(A) = {res.score_logit_diff:.4f}\")\n",
        "    lines.append(f\"  P(Token A) = {res.prob_a:.4f}\")\n",
        "    lines.append(f\"  P(Token B) = {res.prob_b:.4f}\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(f\"Top-{min(max_rows, len(res.topk))} next-token continuations (by probability):\")\n",
        "    for e in res.topk[:max_rows]:\n",
        "        lines.append(\n",
        "            f\"{e.rank:02d}. id={e.token_id:5d} tok={repr(e.token_str):>14}  prob={e.prob:.4f}  logit={e.logit:.4f}\"\n",
        "        )\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CLEAN baseline ===\n",
            "Prompt (seq_len=11): Michelle Jones was a top-notch student. Michelle\n",
            "\n",
            "Metric tokens:\n",
            "  Token A (clean-consistent):   ' Jones'  id=5437  logit=-79.6386\n",
            "  Token B (corrupt-consistent): ' Smith'  id=4176  logit=-83.7627\n",
            "  score = logit(B) - logit(A) = -4.1241\n",
            "\n",
            "Top-20 next-token continuations (by probability):\n",
            "01. id=  373 tok=        ' was'  prob=0.1634  logit=-79.4807\n",
            "02. id= 5437 tok=      ' Jones'  prob=0.1396  logit=-79.6386\n",
            "03. id=  338 tok=          \"'s\"  prob=0.0806  logit=-80.1876\n",
            "04. id=  550 tok=        ' had'  prob=0.0491  logit=-80.6838\n",
            "05. id=  318 tok=         ' is'  prob=0.0229  logit=-81.4471\n",
            "06. id=  290 tok=        ' and'  prob=0.0227  logit=-81.4569\n",
            "07. id=   11 tok=           ','  prob=0.0222  logit=-81.4781\n",
            "08. id=  531 tok=       ' said'  prob=0.0134  logit=-81.9811\n",
            "09. id=  468 tok=        ' has'  prob=0.0120  logit=-82.0913\n",
            "10. id=  635 tok=       ' also'  prob=0.0117  logit=-82.1161\n",
            "11. id= 1625 tok=       ' came'  prob=0.0091  logit=-82.3733\n",
            "12. id= 1297 tok=       ' told'  prob=0.0084  logit=-82.4499\n",
            "13. id= 1422 tok=       ' didn'  prob=0.0070  logit=-82.6320\n",
            "14. id= 2993 tok=       ' knew'  prob=0.0067  logit=-82.6713\n",
            "15. id= 1816 tok=       ' went'  prob=0.0061  logit=-82.7684\n",
            "16. id=  561 tok=      ' would'  prob=0.0061  logit=-82.7738\n",
            "17. id= 3111 tok=     ' worked'  prob=0.0055  logit=-82.8806\n",
            "18. id=  750 tok=        ' did'  prob=0.0054  logit=-82.8953\n",
            "19. id= 2486 tok=      ' Obama'  prob=0.0053  logit=-82.9094\n",
            "20. id= 2492 tok=       ' wasn'  prob=0.0050  logit=-82.9685\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "=== CORRUPTED baseline (NO patch) ===\n",
            "Prompt (seq_len=11): Michelle Smith was a top-notch student. Michelle\n",
            "\n",
            "Metric tokens:\n",
            "  Token A (clean-consistent):   ' Jones'  id=5437  logit=-88.4841\n",
            "  Token B (corrupt-consistent): ' Smith'  id=4176  logit=-82.8279\n",
            "  score = logit(B) - logit(A) = 5.6562\n",
            "\n",
            "Top-20 next-token continuations (by probability):\n",
            "01. id=  373 tok=        ' was'  prob=0.1630  logit=-82.6385\n",
            "02. id= 4176 tok=      ' Smith'  prob=0.1349  logit=-82.8279\n",
            "03. id=  338 tok=          \"'s\"  prob=0.0858  logit=-83.2802\n",
            "04. id=  550 tok=        ' had'  prob=0.0627  logit=-83.5946\n",
            "05. id=  318 tok=         ' is'  prob=0.0256  logit=-84.4906\n",
            "06. id=   11 tok=           ','  prob=0.0255  logit=-84.4927\n",
            "07. id=  290 tok=        ' and'  prob=0.0227  logit=-84.6085\n",
            "08. id=  531 tok=       ' said'  prob=0.0160  logit=-84.9604\n",
            "09. id=  468 tok=        ' has'  prob=0.0134  logit=-85.1377\n",
            "10. id= 7817 tok=     ' taught'  prob=0.0111  logit=-85.3298\n",
            "11. id=  635 tok=       ' also'  prob=0.0093  logit=-85.5020\n",
            "12. id= 3111 tok=     ' worked'  prob=0.0092  logit=-85.5162\n",
            "13. id= 1625 tok=       ' came'  prob=0.0079  logit=-85.6695\n",
            "14. id=  561 tok=      ' would'  prob=0.0074  logit=-85.7352\n",
            "15. id= 1297 tok=       ' told'  prob=0.0073  logit=-85.7472\n",
            "16. id= 2993 tok=       ' knew'  prob=0.0066  logit=-85.8450\n",
            "17. id= 1718 tok=       ' took'  prob=0.0063  logit=-85.8929\n",
            "18. id= 1422 tok=       ' didn'  prob=0.0059  logit=-85.9512\n",
            "19. id= 9141 tok=   ' attended'  prob=0.0056  logit=-86.0030\n",
            "20. id=  750 tok=        ' did'  prob=0.0051  logit=-86.0983\n",
            "\n",
            "==========================================================================================\n",
            "=== Metric sanity check (expected shift toward corrupted) ===\n",
            "clean score   = -4.1241\n",
            "corrupt score = 5.6562\n",
            "delta (corrupt - clean) = 9.7803\n"
          ]
        }
      ],
      "source": [
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "from baseline_utils import (\n",
        "    run_clean_baseline,\n",
        "    run_corrupt_baseline,\n",
        "    format_topk_table,\n",
        ")\n",
        "\n",
        "CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "TOKEN_A = \" Jones\"  # clean-consistent continuation\n",
        "TOKEN_B = \" Smith\"  # corrupt-consistent continuation\n",
        "\n",
        "bpe = BPETokenizer()\n",
        "\n",
        "clean_res = run_clean_baseline(model, bpe, CLEAN_TEXT, TOKEN_A, TOKEN_B, device=device, top_k=20, overwrite_cache=True)\n",
        "corrupt_res = run_corrupt_baseline(model, bpe, CORRUPT_TEXT, TOKEN_A, TOKEN_B, device=device, top_k=20)\n",
        "\n",
        "print(\"=== CLEAN baseline ===\")\n",
        "print(format_topk_table(clean_res, max_rows=20))\n",
        "print(\"\\n\" + \"=\"*90 + \"\\n\")\n",
        "print(\"=== CORRUPTED baseline (NO patch) ===\")\n",
        "print(format_topk_table(corrupt_res, max_rows=20))\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"=== Metric sanity check (expected shift toward corrupted) ===\")\n",
        "print(f\"clean score   = {clean_res.score_logit_diff:.4f}\")\n",
        "print(f\"corrupt score = {corrupt_res.score_logit_diff:.4f}\")\n",
        "print(f\"delta (corrupt - clean) = {corrupt_res.score_logit_diff - clean_res.score_logit_diff:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_section_8.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_8.py\n",
        "import pytest\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from mingpt.model import GPT\n",
        "\n",
        "import baseline_utils as bu\n",
        "\n",
        "\n",
        "# Dummy tokenizer (FAST tests, no downloads)\n",
        "class DummyTokenizer:\n",
        "    \"\"\"\n",
        "    Minimal stand-in for BPETokenizer that supports:\n",
        "    - __call__(text) -> tensor(1,T)\n",
        "    - decode(tensor([id])) -> string\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # ids for prompt chars\n",
        "        self.map = {\n",
        "            \"a\": 1, \"b\": 2, \"c\": 3, \"x\": 4, \"y\": 5, \"z\": 6,\n",
        "            # ids for \"tokens\" A/B (single-token strings)\n",
        "            \" A\": 7,\n",
        "            \" B\": 8,\n",
        "        }\n",
        "        self.inv = {v: k for k, v in self.map.items()}\n",
        "\n",
        "    def __call__(self, s: str):\n",
        "        if s in self.map:\n",
        "            ids = [self.map[s]]\n",
        "        else:\n",
        "            ids = [self.map[ch] for ch in s]  # tokenize per char for prompt\n",
        "        return torch.tensor([ids], dtype=torch.long)\n",
        "\n",
        "    def decode(self, t: torch.Tensor) -> str:\n",
        "        # expects shape (1,) or (n,)\n",
        "        ids = t.flatten().tolist()\n",
        "        return \"\".join(self.inv.get(int(i), f\"<{int(i)}>\") for i in ids)\n",
        "\n",
        "\n",
        "def _make_tiny_gpt(vocab_size=50, block_size=32):\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = vocab_size\n",
        "    cfg.block_size = block_size\n",
        "    return GPT(cfg).eval()\n",
        "\n",
        "\n",
        "# Section 8: baseline utils tests (FAST)\n",
        "\n",
        "def test_single_token_id_accepts_single_and_rejects_multi():\n",
        "    bpe = DummyTokenizer()\n",
        "    assert bu.single_token_id(bpe, \" A\") == 7\n",
        "    assert bu.single_token_id(bpe, \" B\") == 8\n",
        "\n",
        "    # Multi-token string under DummyTokenizer (tokenizes as chars)\n",
        "    with pytest.raises(ValueError):\n",
        "        _ = bu.single_token_id(bpe, \"ab\")\n",
        "\n",
        "\n",
        "def test_compute_logit_diff_correctness():\n",
        "    last = torch.tensor([0.0, 1.0, 2.0, -3.0], dtype=torch.float32)\n",
        "    logit_a, logit_b, score = bu.compute_logit_diff(last, token_b_id=2, token_a_id=1)\n",
        "    assert logit_a == 1.0\n",
        "    assert logit_b == 2.0\n",
        "    assert score == 1.0\n",
        "\n",
        "\n",
        "def test_topk_from_last_logits_sorted_and_probabilities_valid():\n",
        "    bpe = DummyTokenizer()\n",
        "    last = torch.tensor([0.0, 1.0, 2.0, 3.0, -1.0, -2.0, 0.5, 0.25, 0.1], dtype=torch.float32)\n",
        "    k = 5\n",
        "    topk = bu.topk_from_last_logits(bpe, last, k=k)\n",
        "\n",
        "    assert len(topk) == k\n",
        "    # probabilities in [0,1] and sorted desc\n",
        "    probs = [e.prob for e in topk]\n",
        "    assert all(0.0 <= p <= 1.0 for p in probs)\n",
        "    assert probs == sorted(probs, reverse=True)\n",
        "\n",
        "\n",
        "def test_clean_baseline_caches_activations_and_sets_last_logits():\n",
        "    model = _make_tiny_gpt(vocab_size=60, block_size=16)\n",
        "    bpe = DummyTokenizer()\n",
        "\n",
        "    clean_text = \"abc\"      # -> ids [1,2,3]\n",
        "    token_a = \" A\"          # -> id 7\n",
        "    token_b = \" B\"          # -> id 8\n",
        "\n",
        "    res = bu.run_clean_baseline(model, bpe, clean_text, token_a, token_b, device=\"cpu\", top_k=5, overwrite_cache=True)\n",
        "\n",
        "    assert model.clean_activations is not None, \"Clean baseline must cache activations.\"\n",
        "    assert model.last_logits is not None, \"Clean baseline must set last_logits.\"\n",
        "    assert isinstance(res.score_logit_diff, float)\n",
        "\n",
        "\n",
        "def test_corrupt_baseline_does_not_overwrite_clean_cache():\n",
        "    model = _make_tiny_gpt(vocab_size=60, block_size=16)\n",
        "    bpe = DummyTokenizer()\n",
        "\n",
        "    clean_text = \"abc\"\n",
        "    corrupt_text = \"abx\"  # differs in one char token id\n",
        "\n",
        "    token_a = \" A\"\n",
        "    token_b = \" B\"\n",
        "\n",
        "    _ = bu.run_clean_baseline(model, bpe, clean_text, token_a, token_b, device=\"cpu\", top_k=5, overwrite_cache=True)\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    _ = bu.run_corrupt_baseline(model, bpe, corrupt_text, token_a, token_b, device=\"cpu\", top_k=5)\n",
        "\n",
        "    # verify cache unchanged\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "\n",
        "# Optional SLOW integration test with real GPT-2 (skips if download/cache missing)\n",
        "@pytest.mark.slow\n",
        "def test_section8_metric_shifts_toward_corrupted_on_gpt2_if_available():\n",
        "    \"\"\"\n",
        "    Expected behavior for the canonical example:\n",
        "      score = logit(' Smith') - logit(' Jones')\n",
        "      clean prompt  -> score tends to be smaller (often negative)\n",
        "      corrupt prompt -> score tends to be larger (often positive)\n",
        "    We only assert corrupt_score > clean_score.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from mingpt.bpe import BPETokenizer\n",
        "        from mingpt.model import GPT\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping due to import error: {e}\")\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    try:\n",
        "        model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"Skipping GPT-2 integration (weights/tokenizer unavailable): {e}\")\n",
        "\n",
        "    CLEAN = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    CORR  = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "    A = \" Jones\"\n",
        "    B = \" Smith\"\n",
        "\n",
        "    clean_res = bu.run_clean_baseline(model, bpe, CLEAN, A, B, device=device, top_k=10, overwrite_cache=True)\n",
        "    corr_res  = bu.run_corrupt_baseline(model, bpe, CORR, A, B, device=device, top_k=10)\n",
        "\n",
        "    assert corr_res.score_logit_diff > clean_res.score_logit_diff\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                   [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 16.32s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q test_section_8.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SECTION 8 RUN SECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "Clean cache meta: {'seq_len': 11, 'n_layer': 12, 'd_model': 768}\n",
            "\n",
            "=== CLEAN baseline ===\n",
            "Prompt (seq_len=11): Michelle Jones was a top-notch student. Michelle\n",
            "\n",
            "Metric tokens:\n",
            "  Token A (clean-consistent):   ' Jones'  id=5437  logit=-79.6386\n",
            "  Token B (corrupt-consistent): ' Smith'  id=4176  logit=-83.7627\n",
            "  score = logit(B) - logit(A) = -4.1241\n",
            "\n",
            "Top-20 next-token continuations (by probability):\n",
            "01. id=  373 tok=        ' was'  prob=0.1634  logit=-79.4807\n",
            "02. id= 5437 tok=      ' Jones'  prob=0.1396  logit=-79.6386\n",
            "03. id=  338 tok=          \"'s\"  prob=0.0806  logit=-80.1876\n",
            "04. id=  550 tok=        ' had'  prob=0.0491  logit=-80.6838\n",
            "05. id=  318 tok=         ' is'  prob=0.0229  logit=-81.4471\n",
            "06. id=  290 tok=        ' and'  prob=0.0227  logit=-81.4569\n",
            "07. id=   11 tok=           ','  prob=0.0222  logit=-81.4781\n",
            "08. id=  531 tok=       ' said'  prob=0.0134  logit=-81.9811\n",
            "09. id=  468 tok=        ' has'  prob=0.0120  logit=-82.0913\n",
            "10. id=  635 tok=       ' also'  prob=0.0117  logit=-82.1161\n",
            "11. id= 1625 tok=       ' came'  prob=0.0091  logit=-82.3733\n",
            "12. id= 1297 tok=       ' told'  prob=0.0084  logit=-82.4499\n",
            "13. id= 1422 tok=       ' didn'  prob=0.0070  logit=-82.6320\n",
            "14. id= 2993 tok=       ' knew'  prob=0.0067  logit=-82.6713\n",
            "15. id= 1816 tok=       ' went'  prob=0.0061  logit=-82.7684\n",
            "16. id=  561 tok=      ' would'  prob=0.0061  logit=-82.7738\n",
            "17. id= 3111 tok=     ' worked'  prob=0.0055  logit=-82.8806\n",
            "18. id=  750 tok=        ' did'  prob=0.0054  logit=-82.8953\n",
            "19. id= 2486 tok=      ' Obama'  prob=0.0053  logit=-82.9094\n",
            "20. id= 2492 tok=       ' wasn'  prob=0.0050  logit=-82.9685\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "=== CORRUPTED baseline (NO patch) ===\n",
            "Prompt (seq_len=11): Michelle Smith was a top-notch student. Michelle\n",
            "\n",
            "Metric tokens:\n",
            "  Token A (clean-consistent):   ' Jones'  id=5437  logit=-88.4841\n",
            "  Token B (corrupt-consistent): ' Smith'  id=4176  logit=-82.8279\n",
            "  score = logit(B) - logit(A) = 5.6562\n",
            "\n",
            "Top-20 next-token continuations (by probability):\n",
            "01. id=  373 tok=        ' was'  prob=0.1630  logit=-82.6385\n",
            "02. id= 4176 tok=      ' Smith'  prob=0.1349  logit=-82.8279\n",
            "03. id=  338 tok=          \"'s\"  prob=0.0858  logit=-83.2802\n",
            "04. id=  550 tok=        ' had'  prob=0.0627  logit=-83.5946\n",
            "05. id=  318 tok=         ' is'  prob=0.0256  logit=-84.4906\n",
            "06. id=   11 tok=           ','  prob=0.0255  logit=-84.4927\n",
            "07. id=  290 tok=        ' and'  prob=0.0227  logit=-84.6085\n",
            "08. id=  531 tok=       ' said'  prob=0.0160  logit=-84.9604\n",
            "09. id=  468 tok=        ' has'  prob=0.0134  logit=-85.1377\n",
            "10. id= 7817 tok=     ' taught'  prob=0.0111  logit=-85.3298\n",
            "11. id=  635 tok=       ' also'  prob=0.0093  logit=-85.5020\n",
            "12. id= 3111 tok=     ' worked'  prob=0.0092  logit=-85.5162\n",
            "13. id= 1625 tok=       ' came'  prob=0.0079  logit=-85.6695\n",
            "14. id=  561 tok=      ' would'  prob=0.0074  logit=-85.7352\n",
            "15. id= 1297 tok=       ' told'  prob=0.0073  logit=-85.7472\n",
            "16. id= 2993 tok=       ' knew'  prob=0.0066  logit=-85.8450\n",
            "17. id= 1718 tok=       ' took'  prob=0.0063  logit=-85.8929\n",
            "18. id= 1422 tok=       ' didn'  prob=0.0059  logit=-85.9512\n",
            "19. id= 9141 tok=   ' attended'  prob=0.0056  logit=-86.0030\n",
            "20. id=  750 tok=        ' did'  prob=0.0051  logit=-86.0983\n",
            "\n",
            "==========================================================================================\n",
            "=== Metric sanity check (expected shift toward corrupted) ===\n",
            "clean score   = -4.1241\n",
            "corrupt score = 5.6562\n",
            "delta (corrupt - clean) = 9.7803\n",
            "\n",
            " Section 8 baseline behavior looks correct.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "from baseline_utils import (\n",
        "    run_clean_baseline,\n",
        "    run_corrupt_baseline,\n",
        "    format_topk_table,\n",
        ")\n",
        "\n",
        "def main() -> None:\n",
        "    set_seed(3407)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "    TOKEN_A = \" Jones\"   # clean-consistent continuation\n",
        "    TOKEN_B = \" Smith\"   # corrupt-consistent continuation\n",
        "\n",
        "    clean_res = run_clean_baseline(\n",
        "        model, bpe, CLEAN_TEXT, TOKEN_A, TOKEN_B,\n",
        "        device=device, top_k=20, overwrite_cache=True\n",
        "    )\n",
        "\n",
        "    assert model.clean_activations is not None, \"Clean cache was not created.\"\n",
        "    assert model.clean_activation_meta is not None, \"Clean cache meta was not created.\"\n",
        "    print(\"Clean cache meta:\", model.clean_activation_meta)\n",
        "\n",
        "    # Snapshot cache to verify it doesn't get overwritten by corrupted baseline\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    corrupt_res = run_corrupt_baseline(\n",
        "        model, bpe, CORRUPT_TEXT, TOKEN_A, TOKEN_B,\n",
        "        device=device, top_k=20\n",
        "    )\n",
        "\n",
        "    # Verify cache unchanged\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p]), \"Clean cache was mutated by corrupt baseline!\"\n",
        "\n",
        "    print(\"\\n=== CLEAN baseline ===\")\n",
        "    print(format_topk_table(clean_res, max_rows=20))\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 90 + \"\\n\")\n",
        "\n",
        "    print(\"=== CORRUPTED baseline (NO patch) ===\")\n",
        "    print(format_topk_table(corrupt_res, max_rows=20))\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 90)\n",
        "    print(\"=== Metric sanity check (expected shift toward corrupted) ===\")\n",
        "    print(f\"clean score   = {clean_res.score_logit_diff:.4f}\")\n",
        "    print(f\"corrupt score = {corrupt_res.score_logit_diff:.4f}\")\n",
        "    print(f\"delta (corrupt - clean) = {corrupt_res.score_logit_diff - clean_res.score_logit_diff:.4f}\")\n",
        "\n",
        "    assert corrupt_res.score_logit_diff > clean_res.score_logit_diff, (\n",
        "        \"Expected corrupted score to be larger than clean score for logit(B)-logit(A).\"\n",
        "    )\n",
        "    print(\"\\n Section 8 baseline behavior looks correct.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 93%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m77 passed\u001b[0m\u001b[32m in 30.64s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing patching_sweep.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile patching_sweep.py\n",
        "\"\"\"\n",
        "Full Activation Patching Sweep (Layer  Position Difference Matrix)\n",
        "\n",
        "Goal:\n",
        "- For each layer L and token position P:\n",
        "  run corrupted input with a patch at (L,P),\n",
        "  compute the scalar metric: logit(token_B) - logit(token_A)\n",
        "  from last-position logits,\n",
        "  store it in matrix[L, P].\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Sequence, Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# Small helpers\n",
        "def _infer_device(model: torch.nn.Module) -> torch.device:\n",
        "    try:\n",
        "        return next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def single_token_id(bpe, token_str: str) -> int:\n",
        "    \"\"\"\n",
        "    Convert token_str into EXACTLY one BPE token id.\n",
        "    Raises ValueError if it tokenizes into multiple tokens.\n",
        "\n",
        "    Important: For GPT-2 BPE, mid-sequence tokens often need a leading space, e.g. \" Jones\".\n",
        "    \"\"\"\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(\n",
        "            f\"Target token string must map to exactly 1 BPE token. \"\n",
        "            f\"Got {len(ids)} tokens for {repr(token_str)}: {ids}\"\n",
        "        )\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "def logit_diff_from_last_logits(last_logits_1d: torch.Tensor, *, token_a_id: int, token_b_id: int) -> float:\n",
        "    \"\"\"\n",
        "    last_logits_1d: shape (vocab_size,)\n",
        "    returns score = logit(B) - logit(A)\n",
        "    \"\"\"\n",
        "    a = float(last_logits_1d[token_a_id])\n",
        "    b = float(last_logits_1d[token_b_id])\n",
        "    return b - a\n",
        "\n",
        "\n",
        "# Outputs\n",
        "@dataclass(frozen=True)\n",
        "class SweepResult:\n",
        "    \"\"\"\n",
        "    matrix shape: (n_layers, seq_len) on CPU (float32)\n",
        "    \"\"\"\n",
        "    matrix: torch.Tensor\n",
        "    n_layers: int\n",
        "    seq_len: int\n",
        "    token_a_str: str\n",
        "    token_b_str: str\n",
        "    token_a_id: int\n",
        "    token_b_id: int\n",
        "    clean_score: float\n",
        "    corrupt_score: float\n",
        "    clean_text: str\n",
        "    corrupt_text: str\n",
        "\n",
        "\n",
        "# Core sweep (tensor-level) - best for tests\n",
        "@torch.no_grad()\n",
        "def sweep_from_ids(\n",
        "    model,\n",
        "    idx_corrupt: torch.LongTensor,\n",
        "    *,\n",
        "    token_a_id: int,\n",
        "    token_b_id: int,\n",
        "    layers: Optional[Sequence[int]] = None,\n",
        "    positions: Optional[Sequence[int]] = None,\n",
        "    progress: bool = False,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute the full patching matrix given:\n",
        "    - model already has clean activations cached (model.clean_activations != None)\n",
        "    - idx_corrupt is token ids tensor shape (1, T)\n",
        "\n",
        "    Returns:\n",
        "    - matrix: torch.Tensor on CPU, shape (n_layers, T), dtype float32\n",
        "    \"\"\"\n",
        "    if getattr(model, \"clean_activations\", None) is None:\n",
        "        raise RuntimeError(\"No clean cache found. Run a clean pass with cache_activations=True first.\")\n",
        "\n",
        "    if idx_corrupt.ndim != 2 or idx_corrupt.shape[0] != 1:\n",
        "        raise ValueError(f\"Expected idx_corrupt shape (1,T). Got {tuple(idx_corrupt.shape)}\")\n",
        "\n",
        "    device = _infer_device(model)\n",
        "    idx_corrupt = idx_corrupt.to(device)\n",
        "\n",
        "    n_layers = len(model.transformer.h)\n",
        "    T = int(idx_corrupt.shape[1])\n",
        "\n",
        "    layers = list(range(n_layers)) if layers is None else list(layers)\n",
        "    positions = list(range(T)) if positions is None else list(positions)\n",
        "\n",
        "    it = [(L, P) for L in layers for P in positions]\n",
        "    if progress:\n",
        "        try:\n",
        "            from tqdm import tqdm  # type: ignore\n",
        "            it = tqdm(it, desc=\"patching sweep\", total=len(it))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    mat = torch.empty((len(layers), len(positions)), dtype=torch.float32, device=\"cpu\")\n",
        "\n",
        "    layer_index = {L: i for i, L in enumerate(layers)}\n",
        "    pos_index = {P: j for j, P in enumerate(positions)}\n",
        "\n",
        "    for L, P in it:\n",
        "        _logits, _loss = model(idx_corrupt, layer_to_patch=int(L), position_to_patch=int(P))\n",
        "        if model.last_logits is None:\n",
        "            raise RuntimeError(\"model.last_logits was not set. Ensure forward() stores last_logits.\")\n",
        "        last = model.last_logits[0].detach()  # (vocab,)\n",
        "        score = logit_diff_from_last_logits(last, token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "        mat[layer_index[L], pos_index[P]] = float(score)\n",
        "\n",
        "    return mat\n",
        "\n",
        "@torch.no_grad()\n",
        "def build_patching_sweep(\n",
        "    model,\n",
        "    bpe,\n",
        "    *,\n",
        "    clean_text: str,\n",
        "    corrupt_text: str,\n",
        "    token_a_str: str,\n",
        "    token_b_str: str,\n",
        "    overwrite_cache: bool = True,\n",
        "    progress: bool = True,\n",
        ") -> SweepResult:\n",
        "    \"\"\"\n",
        "    Full pipeline:\n",
        "    1) tokenize clean/corrupt and enforce equal seq_len\n",
        "    2) cache clean activations (clean run)\n",
        "    3) compute baseline clean score and corrupted score\n",
        "    4) sweep all (layer, position) patches on corrupted prompt\n",
        "    5) return SweepResult with matrix shape (n_layers, seq_len)\n",
        "\n",
        "    Metric:\n",
        "      score = logit(Token B) - logit(Token A), using last-position logits.\n",
        "    \"\"\"\n",
        "    device = _infer_device(model)\n",
        "\n",
        "    idx_clean = bpe(clean_text).to(device)      # (1, T)\n",
        "    idx_corrupt = bpe(corrupt_text).to(device)  # (1, T)\n",
        "\n",
        "    if idx_clean.shape != idx_corrupt.shape:\n",
        "        raise ValueError(\n",
        "            f\"Clean/Corrupt token length mismatch: clean={tuple(idx_clean.shape)}, corrupt={tuple(idx_corrupt.shape)}. \"\n",
        "            \"You MUST make both prompts have the same number of BPE tokens.\"\n",
        "        )\n",
        "\n",
        "    T = int(idx_clean.shape[1])\n",
        "    n_layers = len(model.transformer.h)\n",
        "\n",
        "    # Token ids for metric\n",
        "    token_a_id = single_token_id(bpe, token_a_str)\n",
        "    token_b_id = single_token_id(bpe, token_b_str)\n",
        "\n",
        "    # CLEAN run: cache activations + baseline score\n",
        "    _logits, _loss = model(idx_clean, cache_activations=True, overwrite_cache=overwrite_cache)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits missing after clean run.\")\n",
        "    clean_last = model.last_logits[0].detach()\n",
        "    clean_score = logit_diff_from_last_logits(clean_last, token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "\n",
        "    # CORRUPTED baseline (no patch)\n",
        "    _logits, _loss = model(idx_corrupt)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits missing after corrupt baseline run.\")\n",
        "    corrupt_last = model.last_logits[0].detach()\n",
        "    corrupt_score = logit_diff_from_last_logits(corrupt_last, token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "\n",
        "    # FULL sweep on corrupted ids (requires clean cache)\n",
        "    matrix = sweep_from_ids(\n",
        "        model,\n",
        "        idx_corrupt,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        layers=list(range(n_layers)),\n",
        "        positions=list(range(T)),\n",
        "        progress=progress,\n",
        "    )\n",
        "\n",
        "    return SweepResult(\n",
        "        matrix=matrix,\n",
        "        n_layers=n_layers,\n",
        "        seq_len=T,\n",
        "        token_a_str=token_a_str,\n",
        "        token_b_str=token_b_str,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        clean_score=float(clean_score),\n",
        "        corrupt_score=float(corrupt_score),\n",
        "        clean_text=clean_text,\n",
        "        corrupt_text=corrupt_text,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting section9_sweep_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile section9_sweep_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "from patching_sweep import build_patching_sweep\n",
        "\n",
        "from section10_visualization import (\n",
        "    HeatmapMeta,\n",
        "    decode_prompt_token_labels,\n",
        "    plot_logit_diff_heatmap,\n",
        "    save_figure_publication_quality,\n",
        "    save_heatmap_artifacts,\n",
        ")\n",
        "\n",
        "import tokenization_protocol as tp\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    set_seed(3407)\n",
        "\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    CLEAN_TEXT = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "\n",
        "    TOKEN_A = \" Jones\"  # clean-consistent\n",
        "    TOKEN_B = \" Smith\"  # corrupt-consistent\n",
        "\n",
        "    # Load model + tokenizer\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    # Enforce the constraint: same length AND exactly one differing BPE token\n",
        "    comp = tp.validate_pair(\n",
        "        bpe=bpe,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        require_same_length=True,\n",
        "        require_one_token_diff=True,\n",
        "    )\n",
        "    print(tp.describe_pair(comp))\n",
        "    print(\"Changed token position:\", comp.diff_positions[0])\n",
        "\n",
        "    # Build the sweep matrix (Section 9)\n",
        "    res = build_patching_sweep(\n",
        "        model,\n",
        "        bpe,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        overwrite_cache=True,\n",
        "        progress=True,\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Baseline metric sanity ===\")\n",
        "    print(f\"clean score   = {res.clean_score:.4f}\")\n",
        "    print(f\"corrupt score = {res.corrupt_score:.4f}\")\n",
        "    print(f\"delta (corrupt - clean) = {res.corrupt_score - res.clean_score:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Matrix ===\")\n",
        "    print(\"shape:\", tuple(res.matrix.shape), \"(n_layers, seq_len)\")\n",
        "    print(\"n_layers:\", res.n_layers, \"seq_len:\", res.seq_len)\n",
        "    print(\"dtype:\", res.matrix.dtype, \"device:\", res.matrix.device)\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"matrix\": res.matrix,\n",
        "            \"n_layers\": res.n_layers,\n",
        "            \"seq_len\": res.seq_len,\n",
        "            \"token_a\": res.token_a_str,\n",
        "            \"token_b\": res.token_b_str,\n",
        "            \"token_a_id\": res.token_a_id,\n",
        "            \"token_b_id\": res.token_b_id,\n",
        "            \"clean_score\": res.clean_score,\n",
        "            \"corrupt_score\": res.corrupt_score,\n",
        "            \"clean_text\": res.clean_text,\n",
        "            \"corrupt_text\": res.corrupt_text,\n",
        "        },\n",
        "        \"section9_diff_matrix.pt\",\n",
        "    )\n",
        "    print(\"\\nSaved: section9_diff_matrix.pt\")\n",
        "\n",
        "    out_dir = Path(\"artifacts/section9_and_10\")\n",
        "    token_labels = decode_prompt_token_labels(bpe, CLEAN_TEXT)\n",
        "    metric_title = f\"Logit difference heatmap: logit({repr(TOKEN_B)})  logit({repr(TOKEN_A)})\"\n",
        "\n",
        "    meta = HeatmapMeta(\n",
        "        metric_title=metric_title,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        n_layers=res.n_layers,\n",
        "        seq_len=res.seq_len,\n",
        "        token_labels=token_labels,\n",
        "    )\n",
        "\n",
        "    save_heatmap_artifacts(out_dir=out_dir, matrix=res.matrix, meta=meta)\n",
        "\n",
        "    fig, ax = plot_logit_diff_heatmap(\n",
        "        res.matrix,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=metric_title,\n",
        "        show_token_strings=True,\n",
        "        center_zero=True,\n",
        "        include_pos_in_label=True,\n",
        "    )\n",
        "\n",
        "    save_figure_publication_quality(\n",
        "        fig,\n",
        "        out_basepath=out_dir / \"heatmap_logit_diff\",\n",
        "        formats=(\"png\", \"pdf\"),\n",
        "        dpi=300,\n",
        "    )\n",
        "    print(\"Saved Section 10 heatmap to:\", out_dir.resolve())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "=== Pair summary ===\n",
            "Clean tokens:   11\n",
            "Corrupt tokens: 11\n",
            "Same length?    True\n",
            "Diff count:     1\n",
            "Diff positions: [1]\n",
            "One-token diff? True\n",
            "\n",
            "Changed token position: 1\n",
            "patching sweep: 100%|| 132/132 [00:03<00:00, 41.27it/s]\n",
            "\n",
            "=== Baseline metric sanity ===\n",
            "clean score   = -4.1241\n",
            "corrupt score = 5.6562\n",
            "delta (corrupt - clean) = 9.7803\n",
            "\n",
            "=== Matrix ===\n",
            "shape: (12, 11) (n_layers, seq_len)\n",
            "n_layers: 12 seq_len: 11\n",
            "dtype: torch.float32 device: cpu\n",
            "\n",
            "Saved: section9_diff_matrix.pt\n",
            "Saved Section 10 heatmap to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/section9_and_10\n"
          ]
        }
      ],
      "source": [
        "!python section9_sweep_driver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_all_sections.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_all_sections.py\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "\n",
        "import baseline_utils as bu\n",
        "import patching_sweep as ps\n",
        "\n",
        "\n",
        "# Dummy tokenizer (FAST, no downloads)\n",
        "class DummyTokenizer:\n",
        "    \"\"\"\n",
        "    Minimal stand-in for BPETokenizer that supports:\n",
        "    - __call__(text) -> tensor(1,T)\n",
        "    - decode(tensor([id])) -> string\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        # ids for prompt chars\n",
        "        self.map = {\n",
        "            \"a\": 1, \"b\": 2, \"c\": 3, \"x\": 4, \"y\": 5, \"z\": 6,\n",
        "            # ids for \"tokens\" A/B (single-token strings)\n",
        "            \" A\": 7,\n",
        "            \" B\": 8,\n",
        "        }\n",
        "        self.inv = {v: k for k, v in self.map.items()}\n",
        "\n",
        "    def __call__(self, s: str):\n",
        "        if s in self.map:\n",
        "            ids = [self.map[s]]\n",
        "        else:\n",
        "            ids = [self.map[ch] for ch in s]  # tokenize per char for prompt\n",
        "        return torch.tensor([ids], dtype=torch.long)\n",
        "\n",
        "    def decode(self, t: torch.Tensor) -> str:\n",
        "        ids = t.flatten().tolist()\n",
        "        return \"\".join(self.inv.get(int(i), f\"<{int(i)}>\") for i in ids)\n",
        "\n",
        "\n",
        "def _make_tiny_gpt(vocab_size=80, block_size=32):\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = vocab_size\n",
        "    cfg.block_size = block_size\n",
        "    return GPT(cfg).eval()\n",
        "\n",
        "\n",
        "# Section 8 baseline utils (fast)\n",
        "def test_single_token_id_accepts_single_and_rejects_multi():\n",
        "    bpe = DummyTokenizer()\n",
        "    assert bu.single_token_id(bpe, \" A\") == 7\n",
        "    assert bu.single_token_id(bpe, \" B\") == 8\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        _ = bu.single_token_id(bpe, \"ab\")  # multi-token under DummyTokenizer\n",
        "\n",
        "\n",
        "def test_clean_baseline_caches_activations_and_sets_last_logits():\n",
        "    model = _make_tiny_gpt(vocab_size=60, block_size=16)\n",
        "    bpe = DummyTokenizer()\n",
        "\n",
        "    res = bu.run_clean_baseline(\n",
        "        model,\n",
        "        bpe,\n",
        "        clean_text=\"abc\",\n",
        "        token_a_str=\" A\",\n",
        "        token_b_str=\" B\",\n",
        "        device=\"cpu\",\n",
        "        top_k=5,\n",
        "        overwrite_cache=True,\n",
        "    )\n",
        "\n",
        "    assert model.clean_activations is not None\n",
        "    assert model.last_logits is not None\n",
        "    assert isinstance(res.score_logit_diff, float)\n",
        "\n",
        "\n",
        "def test_corrupt_baseline_does_not_overwrite_clean_cache():\n",
        "    model = _make_tiny_gpt(vocab_size=60, block_size=16)\n",
        "    bpe = DummyTokenizer()\n",
        "\n",
        "    _ = bu.run_clean_baseline(model, bpe, \"abc\", \" A\", \" B\", device=\"cpu\", top_k=5, overwrite_cache=True)\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    _ = bu.run_corrupt_baseline(model, bpe, \"abx\", \" A\", \" B\", device=\"cpu\", top_k=5)\n",
        "\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(len(snap[L])):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "\n",
        "# Section 9 sweep tests (fast, no downloads)\n",
        "def test_section9_sweep_matrix_shape_and_dtype():\n",
        "    model = _make_tiny_gpt(vocab_size=100, block_size=32)\n",
        "\n",
        "    T = 10\n",
        "    clean = torch.randint(0, 100, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, 3] = (corrupt[0, 3] + 1) % 100  # minimal corruption, same length\n",
        "\n",
        "    # cache clean activations\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # sweep (token ids arbitrary for test)\n",
        "    mat = ps.sweep_from_ids(model, corrupt, token_a_id=1, token_b_id=2, progress=False)\n",
        "\n",
        "    assert tuple(mat.shape) == (len(model.transformer.h), T)\n",
        "    assert mat.dtype == torch.float32\n",
        "    assert mat.device.type == \"cpu\"\n",
        "    assert torch.isfinite(mat).all()\n",
        "\n",
        "\n",
        "def test_section9_sweep_does_not_mutate_clean_cache():\n",
        "    model = _make_tiny_gpt(vocab_size=100, block_size=32)\n",
        "\n",
        "    T = 8\n",
        "    clean = torch.randint(0, 100, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, 2] = (corrupt[0, 2] + 1) % 100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    snap = [[t.clone() for t in layer] for layer in model.clean_activations]\n",
        "\n",
        "    _ = ps.sweep_from_ids(model, corrupt, token_a_id=1, token_b_id=2, progress=False)\n",
        "\n",
        "    for L in range(len(snap)):\n",
        "        for p in range(T):\n",
        "            assert torch.equal(model.clean_activations[L][p], snap[L][p])\n",
        "\n",
        "\n",
        "def test_section9_sweep_matches_direct_single_call():\n",
        "    model = _make_tiny_gpt(vocab_size=120, block_size=32)\n",
        "\n",
        "    T = 9\n",
        "    clean = torch.randint(0, 120, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, 4] = (corrupt[0, 4] + 7) % 120\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    token_a_id, token_b_id = 5, 6\n",
        "\n",
        "    mat = ps.sweep_from_ids(model, corrupt, token_a_id=token_a_id, token_b_id=token_b_id, progress=False)\n",
        "\n",
        "    # pick one coordinate and verify equality vs direct model call\n",
        "    L, P = 0, 4\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, layer_to_patch=L, position_to_patch=P)\n",
        "        last = model.last_logits[0].detach()\n",
        "        direct = ps.logit_diff_from_last_logits(last, token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "\n",
        "    assert abs(float(mat[L, P]) - float(direct)) < 1e-6\n",
        "\n",
        "\n",
        "# Optional SLOW integration with real GPT-2 (skips if unavailable)\n",
        "@pytest.mark.slow\n",
        "def test_section9_real_gpt2_sweep_shape_if_available():\n",
        "    try:\n",
        "        from mingpt.bpe import BPETokenizer\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"BPETokenizer unavailable: {e}\")\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    try:\n",
        "        model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "        bpe = BPETokenizer()\n",
        "    except Exception as e:\n",
        "        pytest.skip(f\"GPT-2 weights/tokenizer unavailable: {e}\")\n",
        "\n",
        "    clean = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    corr  = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "    A = \" Jones\"\n",
        "    B = \" Smith\"\n",
        "\n",
        "    res = ps.build_patching_sweep(\n",
        "        model,\n",
        "        bpe,\n",
        "        clean_text=clean,\n",
        "        corrupt_text=corr,\n",
        "        token_a_str=A,\n",
        "        token_b_str=B,\n",
        "        overwrite_cache=True,\n",
        "        progress=False,\n",
        "    )\n",
        "\n",
        "    assert tuple(res.matrix.shape) == (12, res.seq_len)\n",
        "    assert torch.isfinite(res.matrix).all()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 85%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                             [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m84 passed\u001b[0m\u001b[32m in 36.96s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting section10_visualization.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile section10_visualization.py\n",
        "\"\"\"\n",
        "Visualization: Heatmap Generation and Presentation Standards\n",
        "\n",
        "This module:\n",
        "- plots a (n_layers, seq_len) matrix as a heatmap using matplotlib (matshow)\n",
        "- labels axes (x: token positions or decoded token strings; y: layer indices)\n",
        "- adds colorbar + title\n",
        "- saves publication-quality figures (PNG + PDF by default)\n",
        "- optionally saves/loads matrix + metadata to/from disk for reproducibility\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass, asdict\n",
        "from pathlib import Path\n",
        "from typing import Any, List, Optional, Sequence, Tuple, Union\n",
        "\n",
        "import json\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "\n",
        "\n",
        "ArrayLike = Union[torch.Tensor, Any]  # keep flexible (torch preferred)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class HeatmapMeta:\n",
        "    metric_title: str\n",
        "    clean_text: str\n",
        "    corrupt_text: str\n",
        "    token_a_str: str\n",
        "    token_b_str: str\n",
        "    n_layers: int\n",
        "    seq_len: int\n",
        "    token_labels: Optional[List[str]] = None  # per-position decoded tokens (optional)\n",
        "\n",
        "\n",
        "def _to_2d_cpu_float(matrix: ArrayLike) -> torch.Tensor:\n",
        "    if isinstance(matrix, torch.Tensor):\n",
        "        m = matrix.detach().to(\"cpu\")\n",
        "    else:\n",
        "        m = torch.tensor(matrix)\n",
        "    if m.ndim != 2:\n",
        "        raise ValueError(f\"Expected a 2D matrix, got shape {tuple(m.shape)}\")\n",
        "    return m.to(dtype=torch.float32)\n",
        "\n",
        "\n",
        "def _tick_positions(total: int, max_ticks: int = 40, *, max_xticks: Optional[int] = None) -> List[int]:\n",
        "    \"\"\"\n",
        "    Returns a list of tick indices for a length-`total` axis.\n",
        "\n",
        "    Accepts both:\n",
        "      - max_ticks (preferred)\n",
        "      - max_xticks (backwards/alternate name)\n",
        "    \"\"\"\n",
        "    if max_xticks is not None:\n",
        "        max_ticks = int(max_xticks)\n",
        "\n",
        "    if total <= 0:\n",
        "        return []\n",
        "    if max_ticks <= 0:\n",
        "        return list(range(total))\n",
        "    if total <= max_ticks:\n",
        "        return list(range(total))\n",
        "\n",
        "    stride = int(math.ceil(total / max_ticks))\n",
        "    return list(range(0, total, stride))\n",
        "\n",
        "\n",
        "def decode_prompt_token_labels(bpe, text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Returns per-token decoded strings for the FULL prompt.\n",
        "    This is exactly what you want for x-axis labels (optional).\n",
        "    \"\"\"\n",
        "    ids_1d = bpe(text)[0].tolist()\n",
        "    labels: List[str] = []\n",
        "    for tid in ids_1d:\n",
        "        tok = bpe.decode(torch.tensor([int(tid)], dtype=torch.long))\n",
        "        labels.append(tok)\n",
        "    return labels\n",
        "\n",
        "\n",
        "def plot_logit_diff_heatmap(\n",
        "    matrix: ArrayLike,\n",
        "    *,\n",
        "    token_labels: Optional[Sequence[str]] = None,\n",
        "    metric_title: str = \"Logit difference heatmap\",\n",
        "    xlabel: str = \"Token position\",\n",
        "    ylabel: str = \"Layer\",\n",
        "    show_token_strings: bool = True,\n",
        "    max_xticks: int = 40,\n",
        "    max_token_label_len: int = 18,\n",
        "    include_pos_in_label: bool = True,\n",
        "    center_zero: bool = True,\n",
        "    vmin: Optional[float] = None,\n",
        "    vmax: Optional[float] = None,\n",
        "    figsize: Optional[Tuple[float, float]] = None,\n",
        ") -> Tuple[\"plt.Figure\", \"plt.Axes\"]:\n",
        "    \"\"\"\n",
        "    Plots the matrix using matshow.\n",
        "\n",
        "    Expected matrix shape: (n_layers, seq_len)\n",
        "      - y-axis: layer index 0..n_layers-1\n",
        "      - x-axis: token positions 0..seq_len-1\n",
        "    \"\"\"\n",
        "    m = _to_2d_cpu_float(matrix)\n",
        "    n_layers, seq_len = int(m.shape[0]), int(m.shape[1])\n",
        "\n",
        "    if figsize is None:\n",
        "        w = max(7.5, min(16.0, 0.35 * seq_len + 5.0))\n",
        "        h = max(5.0, min(10.0, 0.28 * n_layers + 4.0))\n",
        "        figsize = (w, h)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    norm = None\n",
        "    if center_zero:\n",
        "        data_min = float(m.min()) if vmin is None else float(vmin)\n",
        "        data_max = float(m.max()) if vmax is None else float(vmax)\n",
        "\n",
        "        # If data doesn't straddle 0, make a symmetric range around 0\n",
        "        max_abs = max(abs(data_min), abs(data_max))\n",
        "        if max_abs == 0.0:\n",
        "            max_abs = 1.0  # avoid degenerate norm\n",
        "\n",
        "        _vmin, _vmax = -max_abs, max_abs\n",
        "        norm = TwoSlopeNorm(vcenter=0.0, vmin=_vmin, vmax=_vmax)\n",
        "\n",
        "    im = ax.matshow(m.numpy(), norm=norm, vmin=None if norm else vmin, vmax=None if norm else vmax)\n",
        "\n",
        "    cbar = fig.colorbar(im, ax=ax)\n",
        "    cbar.set_label(\"logit(Token B)  logit(Token A)\", rotation=90)\n",
        "\n",
        "    ax.set_title(metric_title, pad=18)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "\n",
        "    xt = _tick_positions(seq_len, max_ticks=max_xticks)\n",
        "    yt = list(range(n_layers))\n",
        "\n",
        "    ax.set_xticks(xt)\n",
        "    ax.set_yticks(yt)\n",
        "    ax.set_yticklabels([str(i) for i in yt])\n",
        "\n",
        "    if show_token_strings and token_labels is not None and len(token_labels) == seq_len:\n",
        "        labels_out: List[str] = []\n",
        "        for i in xt:\n",
        "            tok = str(token_labels[i])\n",
        "            tok_short = tok if len(tok) <= max_token_label_len else (tok[: max_token_label_len - 3] + \"...\")\n",
        "            labels_out.append(f\"{i}:{tok_short}\" if include_pos_in_label else tok_short)\n",
        "        ax.set_xticklabels(labels_out, rotation=90)\n",
        "    else:\n",
        "        ax.set_xticklabels([str(i) for i in xt], rotation=0)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def save_figure_publication_quality(\n",
        "    fig: \"plt.Figure\",\n",
        "    *,\n",
        "    out_basepath: Union[str, Path],\n",
        "    formats: Sequence[str] = (\"png\", \"pdf\"),\n",
        "    dpi: int = 300,\n",
        "    transparent: bool = False,\n",
        "    close: bool = True,\n",
        ") -> List[Path]:\n",
        "    \"\"\"\n",
        "    Saves the figure to out_basepath.{fmt} for each fmt.\n",
        "    - PNG: high dpi raster\n",
        "    - PDF: vector-friendly for reports\n",
        "    \"\"\"\n",
        "    out_base = Path(out_basepath)\n",
        "    out_base.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    saved: List[Path] = []\n",
        "    for fmt in formats:\n",
        "        p = out_base.with_suffix(\".\" + fmt.lower())\n",
        "        fig.savefig(p, dpi=dpi, bbox_inches=\"tight\", transparent=transparent)\n",
        "        saved.append(p)\n",
        "\n",
        "    if close:\n",
        "        plt.close(fig)\n",
        "\n",
        "    return saved\n",
        "\n",
        "\n",
        "def save_heatmap_artifacts(\n",
        "    *,\n",
        "    out_dir: Union[str, Path],\n",
        "    matrix: ArrayLike,\n",
        "    meta: HeatmapMeta,\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Saves:\n",
        "      - matrix.pt  (torch tensor, CPU float32)\n",
        "      - meta.json  (json)\n",
        "    \"\"\"\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    m = _to_2d_cpu_float(matrix)\n",
        "    torch.save(m, out_dir / \"matrix.pt\")\n",
        "\n",
        "    with (out_dir / \"meta.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(asdict(meta), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return out_dir\n",
        "\n",
        "\n",
        "def load_heatmap_artifacts(out_dir: Union[str, Path]) -> Tuple[torch.Tensor, HeatmapMeta]:\n",
        "    out_dir = Path(out_dir)\n",
        "    m = torch.load(out_dir / \"matrix.pt\", map_location=\"cpu\")\n",
        "\n",
        "    with (out_dir / \"meta.json\").open(\"r\", encoding=\"utf-8\") as f:\n",
        "        d = json.load(f)\n",
        "\n",
        "    meta = HeatmapMeta(**d)\n",
        "    return m, meta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting section10_visualize_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile section10_visualize_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "from baseline_utils import run_clean_baseline, run_corrupt_baseline\n",
        "\n",
        "from section10_visualization import (\n",
        "    HeatmapMeta,\n",
        "    decode_prompt_token_labels,\n",
        "    plot_logit_diff_heatmap,\n",
        "    save_figure_publication_quality,\n",
        "    save_heatmap_artifacts,\n",
        ")\n",
        "\n",
        "DEFAULT_SAVED = \"section9_diff_matrix.pt\"\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--out_dir\", type=str, required=True)\n",
        "    p.add_argument(\"--saved\", type=str, default=DEFAULT_SAVED, help=\"Path to section9 saved matrix (.pt)\")\n",
        "    p.add_argument(\"--show_token_strs\", action=\"store_true\", help=\"Label x-axis with decoded token strings\")\n",
        "    p.add_argument(\"--also_delta\", action=\"store_true\", help=\"Also save delta heatmap: score(L,P) - corrupt_score\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "def _safe_token_label(tok: str, max_len: int = 18) -> str:\n",
        "    \"\"\"\n",
        "    Make token strings readable in tick labels:\n",
        "    - show leading space explicitly as ''\n",
        "    - escape newlines\n",
        "    - truncate long labels\n",
        "    \"\"\"\n",
        "    tok = tok.replace(\"\\n\", \"\\\\n\")\n",
        "    if tok.startswith(\" \"):\n",
        "        tok = \"\" + tok[1:]\n",
        "    if len(tok) > max_len:\n",
        "        tok = tok[: max_len - 3] + \"...\"\n",
        "    return tok\n",
        "\n",
        "\n",
        "def _load_saved_matrix(path: Path) -> Tuple[torch.Tensor, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Loads either:\n",
        "      - dict with 'matrix' + metadata\n",
        "      - raw tensor\n",
        "    Returns (matrix_float32_cpu, meta_dict)\n",
        "    \"\"\"\n",
        "    obj = torch.load(str(path), map_location=\"cpu\")\n",
        "    meta: Dict[str, Any] = {}\n",
        "\n",
        "    if isinstance(obj, dict) and \"matrix\" in obj:\n",
        "        matrix = obj[\"matrix\"]\n",
        "        meta = dict(obj)\n",
        "    elif torch.is_tensor(obj):\n",
        "        matrix = obj\n",
        "        meta = {}\n",
        "    else:\n",
        "        raise TypeError(f\"Unexpected save format in {path}: {type(obj)}\")\n",
        "\n",
        "    if not torch.is_tensor(matrix) or matrix.ndim != 2:\n",
        "        raise ValueError(f\"Expected a 2D tensor under key 'matrix'. Got: {type(matrix)} shape={getattr(matrix, 'shape', None)}\")\n",
        "\n",
        "    return matrix.detach().to(dtype=torch.float32, device=\"cpu\"), meta\n",
        "\n",
        "\n",
        "def _tick_positions(total: int, max_ticks: int = 40) -> list[int]:\n",
        "    if total <= 0:\n",
        "        return []\n",
        "    if total <= max_ticks:\n",
        "        return list(range(total))\n",
        "    stride = int((total + max_ticks - 1) // max_ticks)\n",
        "    return list(range(0, total, stride))\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    args = parse_args()\n",
        "    out_dir = Path(args.out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    set_seed(3407)\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    saved_path = Path(args.saved)\n",
        "    if not saved_path.exists():\n",
        "        raise FileNotFoundError(f\"Saved matrix not found: {saved_path.resolve()}\")\n",
        "\n",
        "    matrix, saved_meta = _load_saved_matrix(saved_path)\n",
        "    n_layers, T = int(matrix.shape[0]), int(matrix.shape[1])\n",
        "    print(f\"Loaded {saved_path} with matrix shape {tuple(matrix.shape)}\")\n",
        "\n",
        "    # Defaults (used if file doesn't contain metadata)\n",
        "    CLEAN_TEXT = str(saved_meta.get(\"clean_text\", \"Michelle Jones was a top-notch student. Michelle\"))\n",
        "    CORRUPT_TEXT = str(saved_meta.get(\"corrupt_text\", \"Michelle Smith was a top-notch student. Michelle\"))\n",
        "    TOKEN_A = str(saved_meta.get(\"token_a\", \" Jones\"))\n",
        "    TOKEN_B = str(saved_meta.get(\"token_b\", \" Smith\"))\n",
        "\n",
        "    saved_clean_score = saved_meta.get(\"clean_score\", float(\"nan\"))\n",
        "    saved_corrupt_score = saved_meta.get(\"corrupt_score\", float(\"nan\"))\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    clean_res = run_clean_baseline(\n",
        "        model,\n",
        "        bpe,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        device=device,\n",
        "        top_k=20,\n",
        "        overwrite_cache=True,\n",
        "    )\n",
        "    corrupt_res = run_corrupt_baseline(\n",
        "        model,\n",
        "        bpe,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        device=device,\n",
        "        top_k=20,\n",
        "    )\n",
        "\n",
        "    clean_score = float(clean_res.score_logit_diff)\n",
        "    corrupt_score = float(corrupt_res.score_logit_diff)\n",
        "\n",
        "    print(\"\\nBaselines (for report):\")\n",
        "    print(f\"clean_score   = {clean_score:.4f}\")\n",
        "    print(f\"corrupt_score = {corrupt_score:.4f}\")\n",
        "    print(f\"delta (corrupt-clean) = {corrupt_score - clean_score:.4f}\")\n",
        "\n",
        "    if isinstance(saved_meta, dict) and (not (saved_clean_score != saved_clean_score) or not (saved_corrupt_score != saved_corrupt_score)):\n",
        "        print(\"\\nSaved baselines (from file, if present):\")\n",
        "        try:\n",
        "            print(f\"saved_clean_score   = {float(saved_clean_score):.4f}\")\n",
        "            print(f\"saved_corrupt_score = {float(saved_corrupt_score):.4f}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Optional: x-axis token labels\n",
        "    token_labels: Optional[list[str]] = None\n",
        "    if args.show_token_strs:\n",
        "        labels_raw = decode_prompt_token_labels(bpe, CORRUPT_TEXT)  # labels should match the prompt used for the matrix\n",
        "        if len(labels_raw) == T:\n",
        "            token_labels = [_safe_token_label(s, max_len=18) for s in labels_raw]\n",
        "        else:\n",
        "            # fallback: still show positions if mismatch\n",
        "            token_labels = None\n",
        "\n",
        "    metric_title = f\"Logit difference heatmap: logit({repr(TOKEN_B)})  logit({repr(TOKEN_A)})\\nclean={clean_score:.3f}   corrupt={corrupt_score:.3f}\"\n",
        "\n",
        "    meta = HeatmapMeta(\n",
        "        metric_title=metric_title,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        n_layers=n_layers,\n",
        "        seq_len=T,\n",
        "        token_labels=token_labels,\n",
        "    )\n",
        "\n",
        "    # Save matrix + metadata for reproducibility\n",
        "    save_heatmap_artifacts(out_dir=out_dir, matrix=matrix, meta=meta)\n",
        "\n",
        "    fig, ax = plot_logit_diff_heatmap(\n",
        "        matrix,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=metric_title,\n",
        "        show_token_strings=bool(args.show_token_strs),\n",
        "        max_xticks=40,\n",
        "        center_zero=True,\n",
        "        include_pos_in_label=True,\n",
        "    )\n",
        "\n",
        "    fig_base = out_dir / \"heatmap_logit_diff\"\n",
        "    saved = save_figure_publication_quality(fig, out_basepath=fig_base, formats=(\"png\", \"pdf\"), dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Delta heatmap (patched - corrupt) for interpretability/debug\n",
        "    if args.also_delta:\n",
        "        delta = matrix - float(corrupt_score)\n",
        "        max_abs = float(delta.abs().max())\n",
        "        norm = TwoSlopeNorm(vcenter=0.0, vmin=-max_abs, vmax=max_abs) if max_abs > 0 else None\n",
        "\n",
        "        fig2 = plt.figure(figsize=(max(10, 0.8 * T), 6))\n",
        "        ax2 = plt.gca()\n",
        "        im2 = ax2.matshow(delta.cpu().numpy(), norm=norm, aspect=\"auto\")\n",
        "        plt.colorbar(im2, label=\" = score(L,P)  corrupt_score\")\n",
        "\n",
        "        ax2.set_title(\"Delta heatmap: (patched score  corrupt_score)\", pad=18)\n",
        "        ax2.set_xlabel(\"Token position\")\n",
        "        ax2.set_ylabel(\"Layer (0=first, 11=last)\")\n",
        "\n",
        "        xt = _tick_positions(T, max_ticks=40)\n",
        "        ax2.set_xticks(xt)\n",
        "        if args.show_token_strs and (token_labels is not None) and len(token_labels) == T:\n",
        "            ax2.set_xticklabels([f\"{i}:{token_labels[i]}\" for i in xt], rotation=90, fontsize=8)\n",
        "        else:\n",
        "            ax2.set_xticklabels([str(i) for i in xt])\n",
        "\n",
        "        ax2.set_yticks(list(range(n_layers)))\n",
        "        ax2.set_yticklabels([str(i) for i in range(n_layers)])\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        fig2_base = out_dir / \"heatmap_delta\"\n",
        "        saved_delta = save_figure_publication_quality(fig2, out_basepath=fig2_base, formats=(\"png\", \"pdf\"), dpi=300)\n",
        "        plt.close(fig2)\n",
        "        saved = list(saved) + list(saved_delta)\n",
        "\n",
        "    print(\"\\nSaved figures:\")\n",
        "    for p in saved:\n",
        "        print(\" -\", Path(p).resolve())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting test_section_10_all.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_section_10_all.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "# Make matplotlib safe in headless pytest runs\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from section10_visualization import (\n",
        "    plot_logit_diff_heatmap,\n",
        "    save_figure_publication_quality,\n",
        ")\n",
        "\n",
        "\n",
        "def test_section10_plot_returns_figure_and_axes_and_image():\n",
        "    # shape matches assignment: 12 layers x 11 tokens\n",
        "    m = torch.randn(12, 11)\n",
        "    token_labels = [f\" tok{i}\" for i in range(11)]\n",
        "\n",
        "    fig, ax = plot_logit_diff_heatmap(\n",
        "        m,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=\"Logit difference heatmap: logit(' B')  logit(' A')\",\n",
        "        show_token_strings=True,\n",
        "        max_xticks=40,\n",
        "        center_zero=True,\n",
        "    )\n",
        "\n",
        "    # should have at least one image in axis\n",
        "    assert len(ax.images) == 1, \"Expected a single heatmap image (matshow/imshow).\"\n",
        "\n",
        "    # should have colorbar axis as well (figure axes count >= 2)\n",
        "    assert len(fig.axes) >= 2, \"Expected a colorbar to be added.\"\n",
        "\n",
        "    # title should be set\n",
        "    assert \"Logit difference\" in ax.get_title()\n",
        "\n",
        "    # x/y labels should be set\n",
        "    assert ax.get_xlabel() != \"\"\n",
        "    assert ax.get_ylabel() != \"\"\n",
        "\n",
        "\n",
        "def test_section10_save_publication_quality_creates_png_and_pdf(tmp_path: Path):\n",
        "    m = torch.randn(12, 15)\n",
        "    token_labels = [f\" tok{i}\" for i in range(15)]\n",
        "\n",
        "    fig, ax = plot_logit_diff_heatmap(\n",
        "        m,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=\"Metric title\",\n",
        "        show_token_strings=True,\n",
        "        max_xticks=40,\n",
        "        center_zero=True,\n",
        "    )\n",
        "\n",
        "    out_base = tmp_path / \"heatmap_test\"\n",
        "    saved = save_figure_publication_quality(fig, out_basepath=out_base, formats=(\"png\", \"pdf\"), dpi=300)\n",
        "\n",
        "    assert len(saved) == 2\n",
        "    for p in saved:\n",
        "        assert p.exists(), f\"Expected saved file to exist: {p}\"\n",
        "        assert p.stat().st_size > 0, f\"Expected saved file to be non-empty: {p}\"\n",
        "\n",
        "\n",
        "def test_section10_token_label_fallback_to_numeric_when_disabled():\n",
        "    m = torch.randn(12, 60)\n",
        "    token_labels = [f\" tok{i}\" for i in range(60)]\n",
        "\n",
        "    fig, ax = plot_logit_diff_heatmap(\n",
        "        m,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=\"Metric title\",\n",
        "        show_token_strings=False,   # forces numeric labels\n",
        "        max_xticks=12,              # reduce ticks\n",
        "        center_zero=True,\n",
        "    )\n",
        "\n",
        "    # xtick labels should be numeric strings\n",
        "    texts = [t.get_text() for t in ax.get_xticklabels()]\n",
        "    # some may be empty depending on backend/layout; keep it robust:\n",
        "    nonempty = [x for x in texts if x.strip() != \"\"]\n",
        "    assert len(nonempty) > 0\n",
        "    assert all(s.replace(\"-\", \"\").isdigit() for s in nonempty), \"Expected numeric x-tick labels in fallback mode.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 6.79s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q test_section_10_all.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m674.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib)\n",
            "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hUsing cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
            "Downloading pillow-12.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m121.8/121.8 kB\u001b[0m \u001b[31m794.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pillow-12.1.0 pyparsing-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loaded section9_diff_matrix.pt with matrix shape (12, 11)\n",
            "number of parameters: 124.44M\n",
            "\n",
            "Baselines (for report):\n",
            "clean_score   = -4.1241\n",
            "corrupt_score = 5.6562\n",
            "delta (corrupt-clean) = 9.7803\n",
            "\n",
            "Saved baselines (from file, if present):\n",
            "saved_clean_score   = -4.1241\n",
            "saved_corrupt_score = 5.6562\n",
            "\n",
            "Saved figures:\n",
            " - /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/section10/heatmap_logit_diff.png\n",
            " - /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/section10/heatmap_logit_diff.pdf\n"
          ]
        }
      ],
      "source": [
        "!python section10_visualize_driver.py --out_dir artifacts/section10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loaded section9_diff_matrix.pt (dict) with matrix shape (12, 11)\n",
            "Saved clean_score=-4.1241, corrupt_score=5.6562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 124.44M\n",
            "\n",
            "[Check 1] Baselines recomputed:\n",
            "clean_score   = -4.1241\n",
            "corrupt_score = 5.6562\n",
            "delta (corrupt-clean) = 9.7803\n",
            "\n",
            "[Check 5] Matrix cell == direct recomputation (sampled):\n",
            "(L=0, P=0) stored=5.656242 direct=5.656242 abs_diff=0.00e+00\n",
            "(L=0, P=1) stored=-4.069115 direct=-4.069115 abs_diff=0.00e+00\n",
            "(L=6, P=1) stored=-3.150902 direct=-3.150902 abs_diff=0.00e+00\n",
            "(L=6, P=10) stored=4.950867 direct=4.950867 abs_diff=0.00e+00\n",
            "(L=11, P=1) stored=5.656242 direct=5.656242 abs_diff=0.00e+00\n",
            "\n",
            "[Check 6] Delta stats:\n",
            "delta min=-9.7803, max=0.0342, max_abs=9.7803\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from patching_sweep import logit_diff_from_last_logits, single_token_id\n",
        "\n",
        "CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "TOKEN_A = \" Jones\"\n",
        "TOKEN_B = \" Smith\"\n",
        "\n",
        "SAVED = \"section9_diff_matrix.pt\"\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_baselines(model, bpe, device):\n",
        "    idx_clean = bpe(CLEAN_TEXT).to(device)\n",
        "    idx_corr  = bpe(CORRUPT_TEXT).to(device)\n",
        "\n",
        "    a_id = single_token_id(bpe, TOKEN_A)\n",
        "    b_id = single_token_id(bpe, TOKEN_B)\n",
        "\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=True)\n",
        "    clean_score = logit_diff_from_last_logits(\n",
        "        model.last_logits[0], token_a_id=a_id, token_b_id=b_id\n",
        "    )\n",
        "\n",
        "    _ = model(idx_corr)\n",
        "    corr_score = logit_diff_from_last_logits(\n",
        "        model.last_logits[0], token_a_id=a_id, token_b_id=b_id\n",
        "    )\n",
        "\n",
        "    return clean_score, corr_score, a_id, b_id, idx_corr\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main():\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    # Load matrix if available; otherwise we'll compute a small sample check only\n",
        "    matrix = None\n",
        "    saved_clean_score = float(\"nan\")\n",
        "    saved_corr_score = float(\"nan\")\n",
        "\n",
        "    if os.path.exists(SAVED):\n",
        "        d = torch.load(SAVED, map_location=\"cpu\")\n",
        "\n",
        "        # Robust load: handle dict-with-matrix OR tensor-only saves\n",
        "        if isinstance(d, dict) and \"matrix\" in d:\n",
        "            matrix = d[\"matrix\"].to(torch.float32)\n",
        "            saved_clean_score = float(d.get(\"clean_score\", float(\"nan\")))\n",
        "            saved_corr_score  = float(d.get(\"corrupt_score\", float(\"nan\")))\n",
        "            print(f\"Loaded {SAVED} (dict) with matrix shape {tuple(matrix.shape)}\")\n",
        "            if not (torch.isnan(torch.tensor(saved_clean_score)) or torch.isnan(torch.tensor(saved_corr_score))):\n",
        "                print(f\"Saved clean_score={saved_clean_score:.4f}, corrupt_score={saved_corr_score:.4f}\")\n",
        "            else:\n",
        "                print(\"Saved baseline scores not found in file (clean_score/corrupt_score missing).\")\n",
        "\n",
        "        elif torch.is_tensor(d):\n",
        "            matrix = d.to(torch.float32)\n",
        "            print(f\"Loaded {SAVED} (tensor) with shape {tuple(matrix.shape)}\")\n",
        "            print(\"Note: baseline scores not present because file contains only the tensor.\")\n",
        "\n",
        "        else:\n",
        "            raise TypeError(f\"Unexpected save format in {SAVED}: {type(d)}\")\n",
        "\n",
        "    # Load model/tokenizer\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    # Check 1: baselines\n",
        "    clean_score, corr_score, a_id, b_id, idx_corr = compute_baselines(model, bpe, device)\n",
        "    print(\"\\n[Check 1] Baselines recomputed:\")\n",
        "    print(f\"clean_score   = {clean_score:.4f}\")\n",
        "    print(f\"corrupt_score = {corr_score:.4f}\")\n",
        "    print(f\"delta (corrupt-clean) = {corr_score - clean_score:.4f}\")\n",
        "\n",
        "    if matrix is not None:\n",
        "        # Check 5: sample a few cells and compare to direct recomputation\n",
        "        n_layers, T = matrix.shape\n",
        "        samples = [(0, 0), (0, 1), (6, 1), (6, T - 1), (n_layers - 1, 1)]\n",
        "        print(\"\\n[Check 5] Matrix cell == direct recomputation (sampled):\")\n",
        "        for (L, P) in samples:\n",
        "            _ = model(idx_corr, layer_to_patch=int(L), position_to_patch=int(P))\n",
        "            direct = logit_diff_from_last_logits(\n",
        "                model.last_logits[0], token_a_id=a_id, token_b_id=b_id\n",
        "            )\n",
        "            stored = float(matrix[int(L), int(P)])\n",
        "            print(f\"(L={L}, P={P}) stored={stored:.6f} direct={direct:.6f} abs_diff={abs(stored-direct):.2e}\")\n",
        "\n",
        "        # Check 6: delta heatmap\n",
        "        delta = matrix - float(corr_score)\n",
        "        max_abs = float(delta.abs().max())\n",
        "        print(\"\\n[Check 6] Delta stats:\")\n",
        "        print(f\"delta min={float(delta.min()):.4f}, max={float(delta.max()):.4f}, max_abs={max_abs:.4f}\")\n",
        "\n",
        "        norm = TwoSlopeNorm(vcenter=0.0, vmin=-max_abs, vmax=max_abs)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.title(\"DELTA heatmap: (patched score - corrupt_score)\")\n",
        "        plt.imshow(delta.cpu().numpy(), norm=norm, aspect=\"auto\")\n",
        "        plt.colorbar(label=\" = score(L,P) - corrupt_score\")\n",
        "        plt.xlabel(\"Token position\")\n",
        "        plt.ylabel(\"Layer\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"\\nNo saved matrix found. If you want full verification, run section9_sweep_driver.py first to create it.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 82%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                          [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m87 passed\u001b[0m\u001b[32m in 46.67s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing wrong_source_control.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile wrong_source_control.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Tuple, Dict\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Condition:\n",
        "    name: str\n",
        "    target: Tuple[int, int]          # (L_target, P_target)\n",
        "    source: Optional[Tuple[int, int]] # None => no patch; else (L_source, P_source)\n",
        "\n",
        "\n",
        "def single_token_id(bpe, token_str: str) -> int:\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(f\"{repr(token_str)} is not a single BPE token. Got {len(ids)} ids: {ids}\")\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "def score_from_last_logits(last_logits_1d: torch.Tensor, token_a_id: int, token_b_id: int) -> float:\n",
        "    # score = logit(B) - logit(A)\n",
        "    return float(last_logits_1d[token_b_id] - last_logits_1d[token_a_id])\n",
        "\n",
        "\n",
        "def normalized_restoration(score_patched: float, score_clean: float, score_corr: float) -> float:\n",
        "    denom = (score_clean - score_corr)\n",
        "    if abs(denom) < 1e-12:\n",
        "        return float(\"nan\")\n",
        "    return (score_patched - score_corr) / denom\n",
        "\n",
        "\n",
        "def conditions_for_target(L: int, P: int, n_layers: int, seq_len: int) -> List[Condition]:\n",
        "    \"\"\"\n",
        "    Returns the 5-condition set (baseline + match + wrong-source variants where valid)\n",
        "    while keeping the patch TARGET fixed at (L,P).\n",
        "    \"\"\"\n",
        "    conds: List[Condition] = []\n",
        "    conds.append(Condition(\"no_patch\", (L, P), None))\n",
        "    conds.append(Condition(\"match\", (L, P), (L, P)))\n",
        "\n",
        "    # WS-pos +/- (same layer, neighbor token)\n",
        "    if P + 1 < seq_len:\n",
        "        conds.append(Condition(\"WS-pos+\", (L, P), (L, P + 1)))\n",
        "    if P - 1 >= 0:\n",
        "        conds.append(Condition(\"WS-pos-\", (L, P), (L, P - 1)))\n",
        "\n",
        "    # WS-layer +/- (same position, neighbor layer)\n",
        "    if L + 1 < n_layers:\n",
        "        conds.append(Condition(\"WS-layer+\", (L, P), (L + 1, P)))\n",
        "    if L - 1 >= 0:\n",
        "        conds.append(Condition(\"WS-layer-\", (L, P), (L - 1, P)))\n",
        "\n",
        "    return conds\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_condition(\n",
        "    model,\n",
        "    idx_corr: torch.Tensor,\n",
        "    cond: Condition,\n",
        "    token_a_id: int,\n",
        "    token_b_id: int,\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Runs ONE condition and returns score + bookkeeping.\n",
        "    \"\"\"\n",
        "    if cond.source is None:\n",
        "        _ = model(idx_corr)\n",
        "        score = score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "        return {\n",
        "            \"score\": score,\n",
        "            \"patched\": 0.0,\n",
        "            \"L_target\": float(cond.target[0]),\n",
        "            \"P_target\": float(cond.target[1]),\n",
        "            \"L_source\": float(\"nan\"),\n",
        "            \"P_source\": float(\"nan\"),\n",
        "        }\n",
        "\n",
        "    (Lt, Pt) = cond.target\n",
        "    (Ls, Ps) = cond.source\n",
        "    _ = model(\n",
        "        idx_corr,\n",
        "        layer_to_patch=Lt,\n",
        "        position_to_patch=Pt,\n",
        "        source_layer=Ls,\n",
        "        source_position=Ps,\n",
        "    )\n",
        "    score = score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "    return {\n",
        "        \"score\": score,\n",
        "        \"patched\": 1.0,\n",
        "        \"L_target\": float(Lt),\n",
        "        \"P_target\": float(Pt),\n",
        "        \"L_source\": float(Ls),\n",
        "        \"P_source\": float(Ps),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing extra1_wrong_source_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra1_wrong_source_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "import wrong_source_control as wsc\n",
        "\n",
        "\n",
        "CLEAN_TEXT = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "TOKEN_A_STR = \" Jones\"   # clean-consistent\n",
        "TOKEN_B_STR = \" Smith\"   # corrupt-consistent\n",
        "TOP_K_HOTSPOTS = 3\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def tokens_same_length(bpe: BPETokenizer, a: str, b: str) -> bool:\n",
        "    return bpe(a).shape[1] == bpe(b).shape[1]\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_score(model, idx, token_a_id: int, token_b_id: int) -> float:\n",
        "    _ = model(idx)\n",
        "    return wsc.score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_match_heatmap(\n",
        "    model,\n",
        "    idx_corr: torch.Tensor,\n",
        "    token_a_id: int,\n",
        "    token_b_id: int,\n",
        ") -> torch.Tensor:\n",
        "    n_layers = len(model.transformer.h)\n",
        "    seq_len = idx_corr.shape[1]\n",
        "    out = torch.empty((n_layers, seq_len), dtype=torch.float32)\n",
        "\n",
        "    for L in range(n_layers):\n",
        "        for P in range(seq_len):\n",
        "            _ = model(idx_corr, layer_to_patch=L, position_to_patch=P)  # source defaults to match\n",
        "            out[L, P] = wsc.score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "    return out\n",
        "\n",
        "\n",
        "def select_hotspots_and_cold(\n",
        "    match_heatmap: torch.Tensor,\n",
        "    score_clean: float,\n",
        "    score_corr: float,\n",
        "    top_k: int = 3,\n",
        ") -> Tuple[List[Tuple[int, int]], Tuple[int, int]]:\n",
        "    \"\"\"\n",
        "    Hotspots: largest normalized restoration R\n",
        "    Cold: smallest absolute change vs corrupted baseline\n",
        "    \"\"\"\n",
        "    n_layers, seq_len = match_heatmap.shape\n",
        "    R = torch.empty_like(match_heatmap)\n",
        "\n",
        "    denom = (score_clean - score_corr)\n",
        "    if abs(denom) < 1e-12:\n",
        "        hot = [(0, 0)]\n",
        "        cold = (0, 0)\n",
        "        return hot, cold\n",
        "\n",
        "    R = (match_heatmap - score_corr) / denom\n",
        "\n",
        "    # flatten\n",
        "    flat_R = R.flatten()\n",
        "    top_vals, top_idx = torch.topk(flat_R, k=min(top_k, flat_R.numel()))\n",
        "    hotspots = []\n",
        "    used = set()\n",
        "    for idx in top_idx.tolist():\n",
        "        L = idx // seq_len\n",
        "        P = idx % seq_len\n",
        "        if (L, P) not in used:\n",
        "            hotspots.append((L, P))\n",
        "            used.add((L, P))\n",
        "        if len(hotspots) >= top_k:\n",
        "            break\n",
        "\n",
        "    delta = (match_heatmap - score_corr).abs()\n",
        "    delta_flat = delta.flatten()\n",
        "    mask = torch.ones_like(delta_flat, dtype=torch.bool)\n",
        "    for (L, P) in hotspots:\n",
        "        mask[L * seq_len + P] = False\n",
        "    masked_delta = delta_flat.clone()\n",
        "    masked_delta[~mask] = float(\"inf\")\n",
        "    cold_idx = int(torch.argmin(masked_delta).item())\n",
        "    cold = (cold_idx // seq_len, cold_idx % seq_len)\n",
        "\n",
        "    return hotspots, cold\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    set_seed(3407)\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    # Load model + tokenizer\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    # Validate same token length\n",
        "    if not tokens_same_length(bpe, CLEAN_TEXT, CORRUPT_TEXT):\n",
        "        raise RuntimeError(\n",
        "            \"CLEAN_TEXT and CORRUPT_TEXT do NOT have the same number of BPE tokens.\\n\"\n",
        "            \"Fix the texts until they tokenize to the same length.\"\n",
        "        )\n",
        "\n",
        "    # Tokenize prompts\n",
        "    idx_clean = bpe(CLEAN_TEXT).to(device)     # (1, T)\n",
        "    idx_corr = bpe(CORRUPT_TEXT).to(device)    # (1, T)\n",
        "    seq_len = idx_corr.shape[1]\n",
        "    n_layers = len(model.transformer.h)\n",
        "\n",
        "    # Token ids for metric\n",
        "    token_a_id = wsc.single_token_id(bpe, TOKEN_A_STR)\n",
        "    token_b_id = wsc.single_token_id(bpe, TOKEN_B_STR)\n",
        "\n",
        "    # Clean baseline (cache activations)\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=True)\n",
        "    score_clean = wsc.score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "    # Corrupted baseline\n",
        "    _ = model(idx_corr)\n",
        "    score_corr = wsc.score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"seq_len={seq_len}, n_layers={n_layers}\")\n",
        "    print(f\"score_clean = {score_clean:.6f}\")\n",
        "    print(f\"score_corr  = {score_corr:.6f}\")\n",
        "\n",
        "    # Compute MATCH heatmap (standard patch)\n",
        "    print(\"\\nComputing match heatmap (this is the same sweep as your main analysis)...\")\n",
        "    match_heatmap = compute_match_heatmap(model, idx_corr, token_a_id, token_b_id)\n",
        "    torch.save(match_heatmap.cpu(), \"match_heatmap.pt\")\n",
        "    print(\"Saved: match_heatmap.pt\")\n",
        "\n",
        "    # Pick top hotspots + one cold cell\n",
        "    hotspots, cold = select_hotspots_and_cold(match_heatmap, score_clean, score_corr, top_k=TOP_K_HOTSPOTS)\n",
        "    targets = hotspots + [cold]\n",
        "\n",
        "    print(\"\\n=== Selected targets ===\")\n",
        "    for i, (L, P) in enumerate(targets):\n",
        "        s = float(match_heatmap[L, P])\n",
        "        R = wsc.normalized_restoration(s, score_clean, score_corr)\n",
        "        tag = \"COLD\" if (L, P) == cold else \"HOT\"\n",
        "        print(f\"{i+1:02d}. ({L},{P})  match_score={s:.6f}  R_match={R:.4f}  [{tag}]\")\n",
        "\n",
        "    # Run wrong-source conditions per target\n",
        "    print(\"\\n=== WRONG-SOURCE CONTROL RESULTS ===\")\n",
        "    print(\"(Metric: score = logit(B) - logit(A); higher/lower direction depends on your pair)\\n\")\n",
        "\n",
        "    for (L, P) in targets:\n",
        "        conds = wsc.conditions_for_target(L, P, n_layers=n_layers, seq_len=seq_len)\n",
        "\n",
        "        print(f\"\\n--- Target (L={L}, P={P}) ---\")\n",
        "        print(f\"{'condition':12s} | {'source':10s} | {'score':>12s} | {'R':>8s}\")\n",
        "        print(\"-\" * 52)\n",
        "\n",
        "        for c in conds:\n",
        "            row = wsc.run_condition(model, idx_corr, c, token_a_id, token_b_id)\n",
        "            score = row[\"score\"]\n",
        "            R = wsc.normalized_restoration(score, score_clean, score_corr)\n",
        "\n",
        "            if c.source is None:\n",
        "                src = \"-\"\n",
        "            else:\n",
        "                src = f\"({c.source[0]},{c.source[1]})\"\n",
        "\n",
        "            print(f\"{c.name:12s} | {src:10s} | {score:12.6f} | {R:8.4f}\")\n",
        "\n",
        "    # OPTIONAL: build one full wrong-source heatmap using deterministic rule (pos+1 else pos-1)\n",
        "    print(\"\\nOptional: computing a full wrong-source heatmap with rule: source=(L,P+1) else (L,P-1)\")\n",
        "    ws_heatmap = torch.empty_like(match_heatmap)\n",
        "    for L in range(n_layers):\n",
        "        for P in range(seq_len):\n",
        "            srcP = P + 1 if (P + 1 < seq_len) else (P - 1)\n",
        "            _ = model(idx_corr, layer_to_patch=L, position_to_patch=P, source_layer=L, source_position=srcP)\n",
        "            ws_heatmap[L, P] = wsc.score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "    torch.save(ws_heatmap.cpu(), \"wrong_source_posshift_heatmap.pt\")\n",
        "    print(\"Saved: wrong_source_posshift_heatmap.pt\")\n",
        "    print(\"\\nDone \")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_extra1_wrong_source_control.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_extra1_wrong_source_control.py\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "\n",
        "import wrong_source_control as wsc\n",
        "\n",
        "\n",
        "def _make_tiny():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 200\n",
        "    cfg.block_size = 32\n",
        "    model = GPT(cfg).eval()\n",
        "    return model, cfg\n",
        "\n",
        "\n",
        "def _make_clean_corrupt(cfg, T=12):\n",
        "    torch.manual_seed(0)\n",
        "    clean = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, 3] = (corrupt[0, 3] + 1) % cfg.vocab_size\n",
        "    return clean, corrupt\n",
        "\n",
        "\n",
        "def test_forward_accepts_wrong_source_parameters_and_records_source_bookkeeping():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=12)\n",
        "\n",
        "    # cache clean\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    L_target, P_target = 0, 3\n",
        "    L_source, P_source = 0, 4\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(\n",
        "            corrupt,\n",
        "            record_activations=True,\n",
        "            layer_to_patch=L_target,\n",
        "            position_to_patch=P_target,\n",
        "            source_layer=L_source,\n",
        "            source_position=P_source,\n",
        "        )\n",
        "\n",
        "    assert model.last_patch == (L_target, P_target)\n",
        "    assert hasattr(model, \"last_patch_source\")\n",
        "    assert model.last_patch_source == (L_source, P_source)\n",
        "\n",
        "    # patched activation at (L_target, P_target) must equal clean cache at (L_source, P_source)\n",
        "    patched_acts = model.last_activations\n",
        "    assert patched_acts is not None\n",
        "    assert torch.allclose(\n",
        "        patched_acts[L_target][P_target],\n",
        "        model.clean_activations[L_source][P_source],\n",
        "        rtol=1e-5,\n",
        "        atol=1e-6,\n",
        "    )\n",
        "\n",
        "\n",
        "def test_standard_patch_is_default_when_source_not_provided():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=10)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    L, P = 1, 2\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True, layer_to_patch=L, position_to_patch=P)\n",
        "\n",
        "    assert model.last_patch == (L, P)\n",
        "    assert model.last_patch_source == (L, P)  # default source == target\n",
        "\n",
        "    patched_acts = model.last_activations\n",
        "    assert torch.allclose(\n",
        "        patched_acts[L][P],\n",
        "        model.clean_activations[L][P],\n",
        "        rtol=1e-5,\n",
        "        atol=1e-6,\n",
        "    )\n",
        "\n",
        "\n",
        "def test_wrong_source_pairing_rules_enforced():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=10)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3, source_layer=0, source_position=None)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3, source_layer=None, source_position=4)\n",
        "\n",
        "\n",
        "def test_wrong_source_bounds_checked():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt = _make_clean_corrupt(cfg, T=8)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # source_position out of range\n",
        "    with pytest.raises(IndexError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3, source_layer=0, source_position=999)\n",
        "\n",
        "    # source_layer out of range\n",
        "    with pytest.raises(IndexError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=3, source_layer=999, source_position=3)\n",
        "\n",
        "\n",
        "def test_conditions_for_target_respects_boundaries():\n",
        "    n_layers = 12\n",
        "    seq_len = 10\n",
        "\n",
        "    # P=0 => no WS-pos-\n",
        "    conds = wsc.conditions_for_target(L=5, P=0, n_layers=n_layers, seq_len=seq_len)\n",
        "    names = {c.name for c in conds}\n",
        "    assert \"WS-pos-\" not in names\n",
        "    assert \"WS-pos+\" in names\n",
        "\n",
        "    # P=seq_len-1 => no WS-pos+\n",
        "    conds = wsc.conditions_for_target(L=5, P=seq_len - 1, n_layers=n_layers, seq_len=seq_len)\n",
        "    names = {c.name for c in conds}\n",
        "    assert \"WS-pos+\" not in names\n",
        "    assert \"WS-pos-\" in names\n",
        "\n",
        "    # L=0 => no WS-layer-\n",
        "    conds = wsc.conditions_for_target(L=0, P=3, n_layers=n_layers, seq_len=seq_len)\n",
        "    names = {c.name for c in conds}\n",
        "    assert \"WS-layer-\" not in names\n",
        "    assert \"WS-layer+\" in names\n",
        "\n",
        "    # L=n_layers-1 => no WS-layer+\n",
        "    conds = wsc.conditions_for_target(L=n_layers - 1, P=3, n_layers=n_layers, seq_len=seq_len)\n",
        "    names = {c.name for c in conds}\n",
        "    assert \"WS-layer+\" not in names\n",
        "    assert \"WS-layer-\" in names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 3.21s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q test_extra1_wrong_source_control.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting wrong_source_control_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile wrong_source_control_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.model import GPT\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class PatchResult:\n",
        "    target: Tuple[int, int]\n",
        "    variant: str\n",
        "    source: Tuple[int, int]\n",
        "    score: float\n",
        "    R: float           # normalized restoration (can be > 1 if overshoot)\n",
        "    C: float           # normalized closeness-to-clean (1 is best)\n",
        "    last_patch: Optional[Tuple[int, int]]\n",
        "    last_patch_source: Optional[Tuple[int, int]]\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "def single_token_id(bpe: BPETokenizer, token_str: str) -> int:\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(\n",
        "            f\"Token string must map to exactly 1 BPE token. \"\n",
        "            f\"Got {len(ids)} tokens for {repr(token_str)}: {ids}\"\n",
        "        )\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "def logit_diff_from_last_logits(last_logits_1d: torch.Tensor, token_b_id: int, token_a_id: int) -> float:\n",
        "    # score = logit(B) - logit(A)\n",
        "    return float(last_logits_1d[token_b_id] - last_logits_1d[token_a_id])\n",
        "\n",
        "\n",
        "def norm_restoration(score: float, score_clean: float, score_corr: float) -> float:\n",
        "    # R = (score - score_corr) / (score_clean - score_corr)\n",
        "    denom = (score_clean - score_corr)\n",
        "    if abs(denom) < 1e-12:\n",
        "        return 0.0\n",
        "    return (score - score_corr) / denom\n",
        "\n",
        "\n",
        "def norm_closeness(score: float, score_clean: float, score_corr: float) -> float:\n",
        "    # C = 1 - |score - score_clean| / |score_corr - score_clean|\n",
        "    denom = abs(score_corr - score_clean)\n",
        "    if denom < 1e-12:\n",
        "        return 1.0\n",
        "    return 1.0 - (abs(score - score_clean) / denom)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_score(\n",
        "    model: GPT,\n",
        "    idx: torch.Tensor,\n",
        "    token_a_id: int,\n",
        "    token_b_id: int,\n",
        "    *,\n",
        "    layer_to_patch: Optional[int] = None,\n",
        "    position_to_patch: Optional[int] = None,\n",
        "    source_layer: Optional[int] = None,\n",
        "    source_position: Optional[int] = None,\n",
        ") -> float:\n",
        "    _logits, _loss = model(\n",
        "        idx,\n",
        "        record_activations=False,\n",
        "        cache_activations=False,\n",
        "        overwrite_cache=False,\n",
        "        layer_to_patch=layer_to_patch,\n",
        "        position_to_patch=position_to_patch,\n",
        "        source_layer=source_layer,\n",
        "        source_position=source_position,\n",
        "    )\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits is None after forward().\")\n",
        "    return logit_diff_from_last_logits(model.last_logits[0], token_b_id=token_b_id, token_a_id=token_a_id)\n",
        "\n",
        "\n",
        "def build_wrong_source_variants(L: int, P: int, n_layer: int, T: int) -> List[Tuple[str, int, int]]:\n",
        "    variants: List[Tuple[str, int, int]] = []\n",
        "    variants.append((\"MATCH\", L, P))\n",
        "\n",
        "    # Position mismatch (same layer)\n",
        "    if P + 1 < T:\n",
        "        variants.append((\"WS-pos+\", L, P + 1))\n",
        "    if P - 1 >= 0:\n",
        "        variants.append((\"WS-pos-\", L, P - 1))\n",
        "\n",
        "    # Layer mismatch (same position)\n",
        "    if L + 1 < n_layer:\n",
        "        variants.append((\"WS-layer+\", L + 1, P))\n",
        "    if L - 1 >= 0:\n",
        "        variants.append((\"WS-layer-\", L - 1, P))\n",
        "\n",
        "    return variants\n",
        "\n",
        "\n",
        "def select_hotspots(match_scores: torch.Tensor, score_clean: float, k: int = 3) -> List[Tuple[int, int]]:\n",
        "    # Pick coords whose MATCH patched score is closest to clean (min |score - score_clean|)\n",
        "    n_layer, T = match_scores.shape\n",
        "    flat: List[Tuple[float, int, int]] = []\n",
        "    for L in range(n_layer):\n",
        "        for P in range(T):\n",
        "            d = abs(float(match_scores[L, P]) - score_clean)\n",
        "            flat.append((d, L, P))\n",
        "    flat.sort(key=lambda x: x[0])\n",
        "    out: List[Tuple[int, int]] = []\n",
        "    for _, L, P in flat:\n",
        "        out.append((L, P))\n",
        "        if len(out) >= k:\n",
        "            break\n",
        "    return out\n",
        "\n",
        "\n",
        "def select_coldcell(\n",
        "    match_scores: torch.Tensor,\n",
        "    score_corr: float,\n",
        "    *,\n",
        "    changed_pos: int,\n",
        ") -> Tuple[int, int]:\n",
        "    # Pick coord with minimal |score - score_corr| but avoid positions before/at the changed token\n",
        "    n_layer, T = match_scores.shape\n",
        "    pos_min = min(T - 1, changed_pos + 1)\n",
        "\n",
        "    candidates: List[Tuple[float, int, int]] = []\n",
        "    for L in range(n_layer):\n",
        "        for P in range(pos_min, T):\n",
        "            d = abs(float(match_scores[L, P]) - score_corr)\n",
        "            candidates.append((d, L, P))\n",
        "\n",
        "    # Fallback if pos_min kills all candidates\n",
        "    if not candidates:\n",
        "        for L in range(n_layer):\n",
        "            for P in range(T):\n",
        "                d = abs(float(match_scores[L, P]) - score_corr)\n",
        "                candidates.append((d, L, P))\n",
        "\n",
        "    candidates.sort(key=lambda x: x[0])\n",
        "    _, L, P = candidates[0]\n",
        "    return (L, P)\n",
        "\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--clean\", type=str, default=\"Michelle Jones was a top-notch student. Michelle\")\n",
        "    p.add_argument(\"--corrupt\", type=str, default=\"Michelle Smith was a top-notch student. Michelle\")\n",
        "    p.add_argument(\"--token_a\", type=str, default=\" Jones\", help=\"Token A (clean-consistent), usually with leading space\")\n",
        "    p.add_argument(\"--token_b\", type=str, default=\" Smith\", help=\"Token B (corrupt-consistent), usually with leading space\")\n",
        "    p.add_argument(\"--seed\", type=int, default=3407)\n",
        "    p.add_argument(\"--n_hot\", type=int, default=3)\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    args = parse_args()\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    bpe = BPETokenizer()\n",
        "    token_a_id = single_token_id(bpe, args.token_a)\n",
        "    token_b_id = single_token_id(bpe, args.token_b)\n",
        "\n",
        "    idx_clean = bpe(args.clean).to(device)\n",
        "    idx_corr = bpe(args.corrupt).to(device)\n",
        "\n",
        "    if idx_clean.shape != idx_corr.shape:\n",
        "        raise ValueError(\n",
        "            f\"Clean/corrupt token length mismatch: clean T={idx_clean.shape[1]} vs corrupt T={idx_corr.shape[1]}\"\n",
        "        )\n",
        "\n",
        "    # Find changed token position (expect exactly one token differs)\n",
        "    clean_ids = idx_clean[0].tolist()\n",
        "    corr_ids = idx_corr[0].tolist()\n",
        "    diffs = [i for i, (a, b) in enumerate(zip(clean_ids, corr_ids)) if int(a) != int(b)]\n",
        "    if len(diffs) != 1:\n",
        "        raise ValueError(f\"Expected exactly 1 differing token position, found {len(diffs)}: {diffs}\")\n",
        "    changed_pos = int(diffs[0])\n",
        "    T = int(idx_clean.shape[1])\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    n_layer = int(len(model.transformer.h))\n",
        "\n",
        "    print(f\"Seq len T={T}, changed token position={changed_pos}\")\n",
        "\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=True)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits not set on clean run.\")\n",
        "    score_clean = logit_diff_from_last_logits(model.last_logits[0], token_b_id=token_b_id, token_a_id=token_a_id)\n",
        "\n",
        "    score_corr = run_score(model, idx_corr, token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"score_clean  = {score_clean:.4f}\")\n",
        "    print(f\"score_corr   = {score_corr:.4f}\")\n",
        "    print(f\"gap (clean-corr) = {(score_clean - score_corr):.4f}\")\n",
        "\n",
        "    match_scores = torch.empty((n_layer, T), dtype=torch.float32)\n",
        "    for L in range(n_layer):\n",
        "        for P in range(T):\n",
        "            s = run_score(\n",
        "                model,\n",
        "                idx_corr,\n",
        "                token_a_id=token_a_id,\n",
        "                token_b_id=token_b_id,\n",
        "                layer_to_patch=L,\n",
        "                position_to_patch=P,\n",
        "                source_layer=L,\n",
        "                source_position=P,\n",
        "            )\n",
        "            match_scores[L, P] = float(s)\n",
        "\n",
        "    hot = select_hotspots(match_scores, score_clean=score_clean, k=args.n_hot)\n",
        "    cold = select_coldcell(match_scores, score_corr=score_corr, changed_pos=changed_pos)\n",
        "\n",
        "    print(\"\\nSelected coords:\")\n",
        "    for (L, P) in hot:\n",
        "        s = float(match_scores[L, P])\n",
        "        improvement = (score_corr - s)\n",
        "        print(f\"  HOT: (L={L}, P={P})  match_score={s:.4f}  improvement={improvement:.4f}\")\n",
        "    s_cold = float(match_scores[cold[0], cold[1]])\n",
        "    print(f\"  COLD: (L={cold[0]}, P={cold[1]})  match_score={s_cold:.4f}  improvement={(score_corr - s_cold):.4f}\")\n",
        "\n",
        "    print(\"\\n=== Wrong-source control table ===\")\n",
        "    print(\"coord | variant | source(L,P) | score | R (restoration) | C (closeness) | last_patch | last_patch_source\")\n",
        "    print(\"-\" * 110)\n",
        "\n",
        "    selected = hot + [cold]\n",
        "\n",
        "    for (L, P) in selected:\n",
        "        variants = build_wrong_source_variants(L, P, n_layer=n_layer, T=T)\n",
        "        results: List[PatchResult] = []\n",
        "\n",
        "        for (name, sL, sP) in variants:\n",
        "            s = run_score(\n",
        "                model,\n",
        "                idx_corr,\n",
        "                token_a_id=token_a_id,\n",
        "                token_b_id=token_b_id,\n",
        "                layer_to_patch=L,\n",
        "                position_to_patch=P,\n",
        "                source_layer=sL,\n",
        "                source_position=sP,\n",
        "            )\n",
        "            R = norm_restoration(s, score_clean=score_clean, score_corr=score_corr)\n",
        "            C = norm_closeness(s, score_clean=score_clean, score_corr=score_corr)\n",
        "\n",
        "            results.append(\n",
        "                PatchResult(\n",
        "                    target=(L, P),\n",
        "                    variant=name,\n",
        "                    source=(sL, sP),\n",
        "                    score=float(s),\n",
        "                    R=float(R),\n",
        "                    C=float(C),\n",
        "                    last_patch=model.last_patch,\n",
        "                    last_patch_source=model.last_patch_source,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Print rows\n",
        "        for r in results:\n",
        "            print(\n",
        "                f\"({r.target[0]:02d},{r.target[1]:02d}) | \"\n",
        "                f\"{r.variant:<9} | \"\n",
        "                f\"({r.source[0]:02d},{r.source[1]:02d})     | \"\n",
        "                f\"{r.score:>7.4f} | \"\n",
        "                f\"{r.R:>7.3f}        | \"\n",
        "                f\"{r.C:>7.3f}        | \"\n",
        "                f\"{r.last_patch} | {r.last_patch_source}\"\n",
        "            )\n",
        "\n",
        "        # Specificity index (FIX): use closeness-to-clean, not restoration fraction\n",
        "        c_match = max([rr.C for rr in results if rr.variant == \"MATCH\"], default=0.0)\n",
        "        c_wrong = [rr.C for rr in results if rr.variant != \"MATCH\"]\n",
        "        if c_wrong:\n",
        "            S = c_match - max(c_wrong)\n",
        "        else:\n",
        "            S = 0.0\n",
        "\n",
        "        print(f\"-> Specificity index S = C_match - max(C_wrong) = {S:.3f}\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "Seq len T=11, changed token position=1\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean  = -4.1241\n",
            "score_corr   = 5.6562\n",
            "gap (clean-corr) = -9.7803\n",
            "\n",
            "Selected coords:\n",
            "  HOT: (L=11, P=10)  match_score=-4.1241  improvement=9.7803\n",
            "  HOT: (L=0, P=1)  match_score=-4.0691  improvement=9.7254\n",
            "  HOT: (L=1, P=1)  match_score=-4.0673  improvement=9.7235\n",
            "  COLD: (L=11, P=2)  match_score=5.6562  improvement=0.0000\n",
            "\n",
            "=== Wrong-source control table ===\n",
            "coord | variant | source(L,P) | score | R (restoration) | C (closeness) | last_patch | last_patch_source\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "(11,10) | MATCH     | (11,10)     | -4.1241 |   1.000        |   1.000        | (11, 10) | (11, 10)\n",
            "(11,10) | WS-pos-   | (11,09)     | -2.8865 |   0.873        |   0.873        | (11, 10) | (11, 9)\n",
            "(11,10) | WS-layer- | (10,10)     | -5.6192 |   1.153        |   0.847        | (11, 10) | (10, 10)\n",
            "-> Specificity index S = C_match - max(C_wrong) = 0.127\n",
            "\n",
            "(00,01) | MATCH     | (00,01)     | -4.0691 |   0.994        |   0.994        | (0, 1) | (0, 1)\n",
            "(00,01) | WS-pos+   | (00,02)     |  1.8408 |   0.390        |   0.390        | (0, 1) | (0, 2)\n",
            "(00,01) | WS-pos-   | (00,00)     |  1.6059 |   0.414        |   0.414        | (0, 1) | (0, 0)\n",
            "(00,01) | WS-layer+ | (01,01)     | -3.6126 |   0.948        |   0.948        | (0, 1) | (1, 1)\n",
            "-> Specificity index S = C_match - max(C_wrong) = 0.047\n",
            "\n",
            "(01,01) | MATCH     | (01,01)     | -4.0673 |   0.994        |   0.994        | (1, 1) | (1, 1)\n",
            "(01,01) | WS-pos+   | (01,02)     |  1.8698 |   0.387        |   0.387        | (1, 1) | (1, 2)\n",
            "(01,01) | WS-pos-   | (01,00)     |  1.5902 |   0.416        |   0.416        | (1, 1) | (1, 0)\n",
            "(01,01) | WS-layer+ | (02,01)     | -3.9423 |   0.981        |   0.981        | (1, 1) | (2, 1)\n",
            "(01,01) | WS-layer- | (00,01)     | -4.1378 |   1.001        |   0.999        | (1, 1) | (0, 1)\n",
            "-> Specificity index S = C_match - max(C_wrong) = -0.004\n",
            "\n",
            "(11,02) | MATCH     | (11,02)     |  5.6562 |  -0.000        |   0.000        | (11, 2) | (11, 2)\n",
            "(11,02) | WS-pos+   | (11,03)     |  5.6562 |  -0.000        |   0.000        | (11, 2) | (11, 3)\n",
            "(11,02) | WS-pos-   | (11,01)     |  5.6562 |  -0.000        |   0.000        | (11, 2) | (11, 1)\n",
            "(11,02) | WS-layer- | (10,02)     |  5.6562 |  -0.000        |   0.000        | (11, 2) | (10, 2)\n",
            "-> Specificity index S = C_match - max(C_wrong) = 0.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python wrong_source_control_driver.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 78%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                     [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m92 passed\u001b[0m\u001b[32m in 42.19s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "=== Pair summary ===\n",
            "Clean tokens:   11\n",
            "Corrupt tokens: 11\n",
            "Same length?    True\n",
            "Diff count:     1\n",
            "Diff positions: [1]\n",
            "One-token diff? True\n",
            "\n",
            "number of parameters: 124.44M\n",
            "Seq len T=11, n_layers=12\n",
            "\n",
            "Baselines:\n",
            "score_clean = -4.124077\n",
            "score_corr  = 5.656242\n",
            "gap(clean-corr) = -9.780319\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 885x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 885x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAJOCAYAAAAnL7bnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAiLFJREFUeJzs3XdcU1f/B/BPwghDlrIVBNwbVKROtFVx1FZr66qCo7WOVqtdrsfR4WirtcNKa+us21brY9XWvRUH7l1QVARBpmyS8/vDH3mMzITATcLn/Xrl1ebk3uSbawgfzrnnXJkQQoCIiIiIqgy51AUQERERUeViACQiIiKqYhgAiYiIiKoYBkAiIiKiKoYBkIiIiKiKYQAkIiIiqmIYAImIiIiqGAZAIiIioiqGAZCIiIioimEAJDJhPj4+GD58uEbbrVu30L17dzg4OEAmk2Hbtm1YuXIlZDIZ7ty5o9XzDx8+HD4+Pnqrl4iIKgcDoJEq+IVd3O3kyZMAgD179kAmk2HOnDmFniM6Oho2NjZ4/fXXMXv27BKfr+DWuXNnAE9/8T/brlAoUL9+fcycORPZ2dnF1j1gwADIZDJ88sknWr3fjRs3YujQoahXr55GHVK7c+cORowYgTp16sDKygru7u7o1KkTZs2aJXVpxQoLC8OlS5fwxRdfYM2aNWjdurXenjszMxOzZ8/GwYMH9facUjh+/Dhmz56NlJSUQo/NnTsX27Ztq/SanlfwMyuXy3Hv3r1Cj6elpcHa2hoymQzvvvtukc9x7do1yGQyWFlZabzX53++i7s9+8fF1q1b0bNnTzg7O8PS0hKenp4YMGAA9u/fr97m4MGDkMlk2LJlS5H1DB8+HNWqVdPtgOjJuHHjIJfLkZSUpNGelJQEuVwOhUJR6DsuKioKMpkM06ZNA/D0e+HZ4ySXy1G9enX07NkTJ06cKPa1jx07hn79+sHNzQ0KhQI+Pj545513EBMTU2jbgn9/Nzc3ZGZmFnrcx8cHL7/8cqH2nJwcfP/99+jQoQOcnJzU/1avvPIK1q9fD6VSWabjpM13nxACa9asQadOneDo6AgbGxs0a9YMn376KTIyMspcOwCcOXMGMpkMK1euLHQsCm4WFhbw8fHBhAkTivwZBrT7vBZ327BhQ5mOlaEyl7oAKp9PP/0Uvr6+hdrr1q0LAOjWrRuGDBmCefPmYfDgwahfv756m3HjxsHCwgLfffcdEhMT1fsAwJMnTzB27Fj069cPr732mrrdzc1N/f8KhQK//PILACA1NRV//vknPvvsM/z7779Yu3ZtoZrS0tLw3//+Fz4+Pli/fj3mz58PmUxWpve5dOlSnD17FoGBgXj8+HGZ9qlot2/fRmBgIKytrTFy5Ej4+Pjg4cOHOHfuHBYsWFBk6K5sN27cgFz+v7/zsrKycOLECUyfPl0jFAwbNgyDBg2CQqHQ6vmXLVsGlUqlvp+Zmal+34YS0nVx/PhxzJkzB8OHD4ejo6PGY3PnzsXrr7+Ovn37SlLb8xQKBdavX4+PP/5Yo/2PP/4odd/ffvsN7u7uSE5OxpYtW/DWW28BAN555x107dpVvV10dDRmzpyJ0aNHo2PHjur2OnXqQAiBkSNHYuXKlQgICMDkyZPh7u6Ohw8fYuvWrXjppZdw7NgxtGvXTk/vuGJ16NABS5cuxbFjx9CnTx91+/HjxyGXy5GXl4czZ86gQ4cO6seOHTum3vdZgwcPRq9evaBUKnHz5k38+OOP6NKlC06fPo1mzZppbPv9999j4sSJ8PPzw3vvvQcPDw9cu3YNv/zyCzZu3IidO3cWeQwfPXqEpUuX4oMPPij1vSUkJKBnz544e/YsQkJCMGPGDFSvXh1xcXHYu3cvhgwZgtu3b+M///lPic+jzXefUqnEkCFDsGnTJnTs2BGzZ8+GjY0Njhw5gjlz5mDz5s3Yu3evxu8WXS1duhTVqlVDRkYG9u3bh++//x7nzp3D0aNH1dvo8nmdMGECAgMDC71e27Zty12zpAQZpRUrVggA4vTp06VuGx8fL5ycnESXLl3UbevXrxcAxHfffVfkPgkJCQKAmDVrVpGPh4WFCVtbW402lUolXnjhBSGTyURcXFyhfZYvXy4sLCzE/v37BQBx8ODBUmsvEBMTI5RKpRBCiCZNmojg4OAy71tRxo0bJ8zNzcWdO3cKPRYfHy9BRaW7e/euACC++uqrCnn+0j43xuKrr74SAER0dHShx2xtbUVYWJheXy8rK0v9+S6rWbNmCQDitddeE/7+/oUe79atm+jfv78AIMaPH1/ocZVKJXx8fMTkyZNFv379ROfOnYt9rdOnTwsAYsWKFYUeKzhW77//vlCpVIUeX716tTh16pQQQogDBw4IAGLz5s1Fvk5R3yuVreBn5OOPP9ZonzJliggICBANGzYU8+bN03hs9OjRQi6Xi+TkZCGEENHR0UX+nO3atUsAEGPHjtVoP3r0qJDL5aJjx44iIyND47Hbt28LNzc34eHhIZKSktTtBf/+/v7+ws3NTWRmZmrsV7t2bdG7d2+NtpCQECGXy8Xvv/9e5Hs/ffq0+O2334o5Mv+jzXff3LlzBQDx4YcfFtp2+/btQi6Xix49epRa+7M1Pv9ZLDgWCQkJGtsOHDhQAFB//oTQ7+fV2HEIuApwdXXFggULcODAAaxatQopKSmYNGkSAgMDMX78eL29jkwmQ4cOHSCEQFRUVKHH165di27duqFLly5o1KhRkb2ExfHy8tLoyTIE//77L2rVqoXatWsXeszV1VXjfsGQxj///AN/f39YWVmhcePGRfbSpKSk4P3334eXlxcUCgXq1q2LBQsWaPS0AYBKpcK3336LZs2awcrKCi4uLujRowfOnDmj8boFw3SzZ89W1/rRRx9BJpOpz98r7hzAXbt2ITg4GHZ2drC3t0dgYCDWrVunfvzZcwDv3LkDFxcXAMCcOXPUwySzZ8/GihUrIJPJEBkZWej9zp07F2ZmZnjw4EERR/mp9PR0vP/++/Dx8YFCoYCrqyu6deuGc+fOaWx36tQp9OrVC05OTrC1tUXz5s3x7bffqh+/ePEihg8fDj8/P/Ww1ciRIzV6lWfPno2PPvoIAODr66t+HwXDehkZGVi1alWRw6APHjzAyJEj1UN4TZo0wfLlyzVqLBhW2rBhA2bMmIGaNWvCxsYGaWlpyMvLw/Xr1/Hw4cNij8XzhgwZgvPnz+P69evqtri4OOzfvx9Dhgwpdr9jx47hzp07GDRoEAYNGoTDhw/j/v37ZX5d4GmP8rx589CwYUN8/fXXRfboDxs2DG3atNHqeUtS8Dp3794t9NjUqVNhaWmJ5ORkAE/Pd+3fvz/c3d1hZWWFWrVqYdCgQUhNTS32+b29veHl5aXu1Stw7NgxtG/fHu3atSvysSZNmhTqLX5eQe/pv//+q9H+2WefQSaTYdWqVbCxsdF4rE6dOvjyyy/x8OFD/PTTT4Wec+bMmYiPj8fSpUtLfO0TJ07g77//xujRozVGdZ7VunVrvPnmmyU+T0H9Zfnuy8rKwldffYX69etj3rx5hbbt06cPwsLCsHv3bvVpS/r0/PGW4vNqyAzrNyppLTU1FYmJiRq3ooZI33rrLbRv3x4ffvghxo0bh4SEBPz00096D1UFAcLJyUmjPTY2FgcOHMDgwYMBPB0a2bJlC3Jzc/X6+pWpdu3auHfvnsY5IyW5desWBg4ciJ49e2LevHkwNzfHG2+8gT179qi3yczMRHBwMH777TeEhobiu+++Q/v27TF16lRMnjxZ4/lGjRqlDooLFizAlClTYGVlVewX6WuvvYZvvvkGwNPjv2bNGixevLjYeleuXInevXsjKSkJU6dOxfz58+Hv74/du3cXub2Li4v6l1C/fv2wZs0arFmzBq+99hpef/11WFtbFxn6165di86dO6NmzZrF1jJmzBgsXboU/fv3x48//ogPP/wQ1tbWuHbtmnqbPXv2oFOnTrh69SomTpyIhQsXokuXLtixY4fGNlFRURgxYgS+//57DBo0CBs2bECvXr0ghFAfp4LP6TfffKN+Hy4uLlizZg0UCgU6duyobn/nnXcAAPHx8XjhhRewd+9evPvuu/j2229Rt25djBo1qsjj/Nlnn+Gvv/7Chx9+iLlz58LS0hIPHjxAo0aNMHXq1GKPxfM6deqEWrVqaQTzjRs3olq1aujdu3ex+61duxZ16tRBYGAg+vTpAxsbG6xfv77MrwsAR48eRVJSEoYMGQIzM7My75eenl7oeysxMRE5OTml7ltwHvGmTZsKPbZp0yZ0794dTk5OyM3NRUhICE6ePIn33nsPS5YswejRoxEVFVXseWEFOnTogDNnzqjryc3NxenTp9GuXTu0a9cOx48fV39ekpOTcfXq1ULDv0Up6vsxMzMT+/btQ8eOHYs8nQcABg4cCIVCofFZLtCxY0e8+OKL+PLLL5GVlVXsa//3v/8FAAwdOrTUOktT1u++o0ePIjk5GUOGDIG5edFnnIWGhgJAke+tvJ4/3vr+vBZ8BoyWtB2QpKuCIeCibgqFosh9Ll++LCwsLNTd3yUp6xBwQkKCSEhIELdv3xZff/21kMlkomnTpoW61r/++mthbW0t0tLShBBC3Lx5UwAQW7du1fq9G8oQ8OXLl4W1tbV6GGbixIli27ZthYZwhHg6pAFAY+glNTVVeHh4iICAAHXbZ599JmxtbcXNmzc19p8yZYowMzMTMTExQgihHkafMGFCodd69tjXrl1bY7iyuKGpgs9TwZBnSkqKsLOzE0FBQSIrK6vY5w8LCxO1a9dW3y/pczN48GDh6empMdR57ty5YocWn+Xg4FDkMGaB/Px84evrK2rXrq0ehiuq3ueHyYT43+kQhw8fVrfpMgQ8atQo4eHhIRITEzXaBw0aJBwcHNSvXTCs5OfnV6iegn+fsgwxPzvs9eGHH4q6deuqHwsMDBQjRowQQogih4Bzc3NFjRo1xPTp09VtQ4YMES1atCjytYobAv7222+1+jkueO8l3coyBNy2bVvRqlUrjbaIiAgBQKxevVoIIURkZKTOw3dLliwRAMSRI0eEEEKcOHFCABB3794VV69eFQDElStXhBBC7NixQwAQa9euVe9f8O84Z84ckZCQIOLi4sSRI0dEYGBgoZrOnz8vAIiJEyeWWFPz5s1F9erV1fef/fc/dOiQACAWLVqkfvz5YdR+/foJACIlJUXjebOystTf4wkJCYV+fopS1u++xYsXl/r5SEpKUp/KUFztzyppCPjGjRsiISFB3LlzRyxfvlxYW1sLFxcXdV36/rw+fPiwTM9jqNgDaOSWLFmCPXv2aNx27dpV5Lb29vawtLQEAHTv3r3cr52RkQEXFxe4uLigbt26+PDDD9G+fXv8+eefhbrW165di969e8POzg4AUK9ePbRq1UqrYWBD06RJE5w/fx5Dhw7FnTt38O2336Jv375wc3PDsmXLCm3v6emJfv36qe/b29sjNDQUkZGRiIuLAwBs3rwZHTt2hJOTk8Zfml27doVSqcThw4cBAL///jtkMlmRM+7KOrGmJHv27EF6erq6V1Efzx8aGqruCS6wdu1aWFtbo3///iXu6+joiFOnTiE2NrbIxyMjIxEdHY3333+/0DDcs/VaW1ur/z87OxuJiYl44YUXAKDQcLI2hBD4/fff0adPHwghNP7tQkJCkJqaWuj5w8LCNOoBng7ZCyE0ZjiWRcHJ+6dPn1b/t6Th3127duHx48fqnk7gaa/whQsXcOXKlTK/blpaGgCof67LaubMmYW+t/bs2VPm76WBAwfi7NmzGkOpGzduhEKhwKuvvgoAcHBwAAD8/fffRc6SLUlBb17B5IFjx46hZs2a8Pb2RsOGDVG9enX1MHBxE0AAYNasWXBxcYG7uzs6duyIa9euYeHChXj99dfV26SnpwMo/Rja2dmpj/fzOnXqhC5dupTYC1iw7/OzrMPDw9Xf4y4uLmXqySzrd19Z3lvBY8W9N200aNAALi4u8PHxwciRI1G3bl3s2rVLPayu789r9erVy12zlDgL2Mi1adOmzMt4vPvuu5DL5ahduzY++OADdO3aFRYWFjq/tpWVlXpY4f79+/jyyy/x6NGjQr/Url27hsjISISGhuL27dvq9s6dO2PJkiVIS0uDvb29znWUpiBc6cLd3b3Ex+vXr481a9ZAqVTi6tWr2LFjB7788kuMHj0avr6+GjMp69atWyg8FczKvnPnDtzd3XHr1i1cvHhRfS7d8x49egTg6Tktnp6eFfYFVPCLtWnTpnp7zm7dusHDwwNr167FSy+9BJVKhfXr1+PVV18t9Qv5yy+/RFhYGLy8vNCqVSv06tULoaGh8PPz06repKQkzJkzBxs2bFAfywIlnRdWmoSEBKSkpODnn3/Gzz//XOQ2z79eccN9uggICEDDhg2xbt06ODo6wt3dHS+++GKx2//222/w9fWFQqFQ/0zWqVMHNjY2WLt2LebOnVum1y34uS34RV9WzZo10/jZeLausnjjjTcwefJkbNy4EdOmTYMQAps3b0bPnj3VNfn6+mLy5MlYtGgR1q5di44dO+KVV17B0KFD1eGwOE2bNoWjo6NGyGvfvj2Ap39QtG3bFseOHcPbb7+NY8eOwcvLC97e3oWeZ/To0XjjjTeQnZ2N/fv347vvviu0zErBZ7+0Y5ienl7iz8ns2bMRHByM8PBwTJo0qdDjBfs+efJE4/33799f/XPzwQcfaNT3/Heng4OD+vu9LN99ZXlvZQ3AzyvqD9Hff/8d9vb2SEhIwHfffYfo6GiN30f6/rwaOwbAKuKPP/7A9u3bsXjxYtSrVw+9e/fGV199pV63ShdmZmYaPxQhISFo2LAh3nnnHWzfvl3dXvClPmnSpCK/mH7//XeMGDFC5zpK4+HhofO+oozneJiZmaFZs2Zo1qwZ2rZtiy5dumDt2rVaf2moVCp069at0JIeBZ5dxsfYmJmZYciQIVi2bBl+/PFHHDt2DLGxsWU6J2nAgAHo2LEjtm7din/++QdfffUVFixYgD/++AM9e/Yscw0DBgzA8ePH8dFHH8Hf3x/VqlWDSqVCjx49Ck2y0UbBvkOHDkVYWFiR2zRv3lzj/vN/KJXXkCFDsHTpUtjZ2WHgwIHFnt9bsBxTdnY26tWrV+jxdevW4YsvvihTT2/Dhg0BAJcuXarUZXE8PT3RsWNHbNq0CdOmTcPJkycRExODBQsWaGy3cOFCDB8+HH/++Sf++ecfTJgwAfPmzcPJkydRq1atYp9fLpejbdu26nP9jh07pvFd2a5dOyxfvlx9bmBx771evXrq74CXX34ZZmZmmDJlCrp06aL+w71u3bowNzfHxYsXi60nJycHN27cKPGP/U6dOqFz58748ssvMWbMmEKPF/xbXb58WR1mgacT7Ly8vABAPfJQ4PnvzhUrVhRaWL6k775GjRoBeDr5qrhjVPC+GzdurG6zsrIqtiezoDf3+ZGJgmPg7OwM4OkEk2bNmuHNN9/E2bNnIZfLJfu8GioGwCogPT0dEyZMQMuWLfHuu+/CzMwM/fv3x+eff47BgwfrrSfCw8MDkyZNwpw5c3Dy5Em88MILEEJg3bp16NKlC8aNG1don88++wxr166t0AD47CSLylDwJf38TM7bt29DCKHxi/XmzZsAoJ5JW6dOHTx58qTU4FinTh38/fffSEpKqpBewDp16gB4+svi2fUhS1NaaAgNDcXChQvx3//+F7t27YKLiwtCQkLK9NweHh4YN24cxo0bh0ePHqFly5b44osv0LNnT416izt2ycnJ2LdvH+bMmYOZM2eq22/duqXV+yjqMRcXF9jZ2UGpVErWUzBkyBDMnDkTDx8+xJo1a4rd7o8//kB2djaWLl2q/mVZ4MaNG5gxYwaOHTtWpqHAgsWE169fj2nTpml1Yn15DRw4EOPGjcONGzewceNG2NjYaKzbV6AgnMyYMQPHjx9H+/btER4ejs8//7zE5+/QoQN27dqF7du349GjRxqhqV27dpg+fTp27tyJrKysMh0rAJg+fTqWLVuGGTNmqCdT2draokuXLti/fz/u3r1b5MzaTZs2IScnp9jFkQvMnj0bnTt3LnK28Msvv4z58+dj7dq1Gu+lJM9/dzZp0qTE7Z//7uvQoQMcHR2xbt06TJ8+vcjPx+rVq9X1FahduzauXr1a5GvcuHFDvU1JqlWrhlmzZmHEiBHYtGkTBg0aJOnn1SBJd/ohlYc26wBOmDBByOVyjW3v378vqlWrJnr16lXkPrqsAyiEEImJicLGxka8+uqrQgghjhw5onFi9vO++OILIZfLxYMHD0p9HwUMZRLI4cOHRW5ubqH2jRs3FpqgUdIkkGfXcJs9e7YAIHbv3l3oeZOTk0VeXp4QouIngaSmpgo7OzvRpk0brSaBZGZmlnpCe/PmzUX37t2Fvb29eO+994rdrkB+fn6hE9eFeDrRoXXr1kIIIZRKZamTQFJTUwUAMXv2bI3Hx40bV+izvnTpUgFAREZGFnpdNzc39ef7WcOHDxeWlpbi0qVLhR579OiR+v9LWlssNzdXXLt2TcTGxhZ67HlFrX22ePHiQmvU4blJIC+99JLw8/Mr8jmzs7NFtWrVxJgxYzTaS1oHcP78+QKA+OCDD4pcV23NmjUVsg5gfHy8MDMzE7NmzRKenp5iwIABGo+npqaqf14KpKWlCblcXuSadM8rmFjRtm1bYWNjo/FcGRkZwtzcXLRt21YAEBcuXNDYt7ifMyGE+Pjjjwt9tg4dOiTkcrno3LlzoYlBUVFRwt3dvdh1AJ9f+65z587C3d1duLm5FZpI0a1bN2FmZia2bdtW5Hvu1KmTaNKkSckHRmj33ff5558LAOKTTz4ptP2OHTuEXC4XISEhGu3FTR7Jzs4Wbdq0Ea6uriInJ0fdXtyxyM3NFbVq1dL4jtXn59XYsQfQyO3atUtj/a8C7dq1g5+fH86ePYslS5Zg/PjxGsMHNWvWxKefforJkyfj999/L/Uk/LKqUaMGRowYgR9//BHXrl3D2rVrYWZmVuxyFK+88gqmT5+ODRs2FFrm5FmHDx9WT4BISEhARkaG+i/4Tp06oVOnTnqpXxsLFizA2bNn8dprr6mH986dO4fVq1ejevXqeP/99zW2r1+/PkaNGoXTp0/Dzc0Ny5cvR3x8PFasWKHe5qOPPsL27dvx8ssvY/jw4WjVqhUyMjJw6dIlbNmyBXfu3IGzszO6dOmCYcOG4bvvvsOtW7fUQ5hHjhxBly5dir30V1nZ29vjm2++wVtvvYXAwEAMGTIETk5OuHDhAjIzM7Fq1aoi97O2tkbjxo2xceNG1K9fH9WrV0fTpk01zs0LDQ3Fhx9+CKBsS1Kkp6ejVq1aeP3119GiRQtUq1YNe/fuxenTp7Fw4UIAT4fsli5dij59+sDf3x8jRoyAh4cHrl+/jitXruDvv/+Gvb09OnXqhC+//BJ5eXmoWbMm/vnnH0RHRxd6zVatWgF42mMzaNAgWFhYoE+fPrC1tUWrVq2wd+9eLFq0CJ6envD19UVQUBDmz5+PAwcOICgoCG+//TYaN26MpKQknDt3Dnv37i10abGiFCwDExYWpvVEEACYOHFiiY8XTMKZMGFCkY8rFAqEhIRg8+bN+O6778p0jvBHH32EK1euYOHChThw4ABef/11uLu7Iy4uDtu2bUNERASOHz+u9XspjaurK7p06YJFixYhPT0dAwcO1Hh8//79ePfdd/HGG2+gfv36yM/Px5o1a9QjIKVp06YNLC0tceLECXTu3FljGRMbGxu0aNECJ06cgKOjo1bnyk6cOBGLFy/G/Pnz1ZcS69SpE77++mtMnjwZzZs3x/Dhw9Wf34Kr7ezcubPQ8lpFmTVrFrp06VLkY7/99ht69OiBvn37omfPnujatSucnJzUVwI5fPhwmU6p0Oa7b8qUKYiMjMSCBQtw4sQJ9O/fH9bW1jh69Ch+++03NGrUqND3yejRo7F8+XK88cYbGDlyJAICAvD48WNs3LgRly9fxurVq9UTGktiYWGBiRMn4qOPPsLu3bvRo0cPnT6vR44cKfISp82bNy90aodRkTqBkm5KWgYG//+Xen5+vmjZsqXw9PQUqamphZ4jPz9f+Pv7i1q1aon09HSNx3TtARRCiH///VeYmZmJIUOGiBo1aoiOHTuW+F58fX01lkIpSsFfeEXdpLrqxLFjx8T48eNF06ZNhYODg7CwsBDe3t5i+PDh4t9//9XYtmBZg7///ls0b95cKBQK0bBhwyL/skxPTxdTp04VdevWFZaWlsLZ2Vm0a9dOfP311xp/defn54uvvvpKNGzYUFhaWgoXFxfRs2dPcfbsWY3X1aUHsMD27dtFu3bthLW1tbC3txdt2rQR69evVz/+fA+gEEIcP35ctGrVSlhaWhb57/Pw4UNhZmYm6tevX9LhVcvJyREfffSRaNGihbCzsxO2traiRYsW4scffyy07dGjR0W3bt3U2zVv3lx8//336sfv378v+vXrJxwdHYWDg4N44403RGxsbJF1fvbZZ6JmzZpCLpdrHJvr16+LTp06qZfBePb4xsfHi/HjxwsvLy9hYWEh3N3dxUsvvSR+/vln9TYl9SrougxMSfBMD+DChQsFALFv375it1+5cqUAIP788091W0k9gAW2bNkiunfvLqpXry7Mzc2Fh4eHGDhwoMYVf/R9JZBly5YJAMLOzq5QT3VUVJQYOXKkqFOnjrCyshLVq1cXXbp0EXv37i3z8xf08E2bNq3QYxMmTBAARM+ePQs9VlIPoBBPe4vNzMzE7du3NdoPHz4sXn31VeHs7Kz+Pnn77beLvOJGSf/+wcHBAkCRS6lkZWWJxYsXi7Zt2wp7e3thbm4u3N3dxcsvvyzWrl0r8vPziz0eBbT57hPiaQ/9ihUrRPv27YW9vb2wsrISTZo0EXPmzBFPnjwp8jWSk5PFpEmThK+vr7CwsBD29vaiS5cuYteuXVodi9TUVOHg4FBo1Eibz6uh/e7RF5kQxr6SIZHh8/HxQdOmTStksVNjk5iYCA8PD8ycObPUa44SEVHF4DqARFSpVq5cCaVSiWHDhkldChFRlcVzAImoUuzfvx9Xr17FF198gb59+6pnPhMRUeVjACSiSvHpp5+ql+H4/vvvpS6HiKhK4zmARERERFUMzwEkIiIiqmIYAImIiIiqGJ4DWAqVSoXY2FjY2dmV6dqYRERERFIQQiA9PR2enp7FXg+8AANgKWJjY9UXyiYiIiIydPfu3UOtWrVK3IYBsBR2dnYAnh5Me3t7iashIiIiKlpaWhq8vLzU2aUkDIClKBj2tbe3ZwAkIiIig1eWU9Y4CYSIiIioimEAJCIiIqpiGACJiIiIqhgGQCIiIqIqhgGQiIiIqIphACQiIiKqYhgAiYiIiKoYBkAiIiKiKoYBkIiIiKiKYQAkIiIiqmIYAImIiIiqGAZAIiIioiqGAZCIiIioimEAJCIiIqpiGACJiIiIqhgGQCIiIqIqxqgC4OHDh9GnTx94enpCJpNh27Ztpe5z8OBBtGzZEgqFAnXr1sXKlSsrvE4iIiIiQ2ZUATAjIwMtWrTAkiVLyrR9dHQ0evfujS5duuD8+fN4//338dZbb+Hvv/+u4EqJiIiIDJe51AVoo2fPnujZs2eZtw8PD4evry8WLlwIAGjUqBGOHj2Kb775BiEhIRVVJhEREZFBM6oeQG2dOHECXbt21WgLCQnBiRMnit0nJycHaWlpGjciIiIiU2LSATAuLg5ubm4abW5ubkhLS0NWVlaR+8ybNw8ODg7qm5eXV2WUSkRERCbo8ZMcqUsokkkHQF1MnToVqamp6tu9e/ekLomIiIiM0L5r8ej45QH8dfGh1KUUYlTnAGrL3d0d8fHxGm3x8fGwt7eHtbV1kfsoFAooFIrKKI+IiIhM1KYz9zD1j0tQqgS2X3iAXs3cIZPJpC5LzaQDYNu2bbFz506Ntj179qBt27YSVURERESmTAiBpYf+xZe7bwAA+reshfn9mxlU+AOMbAj4yZMnOH/+PM6fPw/g6TIv58+fR0xMDICnw7ehoaHq7ceMGYOoqCh8/PHHuH79On788Uds2rQJkyZNkqJ8IiIiMmEqlcCc/15Vh78xwXXw9RvNYWFmeHHLqHoAz5w5gy5duqjvT548GQAQFhaGlStX4uHDh+owCAC+vr7466+/MGnSJHz77beoVasWfvnlFy4BQ0RERHqlVAm8v/E8/nshFgAwo3cjvNXRT+KqiicTQgipizBkaWlpcHBwQGpqKuzt7aUuh4iIiAyQEAKf/3UNq47fwddvtEDfgJqVXoM2mcWoegCJiIiIDJFMJsP0Xo3wWsuaaOLpIHU5pTK8QWkiIiIiIxDzOBOfbLmInHwlAEAulxlF+APYA0hERESktcsPUjF8xWkkPsmBjcIMs/o0kbokrTAAEhEREWnh+O1EjF5zFk9y8tHIwx5jg+tIXZLWGACJiIiIymjHxVhM3ngBuUoVXvCrjp9DW8PeykLqsrTGAEhERERUBqtP3MGs7VcgBNCzqTu+GegPKwszqcvSCQMgERERUSkSn+Tgq79vQAhg6AvemPNKU5jJDevqHtpgACQiIiIqhXM1BX4JbY3Td5Iwvktdg7u0m7YYAImIiIiKkJ2nRFRCBhp7Pl1UOcivBoL8akhclX5wHUAiIiKi56Rm5mHYr6cw6OcTuB6XJnU5esceQCIiIqJnPEzNQtjyCNyMfwI7K3OkZ+dLXZLeMQASERER/b/bj9IR+msEYlOz4WavwKqRbdDQveTr6hojBkAiIiIiAOdikjFy5WmkZObBz8UWq0e2QS0nG6nLqhAMgERERFTlXbiXgiHLTiI7TwV/L0csHx6I6raWUpdVYRgAiYiIqMpr6GGHlt5OsDSX48c3W8LG0rQjkmm/OyIiIqJiCCEAADKZDApzMywLbQ1LczkszEx/kRQGQCIiIqpyVCqBL3ZeAwDM6N0IMpkMtoqqE4uqzjslIiIiApCbr8JHWy7gz/OxAIBXWniihZejtEVVMgZAIiIiqjIycvIx5rezOHIrEeZyGb56o3mVC38AAyARERFVEY+f5GDkytO4cD8VNpZm+PHNlujcwFXqsiTBAEhEREQm715SJkKXRyA6MQPVbS2xfHgg/Ktgz18BBkAiIiIyeVdi03DncQZqOlpjzag28HOpJnVJkmIAJCIiIpPXo6k7vh0UgCDf6nCzt5K6HMmZ/kI3REREVCXtuRqP2JQs9f1XWngy/P0/BkAiIiIyOWtO3sXoNWcQtjwCqVl5UpdjcDgETERERCZDCIFv9t7Cd/tuAQACfaujWhVa4LmseESIiIjIJChVAjO2Xcb6iBgAwPtd62HiS/Ugk8kkrszwMAASERGR0cvOU2Lihkj8fSUechnw6atNMfSF2lKXZbAYAImIiMjofbrjKv6+Eg9Lczm+G+SPHk09pC7JoDEAEhERkdGb+FI9RMakYFafxnjBr4bU5Rg8BkAiIiIySmnZebC3sgAAuNlb4a/3OkAu5/l+ZcFlYIiIiMjoRMYko/NXB/Hn+QfqNoa/smMAJCIiIqNy4MYjDFl2CkkZuVhz4i5UKiF1SUaHQ8BERERkNH4/ex+f/H4R+SqBTvVdsPTNluz50wEDIBERERmFnw//i7k7rwMA+gXUxIL+zWFpzsFMXTAAEhERkUETQmDuzmtYdiQaAPB2R19M7dmIPX/lwABIREREBk0mk8FM/rSnb1qvhhjdqY7EFRk/BkAiIiIyeJ/0aICXGrki0Ke61KWYBA6cExERkcFJysjFrD8vIztPCeBpLyDDn/6wB5CIiIgMyr2kTIQtj0BUYgYyc5X46o0WUpdUbpExyYhOzICvsy0CvJ2kLocBkIiIiAzHtYdpCFsegUfpOajpaI13go3/fL/5u64h/FCU+v6YYD9M6dlIwoo4BExEREQG4lTUYwz46QQepeeggZsdfh/bDnVdq0ldVrlExiRrhD8ACD8UhciYZIkqeooBkIiIiCS3+3Ichi2PQHp2Ptr4VMemd9rC3cFK6rLKLToxQ6v2ysIhYCIiIpLUk5x8TN96Cbn5KnRr7IbvBwfAysJM6rL0wtfZVqv2ysIeQCIiIpJUNYU5fg5tjbC2tbH0zZYmE/4AIMDbCWOC/TTaxgb7ST4RRCaE4BWUS5CWlgYHBwekpqbC3t5e6nKIiIhMglIlEJXwBPXc7KQupVJUxixgbTILh4CJiIioUmXnKfH+hvM4ejsRG0a/gKY1HaQuqcIFeDtJ3uv3LA4BExERUaVJzcpD2PII7L4Sh9x8FR6kZEldUpXEHkAiIiKqFPFp2QhbHoHrcemwU5jjp9BWaFfHWeqyqiQGQCIiIqpwUQlPELo8AveTs+Bip8DKEYFo4mn6Q7+GigGQiIiIKlRUwhO8Hn4CSRm58Klhg9Ujg+Bdw0bqsqo0BkAiIiKqULWcbNC0pgOSM3KxYkQgnKsppC6pymMAJCIiogohhIBMJoOluRxL32wJgadr/pH0OAuYiIiI9O6XI1GY89+rKFhu2FZhzvBnQPgvQURERHqjUgks2H0dPx2OAgC82NAVneq7SFwVPY8BkIiIiPQiT6nCJ1su4o/IBwCAKT0bomM9LvNiiBgAiYiIqNwyc/Mxbu05HLyRADO5DAv6N8frrWpJXRYVgwGQiIiIyiUpIxcjVp7GhXspsLKQ48c3W+LFhm5Sl0UlYAAkIiKicrl4PwWX7qfA0cYCv4YFolVtw7nmLRWNAZCIiIjKpXMDVywa4I+mNe1R19VO6nKoDBgAiYiISGtn7iTBzd4KXtWfXtGjb0BNiSsibXAdQCIiItLKP1fi8OYvpxC2PAJJGblSl0M6YA8gERERldn6iBhM33oJKgH4udjC2sJM6pJIBwyAREREVCohBL7ffxuL9twEAAxs7YUv+jWFuRkHE40RAyARERGVSKkSmL39CtacvAsAeLdLXXzQvT5kMpnElZGuGACJiIioRN/suYk1J+9CJgNmvdwYw9v7Sl0SlZPR9dsuWbIEPj4+sLKyQlBQECIiIkrcfvHixWjQoAGsra3h5eWFSZMmITs7u5KqJSIiMn5h7XxQz7Uavh8cwPBnIoyqB3Djxo2YPHkywsPDERQUhMWLFyMkJAQ3btyAq6troe3XrVuHKVOmYPny5WjXrh1u3ryJ4cOHQyaTYdGiRRK8AyIiIuOQnaeE1f9P8HCxU2DXxI4838+EGNW/5KJFi/D2229jxIgRaNy4McLDw2FjY4Ply5cXuf3x48fRvn17DBkyBD4+PujevTsGDx5caq8hERFRVRadmIHu3xzG5jP31G0Mf6bFaP41c3NzcfbsWXTt2lXdJpfL0bVrV5w4caLIfdq1a4ezZ8+qA19UVBR27tyJXr16Ffs6OTk5SEtL07gRERFVFRfvp+D1pccRk5SJ8EP/IjdfJXVJVAGMZgg4MTERSqUSbm6aF5d2c3PD9evXi9xnyJAhSExMRIcOHSCEQH5+PsaMGYNp06YV+zrz5s3DnDlz9Fo7ERGRMThyKwHvrDmLzFwlmta0x4rhbWBpbjR9RaQFk/5XPXjwIObOnYsff/wR586dwx9//IG//voLn332WbH7TJ06FampqerbvXv3it2WiIjIVPx5/gFGrjyNzFwl2tetgQ2j28LFTiF1WVRBjKYH0NnZGWZmZoiPj9doj4+Ph7u7e5H7/Oc//8GwYcPw1ltvAQCaNWuGjIwMjB49GtOnT4dcXjj/KhQKKBT8wBMRUdWx/Gg0Pt1xFQDwcnMPLBzQAgpzXuHDlBlND6ClpSVatWqFffv2qdtUKhX27duHtm3bFrlPZmZmoZBnZvb0Ay2EqLhiiYiIjEhKVh4AYHg7H3w3KIDhrwowmh5AAJg8eTLCwsLQunVrtGnTBosXL0ZGRgZGjBgBAAgNDUXNmjUxb948AECfPn2waNEiBAQEICgoCLdv38Z//vMf9OnTRx0EiYiIqrpJXeshwNsRneu78OoeVYRRBcCBAwciISEBM2fORFxcHPz9/bF79271xJCYmBiNHr8ZM2ZAJpNhxowZePDgAVxcXNCnTx988cUXUr0FIiIiyWXlKvHd/luY8GI9WFuaQSaToUuDwuvpkumSCY6FligtLQ0ODg5ITU2Fvb291OUQERGVS3JGLkatOo1zMSno3cwDS95sKXVJpCfaZBaj6gEkIiIi3cWmZCF0eQRuP3oCB2sLjOzgI3VJJBEGQCIioirgZnw6Qn+NQFxaNjwcrLB6ZBvUc7OTuiySCAMgERGRiTtzJwkjV55GWnY+6rlWw6qRbeDpaC11WSQhBkAiIiITlpuvwsQN55GWnY9WtZ3wa1hrONpYSl0WScxo1gEkIiIi7Vmay/Hjmy3xcnMP/DYqiOGPADAAEhERmRwhBO4+zlDfb+HliB+GtIS1JdfApacYAImIiEyISiUw579X0fPbIzh/L0XqcshAMQASERGZiJx8Jd7bEImVx+8gM1eJq7FpUpdEBoqTQIiIiExAenYe3llzFsf/fQwLMxkWDvDHKy08pS6LDBQDIBERkZF7lJ6NEStO40psGmwtzfDTsNboUM9Z6rLIgDEAEhERGbH4tGy8EX4CMUmZqGFriZUj2qBZLQepyyIDxwBIRERkxGrYWqKeazUICKweGQRfZ1upSyIjwABIRERkxMzN5PhhSEs8ycmHi51C6nLISHAWMBERkZH574VYzPzzMoQQAABrSzOGP9IKewCJiIiMyMpj0Ziz4yqEAAJ9qqMPZ/qSDhgAiYiIjIAQAl/9fQM/HvwXABDWtjZ6N/OQuCoyVgyAREREBi5fqcK0rZew6cx9AMCH3etjfJe6kMlkEldGxooBkIiIyIBl5Srx7rpz2Hf9EeQyYG6/ZhjUxlvqssjIMQASEREZsIv3U3DwZgIU5k9n+3Zr7CZ1SWQCGACJiIgMWJBfDSwa0AI1Ha3R2qe61OWQiWAAJCIiMjC3H6XDXC6Hz/8v6vyqf02JKyJTw3UAiYiIDMjZu8l4PfwEQpdHICE9R+pyyESxB5BMSmRMMqITM+DrbIsAbyepyyEi0sq+a/EYv+4csvNU8HW2hbmcs3ypYjAAksmYv+sawg9Fqe+PCfbDlJ6NJKyIiKjsNp25h6l/XIJSJfBiQ1f8MCQANpb8NU0Vg0PAZBIiY5I1wh8AhB+KQmRMskQVERGVjRACPx68jY+3XIRSJdC/ZS38NKwVwx9VKAZAMgnRiRlatRMRGYqVx+/gy903AABjO9fB1280h4UZfz1TxeKfF2QSfP9/plxZ24mIDMWr/jXx28m7GBJUG6M6+EpdTpnwfGvjxwBIJiHA2wljgv00hoHHBvvxi4mIDFKeUqXu5atua4m/JnSElYWZxFWVDc+3Ng0MgGQypvRshJAm7vyrlIgMWuKTHIxYcRpDgrwx+P8v6WYs4a+4861DmrjzO9fI8CQDMikB3k54rWUtfhERkUGKeZyJ15cex6UHqVi05yae5ORLXZJWeL616WAPIBERUSW4/CAVw1ecRuKTHNRyssbqkW1QTWFcv4Z5vrXpYA8gERFRBTt+OxGDfj6JxCc5aORhjz/GtoOfSzWpy9JawfnWz+L51sbJuP70ICIiMjJ/XXyISRvPI1epwgt+1fFzaGvYW1lIXZbOeL61aWAAJCIiqkDRiU+Qq1ShVzN3LBrgbzQTPkoS4O3E4GfkGACJiIgq0PgudeHrXA09mrrDjNf2JQPBcwCJiIj0KF+pwpIDt5Hx/zN8ZTIZejf3YPgjg8IASEREpCdZuUqM+e0cvvr7BsavOwchhNQlERWJQ8BERER6kJqZh1GrTuPM3WRYmssxuI03ZDL2+pFhYgAkIiIqp4epWQhbHoGb8U9gZ2WOX0JbI8ivhtRlERWLAZCIiKgcbj9KR+ivEYhNzYabvQKrRrZBQ3d7qcsiKhEDIBERkY5UKoGxv51DbGo2/FxssXpkG9RyspG6LKJScRIIERGRjuRyGb4Z6I+O9ZyxZUw7hj8yGgyAREREWopPy1b/f9OaDlgzKgjVbS0lrIhIOwyAREREZSSEQPihf9H5q4M4ezdJ6nKIdMYASEREVAYqlcDnf13D/F3XkZWnxNFbj6UuiUhnnARCRERUitx8FT7acgF/no8FAMzo3QhvdfSTuCoi3TEAEhERleBJTj7G/nYWR24lwlwuw9dvtEDfgJpSl0VULgyARERExUjNysOwX0/h4v1U2FiaYenQVgiu7yJ1WUTlxgBIRERUjGoKc3g4WOF+chZWDA9ECy9HqUsi0gsGQCIiomKYyWX4dlAAHqXlwLsG1/gj08FZwERERM848e9jzPrzMoQQAAArCzOGPzI57AEkkxIZk4zoxAz4OtsiwNtJ6nKIyMjsvPQQ7284j1ylCvXd7fBmUG2pSyKqEAyAZDLm77qG8ENR6vtjgv0wpWcjCSsiImOy5uRdzPzzMoQAQpq4oX/LWlKXRFRhOARMJiEyJlkj/AFA+KEoRMYkS1QRERkLIQQW7bmJ/2x7Gv6GBHnjxzdbwcrCTOrSiCoMAyCZhOjEDK3aiYgAQKkSmLb1Mr7bdwsA8H7Xeviib1OYyWUSV0ZUsTgETCbB19lWq3YiIgC4GpuGLWfvQS4DPn21KYa+wHP+qGpgACSTEODthDHBfhrDwGOD/TgRhIhK1KyWAxYO8IelmQw9mnpIXQ5RpZGJgnnuVKS0tDQ4ODggNTUV9vb2UpdDpeAsYCIqTVxqNjJz8+HnUk3qUoj0SpvMwnMAiYioyrj96An6Lz2OYb9GID4tW+pyiCTDIWAyGVwGhohKEhmTjJErTyM5Mw++zrbIzVdJXRKRZNgDSCaBy8AQUUkO3HiEIctOITkzDy1qOWDLmLbwqs6re1DVxQBIJoHLwBBRcX4/ex9vrzqDrDwlOtV3wbq3X0CNagqpyyKSFIeAySRwGRgiKsqf5x/gg80XAAD9AmpiQf/msDRn3wcRfwrIJBQsA/MsLgNDRMH1XVDPtRre7uiLhW+0YPgj+n9cBqYUXAbGuHAZGCJSqQTkz1zJ40lOPqopOOBFps+kl4FZsmQJfHx8YGVlhaCgIERERJS4fUpKCsaPHw8PDw8oFArUr18fO3furKRqqbIFeDvhtZa1GP6IqqiMnHwMX3kaq47fUbcx/BEVZlQ/FRs3bsTkyZMRHh6OoKAgLF68GCEhIbhx4wZcXV0LbZ+bm4tu3brB1dUVW7ZsQc2aNXH37l04OjpWfvFERFShHj/JwciVp3HhfirO3knCy809ONmDqBhGNQQcFBSEwMBA/PDDDwAAlUoFLy8vvPfee5gyZUqh7cPDw/HVV1/h+vXrsLCw0Ok1OQRMRGT47iVlImx5BKISM+BkY4HlwwM5EkBVjkkOAefm5uLs2bPo2rWruk0ul6Nr1644ceJEkfts374dbdu2xfjx4+Hm5oamTZti7ty5UCqVlVU2ERFVsGsP09B/6XFEJWagpqM1toxtx/BHVAqjGQJOTEyEUqmEm5ubRrubmxuuX79e5D5RUVHYv38/3nzzTezcuRO3b9/GuHHjkJeXh1mzZhW5T05ODnJyctT309LS9PcmiIhIr05GPcbbq88gPTsfDdzssGpkG7g7WEldFpHBM5oeQF2oVCq4urri559/RqtWrTBw4EBMnz4d4eHhxe4zb948ODg4qG9eXl6VWDEREWnj8oNUpGfno41PdWwa05bhj6iMjKYH0NnZGWZmZoiPj9doj4+Ph7u7e5H7eHh4wMLCAmZmZuq2Ro0aIS4uDrm5ubC0tCy0z9SpUzF58mT1/bS0NIZAIiIDNaqDLxxtLPFycw9YWZiVvgMRATCiHkBLS0u0atUK+/btU7epVCrs27cPbdu2LXKf9u3b4/bt21Cp/nfB75s3b8LDw6PI8AcACoUC9vb2GjciIjIMQgj8dvIu0rPzAAAymQyvt6rF8EekJaMJgAAwefJkLFu2DKtWrcK1a9cwduxYZGRkYMSIEQCA0NBQTJ06Vb392LFjkZSUhIkTJ+LmzZv466+/MHfuXIwfP16qt0BERDpSqgSmb7uMGdsuY/Tqs1CqjGYRCyKDYzRDwAAwcOBAJCQkYObMmYiLi4O/vz92796tnhgSExMDufx/mdbLywt///03Jk2ahObNm6NmzZqYOHEiPvnkE6neAhER6SA7T4n3N5zH7itxkMmAXs09YPbM1T6ISDtGtQ6gFLgOIBGRtFKz8jB69Rmcik6CpZkciwf5o1czD6nLIjI42mQWo+oBJCoNrwVMZFri07IRtjwC1+PSYacwx0+hrdCujrPUZREZPZ0CYEpKCrZu3YojR47g7t27yMzMhIuLCwICAhASEoJ27drpu06iUs3fdQ3hh6LU98cE+2FKz0YSVkRE5SGEwPi153A9Lh0udgqsHBGIJp4OUpdFZBK0mgQSGxuLt956Cx4eHvj888+RlZUFf39/vPTSS6hVqxYOHDiAbt26oXHjxti4cWNF1UxUSGRMskb4A4DwQ1GIjEmWqCIiKi+ZTIYv+jVDi1oO+H1MO4Y/Ij3SqgcwICAAYWFhOHv2LBo3blzkNllZWdi2bRsWL16Me/fu4cMPP9RLoUQlOXjjUbHtHAomMi7JGblwsn26VFcDdztsG98eMhknfBDpk1YB8OrVq6hRo0aJ21hbW2Pw4MEYPHgwHj9+XK7iiIioatkaeR8ztl7G8uGBCPJ7+vuG4Y9I/7QaAn42/OXk5CAjI6PM2xNVpM4NXLVqJyLD88uRKEzaeAEZuUpsvxArdTlEJk3rhaATEhLQs2dPVKtWDfb29njhhRdw+/btiqiNqMwCvJ0wJthPo21ssB+Hf4mMgEolMG/nNXz+1zUAwMj2vvjs1aYSV0Vk2rReB3DkyJHYtWsXJkyYACsrK/z000/w8PDAgQMHKqpGSXEdQOPCZWCIjEueUoVPtlzEH5EPAABTejbEO538OOxLpANtMovWAdDLywu//PILQkJCAAC3bt1Co0aNkJGRAYVCoXvVBooBkIioYmTnKTHmt7M4eCMBZnIZFvRvjtdb1ZK6LCKjpU1m0XoIODY2Fi1atFDfr1evHhQKBR4+fKh9pUREVGVZmslhqzCHlYUcy0JbMfwRVSKdFoI2MzMrdJ9XlCMiIm3I5TIsGtAC/z7KQGNPjrAQVSatA6AQAvXr19c4P+PJkycICAiAXP6/DsWkpCT9VEhERCbjRlw6NpyOwX96N4ZcLoPC3Izhj0gCWgfAFStWVEQdRERk4iKik/DWqtNIy86Hq50VxnauI3VJRFWW1gEwLCysIuog0gvOAiYyTP9cicN76yORk69C69pOGNLGW+qSiKo0nc4BJDJE83dd07ge8JhgP0zp2UjCiogIANZHxGD61ktQCaBrIzf8MCQAVhZmpe9IRBVG61nAZeHr64tRo0YhNpYruVPliIxJ1gh/ABB+KAqRMckSVUREQgh8t+8Wpv7xNPwNCvRC+NCWDH9EBqBCAmBYWBiUSiXat29fEU9PVEh0YtGXJSyunYgqXnRiBn7Y//RKUe+9WBfzXmsGc7MK+bVDRFqqkCHg2bNnV8TTEhXL19lWq3Yiqnh+LtXw7SB/PErPQVg7H6nLIaJn6P1PsaioKHTv3l3fT0tUIl4LmMgwpGXnISrhifp+z2YeDH9EBkjvPYDp6enYt2+fvp+WqFRTejZCSBN3zgImksij9GwMX34ayZm5+H1sO3g6WktdEhEVgydjkEm5GZ+OM3eScDM+XepSiKqU6MQM9F96HFcfpiFPKZCSmSd1SURUAi4DQyaj75KjOH8vFQCwLuIe1kfEYNv4DhJXRWT6Lt5PwYgVp/E4Ixe1a9hgzcggeNewkbosIioBewDJJGw8HaMOfwXO30vFxtMxElVEVDUcuZWAQT+fxOOMXDStaY8tY9ox/BEZAa17AAMCAjSuA/y8zMzMchVEpIsL91KKbR8YyCsOEFWEwzcTMGrVaeQpBdrXrYGfhrVGNQUHloiMgdY/qX379q2AMojKp4WXI9ZF3CuynYgqhr+3I+q62qGOiy0WDmgBhTkXeCYyFjIhhJC6CEOWlpYGBwcHpKamwt7eXupyqATPngMIAAFeDtjKcwCJ9EoIoTEKlJqZBzsrc8jlxY8MEVHl0CazsK+eTMa28R2w8XQMLtxLQQsvRw79EulZnlKFqX9cQkN3O7zV8em6mw42FhJXRUS60GoSSI8ePXDy5MlSt0tPT8eCBQuwZMkSnQsj0sXAQG/Mfa05wx+RnmXlKvHOmrPYcvY+5u+6jntJPN+byJhp1QP4xhtvoH///nBwcECfPn3QunVreHp6wsrKCsnJybh69SqOHj2KnTt3onfv3vjqq68qqm4iIqokyRm5GLnqNCJjUmBlIceSIS3hVZ0zfYmMmdbnAObk5GDz5s3YuHEjjh49itTUp+dcyWQyNG7cGCEhIRg1ahQaNWpUIQVXNp4DSERV2YOULIT+egr/JmTAwdoCy4e3Rqva1aUui4iKoE1mKfckkNTUVGRlZaFGjRqwsDC9c0EYAImoqroRl46w5RGIS8uGh4MVVo9sg3pudlKXRUTFqNRJIA4ODnBwcCjv0xARkYGJiH6MuLRs1HOthlUj2/DavkQmpFxXAlmzZg3at28PT09P3L17FwDwzTff4M8//9RLcUREJJ1hbX0wt18zbB7TluGPyMToHACXLl2KyZMno1evXkhJSYFSqQQAODk5YfHixfqqj4iIKtFfFx8iNTNPfX9IkDccbSwlrIiIKoLOAfD777/HsmXLMH36dJiZ/W/199atW+PSpUt6KY6IiCqHEAJLDtzG+HXn8Nbq08jJV0pdEhFVIJ3PAYyOjkZAQEChdoVCgYyMjHIVRURElUelEvh0x1WsPH4HABDoUx2WZuU6Q4iIDJzOP+G+vr44f/58ofbdu3ebzBIwRESmLidfifc2RKrD36w+jfFxj4Yal3sjItOjcw/g5MmTMX78eGRnZ0MIgYiICKxfvx7z5s3DL7/8os8aiYioAqRn5+GdNWdx/N/HsDCTYeEAf7zSwlPqsoioEugcAN966y1YW1tjxowZyMzMxJAhQ+Dp6Ylvv/0WgwYN0meNRERUASZvuoDj/z6GraUZfhrWGh3qOUtdEhFVknIvBA0AmZmZePLkCVxdXfVRk0HhQtBEZKpuP3qCsb+dxaIB/mhWi+u5Ehm7SrkSSHR0NPLz81GvXj2N9lu3bsHCwgI+Pj66PK3BYQAkIlPyJCcf1RT/G/xRqgTM5Dzfj8gUaJNZdJ4EMnz4cBw/frxQ+6lTpzB8+HBdn5aoXCJjkvHHufuIjEmWuhQig3P0ViI6LtiPo7cS1W0Mf0RVk87nAEZGRqJ9+/aF2l944QW8++675SqKSBfzd11D+KEo9f0xwX6Y0pMz0okAYPuFWHyw6TzylAKrTtzh+X5EVZzOPYAymQzp6emF2lNTU9VXBSGqLJExyRrhDwDCD0WxJ5AIwIpj0ZiwPhJ5SoHezTzww5DCa7gSUdWicwDs1KkT5s2bpxH2lEol5s2bhw4dOuilOKKyik4sevHx4tqJqgIhBL7cfR1z/nsVABDatja+GxwAhblZKXsSkanTeQh4/vz5CA4ORoMGDdCxY0cAwJEjR5CWlob9+/frrUCisvB1ttWqncjU5StVmLb1EjaduQ8A+LB7fYzvUpcLPBMRgHL0ADZp0gQXL17EgAED8OjRI6SnpyM0NBTXr19H06ZN9VkjUakCvJ0wJthPo21ssB8CvJ0kqohIWnKZDHlKAbkMmP9aM7z7Yj2GPyJS02kZmLy8PPTo0QPh4eGFloExNVwGxrhExiQjOjEDvs62DH9U5eUpVTh/LwWBPtWlLoWIKkGFLwNjYWGBixcv6lQcUUUK8HbCay1rMfxRlRSbkoV5O69BqXr6d72FmZzhj4iKpPMQ8NChQ/Hrr7/qsxYiItLRzfh09F96HD8djsI3e25KXQ4RGTidJ4Hk5+dj+fLl2Lt3L1q1agVbW82T7RctWlTu4oiIqHRn7yZh5MozSM3KQx0XWwwO8pa6JCIycDoHwMuXL6Nly5YAgJs3Nf/a5InGRESVY+/VeLy7/hyy81QI8HbE8rBAONlaSl0WERk4nQPggQMH9FkHERFpadOZe5j6xyUoVQIvNnTFD0MCYGOp89c6EVUh/KYgIjJC8WnZmPnnZShVAv1b1sL8/s1gYabzad1EVMXoHAC7dOlS4lAvF4MmIqo4bvZW+H5wS0TGJOOjkAY89YaItKJzAPT399e4n5eXh/Pnz+Py5csICwsrb11ERPScnHwl4lKzUbvG00l33Rq7oVtjN4mrIiJjpHMA/Oabb4psnz17Np48eaJzQUREVNiTnHyMWXMWN+LT8cfYdvCqbiN1SURkxPR+wsjQoUOxfPlyfT8tEVGVlfgkB4N+PoGjtxORkZOPe8mZUpdEREZO75NATpw4ASsrK30/LVGZ8FJwZGpiHmcidPkp3Hmcieq2llgxPBAtvBylLouIjJzOAfC1117TuC+EwMOHD3HmzBn85z//KXdhRNqav+sawg9Fqe+PCfbDlJ6NJKyIqHwuP0jF8BWnkfgkB7WcrLF6ZBv4uVSTuiwiMgE6B0AHBweN+3K5HA0aNMCnn36K7t27l7swIm1ExiRrhD8ACD8UhZAm7uwJJKN04V4K3vzlFJ7k5KORhz1WjQiEqz1HV4hIP3QOgCtWrNBnHUTlEp2YUWw7AyAZozqu1eDrbAtbhRl+Dm0NeysLqUsiIhNS7nMAz549i2vXrgEAmjRpgoCAgHIXRaQtX2dbrdqJDF01hTlWjWwDG0szWFmYSV0OEZkYnQPgo0ePMGjQIBw8eBCOjo4AgJSUFHTp0gUbNmyAi4uLvmokKlWAtxPGBPtpDAOPDfZj7x8ZDSEEFv5zEzYKM4zrXBcAUJ3X9CWiCqJzAHzvvfeQnp6OK1euoFGjpyfaX716FWFhYZgwYQLWr1+vtyKJymJKz0YIaeLOWcBkdPKVKkzfehkbz9wDAHSu74rGnvYSV0VEpkwmhBC67Ojg4IC9e/ciMDBQoz0iIgLdu3dHSkqKPuqTXFpaGhwcHJCamgp7e34hE5F+ZeUq8d76SOy9Fg+5DPi8bzMMCfKWuiwiMkLaZBadF4JWqVSwsCh8UrKFhQVUKpWuT1uqJUuWwMfHB1ZWVggKCkJERESZ9tuwYQNkMhn69u1bYbUREWkjJTMXw349hb3X4mFpLsfSoa0Y/oioUugcAF988UVMnDgRsbGx6rYHDx5g0qRJeOmll/RS3PM2btyIyZMnY9asWTh37hxatGiBkJAQPHr0qMT97ty5gw8//BAdO3askLqIiLT1MDULb4SfwJm7ybCzMseakW0Q0sRd6rKISEeRMcn449x9RMYkS11KmegcAH/44QekpaXBx8cHderUQZ06deDr64u0tDR8//33+qxRbdGiRXj77bcxYsQING7cGOHh4bCxsSnx0nNKpRJvvvkm5syZAz8/vwqpi4hIW8duP8atR0/gZq/A5jFtEeRXQ+qSiEhH83ddQ78fj2Pypgvo9+NxzN91TeqSSqXzJBAvLy+cO3cOe/fuxfXr1wEAjRo1QteuXfVW3LNyc3Nx9uxZTJ06Vd0ml8vRtWtXnDhxotj9Pv30U7i6umLUqFE4cuRIhdRGRKSt11vVQmZuPl5s6IpaTjZSl0NEOjLWCxGUax1AmUyGbt26oVu3bgBQoRM/EhMToVQq4ebmptHu5uamDqDPO3r0KH799VecP3++zK+Tk5ODnJwc9f20tDSd6iUiet7RW4lo4mkPp/9f3iW0rY+0BRFRuRnrhQh0HgJesGABNm7cqL4/YMAA1KhRAzVr1sSFCxf0Ulx5pKenY9iwYVi2bBmcnZ3LvN+8efPg4OCgvnl5eVVglURUVWw+cw9hKyIwYuVpZObmS10OEZVRaef2FXfBgSO3Egz6vECdewDDw8Oxdu1aAMCePXuwZ88e7Nq1C5s2bcJHH32Ef/75R29FAoCzszPMzMwQHx+v0R4fHw9398InTv/777+4c+cO+vTpo24rmJ1sbm6OGzduoE6dOoX2mzp1KiZPnqy+n5aWxhBIRDoTQiD8UBQW7H46UuHnYgsLM53/9iaiSjR/1zWN4d0xwX6Y0rORxjYB3k7oF+CJrZGxGu1bI2M12oraV0o6fwvFxcWpg9GOHTswYMAAdO/eHR9//DFOnz6ttwILWFpaolWrVti3b5+6TaVSYd++fWjbtm2h7Rs2bIhLly7h/Pnz6tsrr7yCLl264Pz588WGOoVCAXt7e40bEZEuVCqBT3dcVYe/d4L9sPCNFgyAREaguHP7iurN61iv9KufFbevVHTuAXRycsK9e/fg5eWF3bt34/PPPwfw9K9dpVKptwKfNXnyZISFhaF169Zo06YNFi9ejIyMDIwYMQIAEBoaipo1a2LevHmwsrJC06ZNNfYvuGTd8+1ERPqWm6/Ch5svYPuFpz0AM3o3wlsduRIBkbHQ5ty+sl53fkNEjMGcF6hzAHzttdcwZMgQ1KtXD48fP0bPnj0BAJGRkahbt67eCnzWwIEDkZCQgJkzZyIuLg7+/v7YvXu3emJITEwM5HL+ZU1E0vvPtsvYfiEW5nIZvn6jBfoG1JS6JCLSQnGhrqj2oq5HX5TkzFy91KYPOl8KLi8vD99++y3u3buH4cOHIyAgAADwzTffwM7ODm+99ZZeC5UKLwVHRLqITsxA6PJT+LxvMwTXL314iIgMz/PnAI4N9sMnJZzHFxmTjOjEDPyb8ARLDvxb6PEF/ZthYGDFXe1Hm8yicwAsq969e+OXX36Bh4dHRb5MhWEAJKKyys5TwsrCTH0/N18FS3PdRyUKfpn4OtsazLARUVWj689h3yVHcf5eqvp+gJcDto7vUBElqhlUALSzs8OFCxeM9iocDIBEVBZXYlPx9qozmPtaM3Ru4Fru5yvL7EMiMmwbT8fgwr0UtPByrNCevwLaZJZyLQRNRETAiX8fY/TqM0jPycd3+24huL4LZDKZzs9nrFcWIKpsht5LPjDQu1KCny4YAImIymHnpYd4f8N55CpVaONbHctCW5cr/AHGe2UBosrEXvLy4ZRZIiIdrTlxB+PXnUOuUoUeTdyxemQbOFhblPt5tZl9SFQVabNGHxWNAZCISEtCCCz65wb+8+cVCAEMCfLGkjdbakwAKY+CJSWeNTbYj71/RP+vpF5yKhsOARMR6SA+LQcA8H7Xepj4Ur1yD/s+b0rPRghp4m7Q5zcRSYW95OVX4QFw2rRpqF69ekW/DBFRpZHJZPiiX1OENHXDiw3dKux1ArydGPyIilDUwsvsJdeOzsvAbN++vegnlMlgZWWFunXrwtfXt1zFGQIuA0NEAJCalYdfj0Zjwot1Yc5r+RIZBEOfBVzZKmUZmL59+0Imk+H5/FjQJpPJ0KFDB2zbtg1OTvxHISLjFZeajbDlEbgRn4707DzM6tNE6pKICOwlLw+d/4zds2cPAgMDsWfPHqSmpiI1NRV79uxBUFAQduzYgcOHD+Px48f48MMP9VkvEVGluv3oCfovPY4b8elwtVNgQGsvqUsiIio3nXsAJ06ciJ9//hnt2rVTt7300kuwsrLC6NGjceXKFSxevBgjR47US6FERJUtMiYZI1eeRnJmHvycbbFqZBt4VbeRuiwionLTOQD++++/RY4v29vbIyrq6UmZ9erVQ2Jiou7VERFJ5MCNRxj32zlk5SnRopYDlg8PRI1qCqnLIiLSC52HgFu1aoWPPvoICQkJ6raEhAR8/PHHCAwMBADcunULXl4cLiEi45KalYcJ6yORladEp/ouWPf2Cwx/RGRSdO4B/PXXX/Hqq6+iVq1a6pB37949+Pn54c8//wQAPHnyBDNmzNBPpURElcTB2gLfDQ7AjgsPMe+1ZrA056xfIjItOi8DAwAqlQr//PMPbt68CQBo0KABunXrBrncdL4suQwMUdWgUgk8TMtGTUdrqUshItKJNpmlXAGwKmAAJDJ9ufkqfLzlAo7eTsSWMe3gw6sJEJERqpR1AAFg37592LdvHx49egSVSqXx2PLly8vz1ERElSIjJx9jfjuLI7cSYS6X4drDNAZAIjJ5OgfAOXPm4NNPP0Xr1q3h4eGh9+tgEhFVtMdPcjBy5WlcuJ8KawszLB3aEp0buEpdFhFRhdM5AIaHh2PlypUYNmyYPushIqoU95IyEbo8AtGJGXCyscDy4YG8ogARVRk6B8Dc3FyNRaCJiIxFVMITDPr5JB6l56CmozVWj2qDOi7VpC6LiKjS6Dxd96233sK6dev0WQsRUaVwd7CCh6M1Grrb4Y9x7Rj+iKjK0bkHMDs7Gz///DP27t2L5s2bw8LCQuPxRYsWlbs4IqKKYGNpjpXDAyGXy+BgbVH6DkREJkbnAHjx4kX4+/sDAC5fvqzxGCeEEJGhWXvqLh4/ycWEl+oBAJxsLSWuiIhIOjoHwAMHDuizDiKiCiGEwLf7bmHx3lsAgDa+1fGCXw2JqyIikla51gEscP/+fQBArVq19PF0RER6oVQJzPzzMtaeigEATHipHoJ8q0tcFRGR9HSeBKJSqfDpp5/CwcEBtWvXRu3ateHo6IjPPvus0KLQRESVLTtPifFrz2HtqRjIZMBnfZticrf6PEWFiAjl6AGcPn06fv31V8yfPx/t27cHABw9ehSzZ89GdnY2vvjiC70VSUSkjdSsPIxefQanopNgaSbH4kH+6NXMQ+qyiIgMhs4BcNWqVfjll1/wyiuvqNuaN2+OmjVrYty4cQyARCSZ47cTcSo6CXYKc/wc2hpt6/CcPyKiZ+kcAJOSktCwYcNC7Q0bNkRSUlK5iiIiKo+ezTwwu09jBPpWRxNPB6nLISIyODqfA9iiRQv88MMPhdp/+OEHtGjRolxFERFp69L9VCQ+yVHfH97el+GPiKgYOvcAfvnll+jduzf27t2Ltm3bAgBOnDiBe/fuYefOnXorkIioNIduJmDsb2dR17Ua1r39Aqop9LLAARGRydK5BzA4OBg3b95Ev379kJKSgpSUFLz22mu4ceMGOnbsqM8aiYiKtS3yAUatPI3MXCWv6kFEVEY6/Zmcl5eHHj16IDw8nJM9iEgyvxyJwud/XQMAvOrvia9ebwFLc53/riUyapExyYhOzICvsy0CvJ2kLocMnE4B0MLCAhcvXtR3LUREZaJSCSzYfR0/HY4CAIzq4IvpvRpBLucaf1Q1zd91DeGHotT3xwT7YUrPRhJWRIZO5z+Vhw4dil9//VWftRARlcnCPTfU4W9qz4aY0Zvhj6quyJhkjfAHAOGHohAZkyxRRWQMdD5TOj8/H8uXL8fevXvRqlUr2Nraajy+aNGichdHRFSUQYHe+OPcA3zQvQFeb8VLUFLVFp2YUWw7h4KpODoHwMuXL6Nly5YAgJs3b2o8xkstEZG+5StVMDd7OmjhVd0G+z/oDGtLM4mrIpKer7OtVu1EQDkC4IEDB/RZBxFRse4nZ2LkytP4OKQhujZ2AwCGP6L/F+DthDHBfhrDwGOD/dj7RyXSOQDu378f7du3h0Kh0Gc9REQarselIWx5BOLTcjB31zV0buCi7gkkMjW6zuSd0rMRQpq4cxYwlZnOAfCVV15Bfn4+AgMD0blzZwQHB6N9+/awtrbWZ31EVIVFRCdh1KrTSM/OR323alg1sg3DH5ms8s7kDfB2YvCjMtP5mzQ5ORn79u1Dz549ERERgX79+sHR0RHt27fHjBkz9FkjEVVBf1+Jw9BfTyE9Ox+BPk7Y/E47eDjwD0wyTZzJS5VN5wBoYWGB9u3bY9q0afj7779x8uRJDB48GBEREZg3b54+aySiKmbdqRiM/e0scvNV6NbYDWtGBcHBhlf5INNV0kxeooqg8xDwzZs3cfDgQRw8eBCHDh1CTk4OOnbsiK+//hqdO3fWY4lEVNVciU2FSgCDAr3wed+mHPYlk8eZvFTZZEIIocuOcrkcLi4umDhxIl5++WU0a9bMJJd/SUtLg4ODA1JTU2Fvby91OURVglIlsONiLF5p4WmS3ytERXn+HMCxwX74hFfzIC1ok1l0DoDvv/8+Dh8+jKtXr6Jly5bo3LkzOnfujA4dOsDGxkanwg0RAyBRxcvOU2LFsTt4q6MvLNjbR1UYr+dL5VEpAbBASkoKjhw5gkOHDuHQoUO4cuUKAgICcOzYsfI8rcFgACSqWGnZeRi9+gxORiVhYGsvLHi9udQlEREZJW0yi87nABZQKpXIy8tDTk4OsrOzkZOTgxs3bpT3aYmoCniUlo2wFadx7WEaqinM8aq/p9QlERFVCTqPtUyYMAHNmzeHm5sb3nnnHcTGxuLtt99GZGQkEhIS9FkjEZmg6MQM9A8/jmsP0+BcTYENo19Au7rOUpdFRFQl6NwD+PDhQ4wePRqdO3dG06ZN9VkTEZm4i/dTMGLFaTzOyEXtGjZYMzII3jVM59xhIiJDp3MA3Lx5c5m26927N3755Rd4eHjo+lJEZEKy85R4a9UZPM7IRdOa9lgxvA1c7HhJSSKiylTh0+0OHz6MrKysin4ZIjISVhZmWDTAH10auGDD6LYMf0REEij3JBAiorJ4lJ4NVzsrAECHes5oX7cG1/gjIpIIF9wiogolhMC8XdcQ8s1h3H70RN3O8EdEJB0GQCKqMHlKFT7cfBE/HYpCcmYeTvybKHVJREQEDgETUQXJzM3H+LXncOBGAszkMsx7rRkGtPaSuiwiIkIFBcCsrCxYW1tXxFMTkRFIzsjFyFWnERmTAisLOZYMaYmXGrlJXRYREf0/vQ4B5+TkYOHChfD19VW3TZs2DdWrV9fnyxCRAYtPy8br4ccRGZMCB2sLrH0riOGPiMjAaB0Ac3JyMHXqVLRu3Rrt2rXDtm3bAAArVqyAr68vFi9ejEmTJqm3nzp1KhwdHfVVLxEZOAdrC1S3tYSHgxW2jGmLVrX5ByARkaGRCSGENjt88skn+Omnn9C1a1ccP34cCQkJGDFiBE6ePIlp06bhjTfegJmZWUXVW+m0ubAyET2VmpmHjNx8eDryVBAiosqiTWbR+hzAzZs3Y/Xq1XjllVdw+fJlNG/eHPn5+bhw4QKXdSCqovZcjceV2FS837U+AMDBxgIONhYSV0VERMXROgDev38frVq1AgA0bdoUCoUCkyZNYvgjqqI2RMRg2tZLUAmgiacDujXm+X5ERIZO6wCoVCphaWn5vycwN0e1atX0WhQRGT4hBH7YfxsL99wEAAxoXQtdGrhIXBUREZWF1gFQCIHhw4dDoXh6/c7s7GyMGTMGtra2Gtv98ccf+qmQiAyOUiUw579XsPrEXQDA+C518GH3BhwJICIyEloHwLCwMI37Q4cO1VsxRGT4cvKVmLzxAv669BAyGTDz5cYY0d639B2JiMhgaB0AV6xYURF1EJGROPHvY/x16SEszGRYNMAffVp4Sl0SERFpyeiuBbxkyRL4+PjAysoKQUFBiIiIKHbbZcuWoWPHjnBycoKTkxO6du1a4vZEVLrODVwxq09jrBjehuGPiMhIGVUA3LhxIyZPnoxZs2bh3LlzaNGiBUJCQvDo0aMitz948CAGDx6MAwcO4MSJE/Dy8kL37t3x4MGDSq6cyLjdSczAo7Rs9f0R7X3RoZ6zZPVExiTjj3P3ERmTLFkNRETGTOuFoKUUFBSEwMBA/PDDDwAAlUoFLy8vvPfee5gyZUqp+yuVSjg5OeGHH35AaGhomV6TC0FTVXf5QSqGr4iAi50VNr7zAuytpF3fb/6uawg/FKW+PybYD1N6NpKwIiIiw6BNZjGaHsDc3FycPXsWXbt2VbfJ5XJ07doVJ06cKNNzZGZmIi8vr8RrE+fk5CAtLU3jRlRVHb2ViIE/nUDik1zIAOTkqSStJzImWSP8AUD4oSj2BBo59ugSVT6tJ4FIJTExEUqlEm5umovMurm54fr162V6jk8++QSenp4aIfJ58+bNw5w5c8pVK5Ep2H4hFh9sOo88pUC7OjXw07BWsJO49y86MaPY9gBvp0quhvSBPbpE0jCaHsDymj9/PjZs2ICtW7fCysqq2O2mTp2K1NRU9e3evXuVWCWRYVhxLBoT1kciTynQu5kHVowIlDz8AYCvs61W7WTY2KNLJB2jCYDOzs4wMzNDfHy8Rnt8fDzc3d1L3Pfrr7/G/Pnz8c8//6B58+YlbqtQKGBvb69xI+PC4aTyWXEsGnP+exUAENq2Nr4bHACFuZnEVT0V4O2EMcF+Gm1jg/3Y+2ekSurRJaKKZTRDwJaWlmjVqhX27duHvn37Ang6CWTfvn149913i93vyy+/xBdffIG///4brVu3rqRqSSrPDyf1C/DENwMDJKzI+HRv4o6fDkVh6AveGN+lrsFd3WNKz0YIaeKO6MQM+DrbMvwZMfboEknHaAIgAEyePBlhYWFo3bo12rRpg8WLFyMjIwMjRowAAISGhqJmzZqYN28eAGDBggWYOXMm1q1bBx8fH8TFxQEAqlWrxusXm6CihpO2RsYCAENgKVQqAbn8adCr6WiNfyZ3kny2b0kCvJ0Y/ExAQY/usz+37NElqhxGFQAHDhyIhIQEzJw5E3FxcfD398fu3bvVE0NiYmIgl/9vVHvp0qXIzc3F66+/rvE8s2bNwuzZsyuzdKoExQ0bbY2MRWhbH/5SKUZKZi7eXn0GI9v7omczDwAw6PBHpoU9ukTSMKp1AKXAdQCNR2RMMvr9eLzIx7o0cMGKEW0quSLDF5uShdDlEbj96Alc7BQ4/FEXWFsaxvl+RESkHZNcB5CoNAHeTqjnWvS5QwduJHBSyHNuxqej/9LjuP3oCdztrbD2rSCDCn+czENEVHGMagiYqCSRMcm49aj42YPPrhUXGZOs1yEnfT9fRTt7NwkjV55BalYe6rpWw6qRbVDT0VrqstS4NhwRUcViACSTUdrSEQUzC/UdLowtrOy9Go/x684hJ1+FAG9HLA8LhJOtpdRlqRW3NlxIE3ejCNdERMaAQ8BkMkpaOuLFhi4I8HbS+8KzxriQ7Ymox8jJV+HFhq5Y99YLBhX+AK4NR0RUGRgAyWQEeDuhX4BnkY+992I9APoPF8YYVqb3aoS5/Zrhp2GtDOqcvwJcG46IqOIxAJJJ+WZgQKEQ+Oy6YvoOF8YQVlQqgTUn7yI3XwUAkMtlGBLkDQszw/zx59U+iIgqHpeBKQWXgTFOJU3KeP6cvbHBfvhEj+cAlvf59CknX4kPNl3AjosP8aq/JxYP9De4K3sUx9gm1hARSU2bzMIAWAoGQNNUFWYBp2fnYcxvZ3Hs9mNYmMmwcIA/XmlR9BA5EREZPwZAPWIAJGOUkJ6D4SsicCU2DbaWZggf1god67lIXRYREVUgbTILl4EhMjF3H2cgdHkE7j7ORA1bS6wc0QbNajlIXRYRERkQBkAiE5KvVGHEitO4+zgTXtWtsXpkkEFNSCEiIsNgmNMAiUgn5mZyfNGvGfy9HPH72HYMf0REVCSeA1gKngNIxiA1Mw8ONhbq+0IIo5ntS0RE+qFNZmEPIJGRW3X8DoK/PoAbcenqNoY/IiIqCQMgkZESQuDrv29g1vYrSMnMw18XY6UuiYiIjAQngRAZoXylCtO3XsbGM/cAAJO71cd7L9aVuCoiIjIWDIBERiYrV4n31kdi77V4yGXAF/2aYXAbb6nLIiIiI8IASGREUrPyMGrlaZy5mwxLczm+HxyAkCbuUpdFRERGhgGQyIgozOUwN5PBzsocv4S2RpBfDalLIiIiI8QASCbFEK/Jq09WFmb4ObQ14lKzUd/NTupyiIjISDEAksmYv+sawg9Fqe+PCfbDlJ6NJKxIP87FJOPIzURM7FoPAGBvZQF7K4tS9iIiIioeAyCZhMiYZI3wBwDhh6IQ0sTdqHsC91+Px7i155Cdp4J3DWv0C6gldUlERGQCuA4gmYToxAyt2o3B5jP38Pbqs8jOU6FzAxdO9iAiIr1hDyCZhOKueWuM18IVQiD8UBQW7L4OAHitZU0s6N8cFmb8e42IiPSDv1HIJAR4O2FMsJ9G29hgP6Mb/lWpBD7dcVUd/t4J9sPCN1ow/BERkV6xB5BMxpSejRDSxN2oZwGfi0nGyuN3AAAzejfCWx39St6BiIhIBzIhhJC6CEOWlpYGBwcHpKamwt7eXupyqApYfeIO7K0s0DegptSlEBGREdEms7AHkEhiiU9ykK8UcHewAgCEtvWRtiAiIjJ5PLGISEIxjzPx+tLjCFsegdTMPKnLISKiKoIBkEgiV2JT8drS47jzOBMZuflIycqVuiQiIqoiOARMJIHj/yZi9OqzeJKTj4budlg9sg1c7a2kLouIiKoIBkCiSvbXxYeYtPE8cpUqBPlWx7Kw1ry0GxERVSoGQKJK9Of5B3h/43kIAfRs6o5vBvrDysJM6rKIiKiKYQAkqkRBvjXg6WCNLg1dMOeVpjCTy6QuiYiIqiAGQKIKJoSATPY06Lk7WGH7u+1R3dZS3UZERFTZOAuYqAJl5ykx9rdz2H4hVt1Wo5qC4Y+IiCTFHkCiCpKalYe3V51BxJ0kHL2diE71nOFoYyl1WURERAyARBUhLjUbYcsjcCM+HXYKcywLa83wR0REBoMBkExKZEwyohMz4OtsiwBvJ0lquP3oCcKWR+BBShZc7RRYNbINGnnwOtJERGQ4GADJZMzfdQ3hh6LU98cE+2FKz0aVWkNkTDJGrjyN5Mw8+DnbYtXINvCqblOpNRAREZWGk0DIJETGJGuEPwAIPxSFyJjkSq1j37VHSM7MQwsvR2we05bhj4iIDBJ7AMkkRCdmFNtemUPBk7vVh5OtJQYFesFWwR8vIiIyTOwBJJPg62yrVbs+/Xn+AbLzlAAAuVyGUR18Gf6IiMigMQCSSQjwdsKYYD+NtrHBfhXa+6dSCXy+4yombjiPSRvPQ6USFfZaRERE+sRuCjIZU3o2QkgT90qZBZybr8LHWy5g2/mnCzwHeDtCzsu6ERGRkWAAJJMS4O1U4ef8ZeTkY8xvZ3HkViLM5TJ8+XpzvNayVoW+JhERkT4xABJp4fGTHIxceRoX7qfC2sIMS4e2ROcGrlKXRUREpBUGQKIyEkJg1KozuHA/FU42Flg+PFCyxaaJiIjKg5NAyKRExiTjj3P3K2T9P5lMhhm9G6GuazVsGduO4Y+IiIwWewDJZFTUlUAyc/NhY/n0R6W1T3X8/X4nmHHCBxERGTH2AJJJqKgrgey69BCdvjyAq7Fp6jaGPyIiMnYMgGQSSroSSGmKGzb+7eRdjFt3DolPcrHm5F291ElERGQIOARMJiFPqdKqvUBRw8af9GiIxXtv4dt9twAAg9t44/O+TfVXLBERkcQYAMkkWJgV3ZldXDtQ/LBxVEIG/rkaDwCY+FI9vN+1HmQyDvsSEZHpYAAkk1DStYAjY5KLvDpIccPD/1yNh0wGfPZqUwx9oXaF1KuL4t4HERGRthgAySQEeDvB38sB5++lqtvqudri7ytxxc4MLi40mstl+H5wAHo286jYorVQUTOciYioauIkEDIJkTHJGuEPAG49yihxZnCAtxPGBPtpPD6qvQ82jWlrUOGvomY4ExFR1cUeQDIJGyJiyrxtdGKGegj1jdZeSMvKQ6vaTvBzqWaQQ6slzXA2xHqJiMjwMQCS0eu75Gih3r+SFAz9nr+XghErIpCcmYdGHvYGG6ZKOr+RiIhIFxwCJqO28XSMVuFvbLAfArydcOhmAoYsO4nkzDw0r+VgUEO+zytqqLrgfRAREemCPYBk1C7cSynx8c71nTGxa32N2bNbI+/jo80Xka8S6FjPGUuHtkI1hWH/KEzp2QghTdw5C5iIiPTCsH/rEZWihZcj1kXcK/bx+LQcBHg7qQPTL0ei8Plf1wAAr/p74qvXW8DS3Dg6wp99H0REROVhHL/5iIoxMNAb/l4OxT5+LS5dPVv2Rlw65u58Gv5GdfDFNwP8jSb8ERER6RN7AMno+TrblngeYMFs2Qbudvisb1OkZ+fjnU5+vLoHERFVWQyAZNQiY5KxNTK2xG3srf73MX8zyHCu7EFERCQVjn+RUStujbwClmYyzN11HUkZuZVUERERkeEzugC4ZMkS+Pj4wMrKCkFBQYiIiChx+82bN6Nhw4awsrJCs2bNsHPnzkqqlCpDaWvh5SoFkjJyEZuSVUkVERERGT6jCoAbN27E5MmTMWvWLJw7dw4tWrRASEgIHj16VOT2x48fx+DBgzFq1ChERkaib9++6Nu3Ly5fvlzJlZOUQhq7oWnN4ieKEBERVTUyIYSQuoiyCgoKQmBgIH744QcAgEqlgpeXF9577z1MmTKl0PYDBw5ERkYGduzYoW574YUX4O/vj/Dw8DK9ZlpaGhwcHJCamgp7e3v9vBHSmz/O3cfkTRdK3W7ruHZcQoWIiEyaNpnFaHoAc3NzcfbsWXTt2lXdJpfL0bVrV5w4caLIfU6cOKGxPQCEhIQUuz0A5OTkIC0tTeNGhqusl0Mr7VxBIiKiqsRoAmBiYiKUSiXc3Nw02t3c3BAXF1fkPnFxcVptDwDz5s2Dg4OD+ubl5VX+4qnCFHWZtKLwurlERET/YzQBsLJMnToVqamp6tu9e8VfZYIMw5SejUp8/MWGLhz+JSIieobRrAPo7OwMMzMzxMfHa7THx8fD3d29yH3c3d212h4AFAoFFApF+QumCqdUCczefgUB3o5wsDZHalZ+kdu992K9Sq6MiIjIsBlND6ClpSVatWqFffv2qdtUKhX27duHtm3bFrlP27ZtNbYHgD179hS7PRmP7Dwlxq89hzUn72LK75dgVcwl3Wwt5ez9IyIieo7RBEAAmDx5MpYtW4ZVq1bh2rVrGDt2LDIyMjBixAgAQGhoKKZOnarefuLEidi9ezcWLlyI69evY/bs2Thz5gzeffddqd4C6UFadh7Clkdg95U4WJrJ8c1Af3So51Lktj2aelRydURERIbPaIaAgafLuiQkJGDmzJmIi4uDv78/du/erZ7oERMTA7n8f5m2Xbt2WLduHWbMmIFp06ahXr162LZtG5o2bSrVW6ByepSWjbAVp3HtYRqqKczxc2grtKvjjJvxRc/WruVkXckVEhERGT6jWgdQClwH0HBEJTxB6PII3E/OgnM1BVaOCFQv8Pz60uM4cze50D6tazthy9h2lV0qERFRpdMmsxhVDyBVbbsux+F+chZq17DBmpFB8K5ho34sKSOnyH2KayciIqrKGADJaIzrXAcAMKC1F1zsNGdqK4qZBFJcOxERUVXG345k0A7ceISsXCUAQCaTYXyXuoXCHwDIZbIi9y+unYiIqCpjACSD9evRaIxYcRrvrT+HfKWqxG1tFUV3ZhfXTkREVJUxAJLBEUJg/q7r+GzHVQCAV3WbUnvy+reqpVU7ERFRVcbuETIoeUoVpvx+Cb+fuw8A+LhHA4wNrgNZKQGwvpudVu1ERERVGXsAyWBk5uZj9Ooz+P3cfZjJZfjy9eYY17luqeEPAKITM7RqJyIiqsrYA0gG4711kThwIwFWFnIsGdISLzVyK/O+vs62WrUTERFVZewBJIPx7ot14elghbVvBWkV/gAgwNsJY4L9NNrGBvvxOsBERERF4JVASsErgVSsnHwlFOZmxd7XVmRMMqITM+DrbMvwR0REVYo2mYU9gCSZ03eS0OWrg7h4P0XdVp7wBzztCXytZS2GPyIiohIwAJIk9lyNx9BfTiE2NRs/7L+tt+eNjEnGH+fuIzKm8HWBiYiI6ClOAqFKtyEiBtO2XoJKAF0bueLbQQF6ed75u64h/FCU+v6YYD9M6dlIL89NRERkStgDSJVGCIHv993ClD+ehr8BrWshfGgrWFuWb9gXeNrz92z4A4DwQ1HsCSQiIioCAyBVCqVKYNb2K1i45yYAYHyXOljQvznMzfTzEeQ6gERERGXHIWCqFCohcC8pEzIZMOvlxhje3levz891AImIiMqOAZAqhYWZHEvebIlT0Uno0sBV788f4O0Efy8HnL+Xqm7z93LgbGAiIqIicAiYKsyj9GwsPfgvCpaatLE0r5DwBzw9B/DZ8AcA5++l8hxAIiKiIrAHkCrEncQMhC6PQExSJuQy4J3gOhX6eiWdA8heQCIiIk0MgKR3lx+kYviKCCQ+yYV3dRv0aOpe4a/JcwCJiIjKjkPApFdHbyVi4E8nkPgkF0087fH72HaoXaPiQxivBUxERFR27AEkvdl+IRYfbDqPPKVA+7o1ED60FeysLCrt9af0bISQJu68FjAREVEpGABJLx6kZKnDX+/mHlg0oEW5r+uriwBvJwY/IiKiUjAAkl7UdLTGF/2a4WpsGma+3BhyuUzqkoiIiKgYDICks3ylCkkZuXC1twIADGjtJXFFREREVBacBEI6ycpV4p01Z/HGTyeQkJ4jdTlERESkBfYAktZSMnMxcuVpnItJgcJcjpvx6XCxU0hdFhEREZURAyBpJTYlC6HLI3D70RM4WFvg17DWaO1TXeqyiIiISAsMgFRmN+PTEbY8Ag9Ts+Fub4XVo9qgvpud1GURERGRlhgAqUwu3k/BsF8jkJqVh7qu1bBqZBvUdLSWuiwiIiLSAQMglUlNR2tUt7WEn4stlocFwsnWUuqSiIiISEcMgFQmNaopsO7tIDhaW8LasvIXeCYiIiL94TIwVCQhBJYcuI2Np2PUbR4O1gx/REREJoA9gFSISiXw6Y6rWHn8DszkMrSq7YS6rsYx2SMyJpnXAiYiIioFAyBpyMlX4oNNF7Dj4kMAwPRejYwm/M3fdQ3hh6LU98cE+2FKz0YSVkRERGSYOARMaunZeRi58jR2XHwICzMZvhscgJEdfKUuq0wiY5I1wh8AhB+KQmRMskQVERERGS4GQAIAJKTnYNDPJ3Hs9mPYWpph+fBAvNLCU+qyyiw6MUOrdiIioqqMQ8AEAPjrYiyuxKahhq0lVo5og2a1HKQuSSu+zrZatRMREVVlDIAEAAhr54O07Hz0aeFplKEpwNsJY4L9NIaBxwb7cSIIERFREWRCCCF1EYYsLS0NDg4OSE1Nhb29vdTl6NXZu8lo5GEHG0vT+TuAs4CJiKiq0iazmM5vftLKjouxmLzxAtrVrYFloa1hYWYap4MGeDsx+BEREZWCAbAKWnX8Dmb/9wqEAGwtzaFiJzAREVGVwgBYhQghsPCfm/jhwG0AQGjb2pjVpwnM5DKJKyMiIqLKxABYReQrVZi+9TI2nrkHAPigW328+2JdyGQMf0RERFUNA2AVURD+5DJgbr9mGNTGW+qSiIiISCKmceY/lWpY29pwrmaJ8KGtGP6IiIiqOPYAmjClSqjP72ta0wGHP+5iUku+EBERkW7YA2iibj9KR/dvDuHcM9fCZfgjIiIigAHQJJ29m4zXw0/g34QMzP3rGrjWNxERET2LXUImZv/1eIxbew7ZeSr4ezni59DWnOlLREREGhgATcjmM/cw5Y9LUKoEOjdwwY9vtuSwLxERERXCdGAChBAIPxSFBbuvAwBea1kTC/o3N5nLuxEREZF+MQCaACGgnuzxTrAfpvRoyGFfIiIiKhYDoAmQy2X4fnAA/r4Sh1f9a0pdDhERERk4jhEaqSc5+fj1aLR6hq+VhRnDHxEREZUJewCNUOKTHIxYcRqXHqQiLSsPk7rVl7okIiIiMiIMgEYm5nEmQpefwp3Hmahua4kXG7pKXRIREREZGQZAI3IlNhVhy08j8UkOajlZY/XINvBzqSZ1WURERGRkGACNxPF/EzF69Vk8yclHQ3c7rB7ZBq72VlKXRUREREaIAdAIJGXk4q1VZ5CZq0SQb3UsC2sNeysLqcsiIiIiI8UAaASq21rii35NsedqPBYN8IeVhZnUJREREZERYwA0UEIIJGXkokY1BQCgX0At9PWvyQWeiYiIqNy4DqAByleqMG3rJby65BgepWWr2xn+iIiISB8YAA1Mdp4S49aew/qIe4hNycLpO8lSl0REREQmhkPABiQ1Kw9vrzqDiDtJsDSX47tBAejR1F3qsoiIiMjEGE0PYFJSEt58803Y29vD0dERo0aNwpMnT0rc/r333kODBg1gbW0Nb29vTJgwAampqZVYddnFpWZjQPgJRNxJgp2VOdaMbMPwp4PImGT8ce4+ImPYc0pERFQco+kBfPPNN/Hw4UPs2bMHeXl5GDFiBEaPHo1169YVuX1sbCxiY2Px9ddfo3Hjxrh79y7GjBmD2NhYbNmypZKrL9mdxAy8+cspPEjJgqudAqtHtUFDd3upyzI683ddQ/ihKPX9McF+mNKzkYQVERERGSaZEEJIXURprl27hsaNG+P06dNo3bo1AGD37t3o1asX7t+/D09PzzI9z+bNmzF06FBkZGTA3Lxs2TctLQ0ODg5ITU2FvX3FhLLkjFy88dMJqFQCq0a2gVd1mwp5HVMWGZOMfj8eL9S+dVw7BHg7SVARERFR5dImsxjFEPCJEyfg6OioDn8A0LVrV8jlcpw6darMz1NwQMoa/iqLk60lVo9sgy1j2zH86Sg6MUOrdiIioqrMsJJQMeLi4uDq6qrRZm5ujurVqyMuLq5Mz5GYmIjPPvsMo0ePLnG7nJwc5OTkqO+npaVpX7AOPB2tK+V1TJWvs61W7URERFWZpD2AU6ZMgUwmK/F2/fr1cr9OWloaevfujcaNG2P27Nklbjtv3jw4ODiob15eXuV+fap4Ad5OGBPsp9E2NtiPw79ERERFkPQcwISEBDx+/LjEbfz8/PDbb7/hgw8+QHLy/2Z25ufnw8rKCps3b0a/fv2K3T89PR0hISGwsbHBjh07YGVlVeLrFdUD6OXlVaHnAJL+RMYkIzoxA77Otgx/RERUpWhzDqCkQ8AuLi5wcXEpdbu2bdsiJSUFZ8+eRatWrQAA+/fvh0qlQlBQULH7paWlISQkBAqFAtu3by81/AGAQqGAQqEo+5sggxLg7cTgR0REVAqjmATSqFEj9OjRA2+//TYiIiJw7NgxvPvuuxg0aJB6BvCDBw/QsGFDREREAHga/rp3746MjAz8+uuvSEtLQ1xcHOLi4qBUKqV8O0RERESSMopJIACwdu1avPvuu3jppZcgl8vRv39/fPfdd+rH8/LycOPGDWRmZgIAzp07p54hXLduXY3nio6Oho+PT6XVTkRERGRIjGIdQClVxjqAREREROVlcusAEhEREZH+MAASERERVTEMgERERERVDAMgERERURXDAEhERERUxTAAEhEREVUxDIBEREREVQwDIBEREVEVwwBIREREVMUwABIRERFVMQyARERERFUMAyARERFRFcMASERERFTFMAASERERVTHmUhdg6IQQAIC0tDSJKyEiIiIqXkFWKcguJWEALEV6ejoAwMvLS+JKiIiIiEqXnp4OBweHEreRibLExCpMpVIhNjYWdnZ2kMlken3utLQ0eHl54d69e7C3t9frc1dVPKb6xeOpfzym+sdjqn88pvpXGcdUCIH09HR4enpCLi/5LD/2AJZCLpejVq1aFfoa9vb2/AHTMx5T/eLx1D8eU/3jMdU/HlP9q+hjWlrPXwFOAiEiIiKqYhgAiYiIiKoYBkAJKRQKzJo1CwqFQupSTAaPqX7xeOofj6n+8ZjqH4+p/hnaMeUkECIiIqIqhj2ARERERFUMAyARERFRFcMASERERFTFMABWsqSkJLz55puwt7eHo6MjRo0ahSdPnpS4/XvvvYcGDRrA2toa3t7emDBhAlJTUyuxasOyZMkS+Pj4wMrKCkFBQYiIiChx+82bN6Nhw4awsrJCs2bNsHPnzkqq1DhoczyXLVuGjh07wsnJCU5OTujatWupx78q0vYzWmDDhg2QyWTo27dvxRZohLQ9pikpKRg/fjw8PDygUChQv359/uw/R9tjunjxYvXvIi8vL0yaNAnZ2dmVVK1hO3z4MPr06QNPT0/IZDJs27at1H0OHjyIli1bQqFQoG7duli5cmWF16lBUKXq0aOHaNGihTh58qQ4cuSIqFu3rhg8eHCx21+6dEm89tprYvv27eL27dti3759ol69eqJ///6VWLXh2LBhg7C0tBTLly8XV65cEW+//bZwdHQU8fHxRW5/7NgxYWZmJr788ktx9epVMWPGDGFhYSEuXbpUyZUbJm2P55AhQ8SSJUtEZGSkuHbtmhg+fLhwcHAQ9+/fr+TKDZe2x7RAdHS0qFmzpujYsaN49dVXK6dYI6HtMc3JyRGtW7cWvXr1EkePHhXR0dHi4MGD4vz585VcueHS9piuXbtWKBQKsXbtWhEdHS3+/vtv4eHhISZNmlTJlRumnTt3iunTp4s//vhDABBbt24tcfuoqChhY2MjJk+eLK5evSq+//57YWZmJnbv3l05BQshGAAr0dWrVwUAcfr0aXXbrl27hEwmEw8ePCjz82zatElYWlqKvLy8iijToLVp00aMHz9efV+pVApPT08xb968IrcfMGCA6N27t0ZbUFCQeOeddyq0TmOh7fF8Xn5+vrCzsxOrVq2qqBKNji7HND8/X7Rr10788ssvIiwsjAHwOdoe06VLlwo/Pz+Rm5tbWSUaHW2P6fjx48WLL76o0TZ58mTRvn37Cq3TGJUlAH788ceiSZMmGm0DBw4UISEhFViZJg4BV6ITJ07A0dERrVu3Vrd17doVcrkcp06dKvPzpKamwt7eHubmVetKfrm5uTh79iy6du2qbpPL5ejatStOnDhR5D4nTpzQ2B4AQkJCit2+KtHleD4vMzMTeXl5qF69ekWVaVR0PaaffvopXF1dMWrUqMoo06jocky3b9+Otm3bYvz48XBzc0PTpk0xd+5cKJXKyirboOlyTNu1a4ezZ8+qh4mjoqKwc+dO9OrVq1JqNjWG8LupaiUIicXFxcHV1VWjzdzcHNWrV0dcXFyZniMxMRGfffYZRo8eXRElGrTExEQolUq4ublptLu5ueH69etF7hMXF1fk9mU93qZMl+P5vE8++QSenp6FvsiqKl2O6dGjR/Hrr7/i/PnzlVCh8dHlmEZFRWH//v148803sXPnTty+fRvjxo1DXl4eZs2aVRllGzRdjumQIUOQmJiIDh06QAiB/Px8jBkzBtOmTauMkk1Ocb+b0tLSkJWVBWtr6wqvgT2AejBlyhTIZLISb2X9hVqStLQ09O7dG40bN8bs2bPLXzhROcyfPx8bNmzA1q1bYWVlJXU5Rik9PR3Dhg3DsmXL4OzsLHU5JkOlUsHV1RU///wzWrVqhYEDB2L69OkIDw+XujSjdfDgQcydOxc//vgjzp07hz/++AN//fUXPvvsM6lLIx2xB1APPvjgAwwfPrzEbfz8/ODu7o5Hjx5ptOfn5yMpKQnu7u4l7p+eno4ePXrAzs4OW7duhYWFRXnLNjrOzs4wMzNDfHy8Rnt8fHyxx8/d3V2r7asSXY5nga+//hrz58/H3r170bx584os06hoe0z//fdf3LlzB3369FG3qVQqAE9HB27cuIE6depUbNEGTpfPqYeHBywsLGBmZqZua9SoEeLi4pCbmwtLS8sKrdnQ6XJM//Of/2DYsGF46623AADNmjVDRkYGRo8ejenTp0MuZ3+SNor73WRvb18pvX8AewD1wsXFBQ0bNizxZmlpibZt2yIlJQVnz55V77t//36oVCoEBQUV+/xpaWno3r07LC0tsX379irb22JpaYlWrVph37596jaVSoV9+/ahbdu2Re7Ttm1bje0BYM+ePcVuX5XocjwB4Msvv8Rnn32G3bt3a5zPStof04YNG+LSpUs4f/68+vbKK6+gS5cuOH/+PLy8vCqzfIOky+e0ffv2uH37tjpMA8DNmzfh4eFR5cMfoNsxzczMLBTyCgK24BVltWYQv5sqbboJCSGeLgMTEBAgTp06JY4ePSrq1aunsQzM/fv3RYMGDcSpU6eEEEKkpqaKoKAg0axZM3H79m3x8OFD9S0/P1+qtyGZDRs2CIVCIVauXCmuXr0qRo8eLRwdHUVcXJwQQohhw4aJKVOmqLc/duyYMDc3F19//bW4du2amDVrFpeBeYa2x3P+/PnC0tJSbNmyReOzmJ6eLtVbMDjaHtPncRZwYdoe05iYGGFnZyfeffddcePGDbFjxw7h6uoqPv/8c6negsHR9pjOmjVL2NnZifXr14uoqCjxzz//iDp16ogBAwZI9RYMSnp6uoiMjBSRkZECgFi0aJGIjIwUd+/eFUIIMWXKFDFs2DD19gXLwHz00Ufi2rVrYsmSJVwGxtQ9fvxYDB48WFSrVk3Y29uLESNGaPzyjI6OFgDEgQMHhBBCHDhwQAAo8hYdHS3Nm5DY999/L7y9vYWlpaVo06aNOHnypPqx4OBgERYWprH9pk2bRP369YWlpaVo0qSJ+Ouvvyq5YsOmzfGsXbt2kZ/FWbNmVX7hBkzbz+izGACLpu0xPX78uAgKChIKhUL4+fmJL774okr+0VwSbY5pXl6emD17tqhTp46wsrISXl5eYty4cSI5ObnyCzdAxf2uLjiGYWFhIjg4uNA+/v7+wtLSUvj5+YkVK1ZUas0yIdh3S0RERFSV8BxAIiIioiqGAZCIiIioimEAJCIiIqpiGACJiIiIqhgGQCIiIqIqhgGQiIiIqIphACQiIiKqYhgAiYiIiKoYBkAiIgPj4+ODxYsXl7rdr7/+iu7du1dYHYmJiXB1dcX9+/cr7DWISBoMgERkEoYPHw6ZTAaZTAYLCwv4+vri448/RnZ2tqR1yWQybNu2Te/Pm52djf/85z+YNWuWum327Nnw9/cv83OsXLlSfczkcjlq1aqFESNG4NGjRwAAZ2dnhIaGarwGEZkGBkAiMhk9evTAw4cPERUVhW+++QY//fSTyYaXLVu2wN7eHu3bty/X89jb2+Phw4e4f/8+li1bhl27dmHYsGHqx0eMGIG1a9ciKSmpvCUTkQFhACQik6FQKODu7g4vLy/07dsXXbt2xZ49e0rd786dO5DJZNi0aRM6duwIa2trBAYG4ubNmzh9+jRat26NatWqoWfPnkhISFDvd/r0aXTr1g3Ozs5wcHBAcHAwzp07p37cx8cHANCvXz/IZDL1fQD473//i8DAQFhZWcHZ2Rn9+vXTqCkzMxMjR46EnZ0dvL298fPPP2s8vmHDBvTp00eHo6RJJpPB3d0dnp6e6NmzJyZMmIC9e/ciKysLANCkSRN4enpi69at5X4tIjIcDIBEZJIuX76M48ePw9LSssz7zJo1CzNmzMC5c+dgbm6OIUOG4OOPP8a3336LI0eO4Pbt25g5c6Z6+/T0dISFheHo0aM4efIk6tWrh169eiE9PR3A04AIACtWrMDDhw/V9//66y/069cPvXr1QmRkJPbt24c2bdpo1LJw4UK0bt0akZGRGDduHMaOHYsbN26oHz969Chat26t8/EpjrW1NVQqFfLz89Vtbdq0wZEjR/T+WkQkHXOpCyAi0pcdO3agWrVqyM/PR05ODuRyOX744Ycy7//hhx8iJCQEADBx4kQMHjwY+/btUw+zjho1CitXrlRv/+KLL2rs//PPP8PR0RGHDh3Cyy+/DBcXFwCAo6Mj3N3d1dt98cUXGDRoEObMmaNua9GihcZz9erVC+PGjQMAfPLJJ/jmm29w4MABNGjQACkpKUhNTYWnp2eZ31tZ3Lp1C+Hh4WjdujXs7OzU7Z6enoiMjNTraxGRtNgDSEQmo0uXLjh//jxOnTqFsLAwjBgxAv379y/z/s2bN1f/v5ubGwCgWbNmGm0FEyQAID4+Hm+//Tbq1asHBwcH2Nvb48mTJ4iJiSnxdc6fP4+XXnqpzLUUDNMWvHbB8KyVlVUZ31nxUlNTUa1aNdjY2KBBgwZwc3PD2rVrNbaxtrZGZmZmuV+LiAwHewCJyGTY2tqibt26AIDly5ejRYsW+PXXXzFq1Kgy7W9hYaH+f5lMVmSbSqVS3w8LC8Pjx4/x7bffonbt2lAoFGjbti1yc3NLfB1ra2utann+tWvUqAGZTIbk5OTS31Qp7OzscO7cOcjlcnh4eBRZW1JSkro3k4hMA3sAicgkyeVyTJs2DTNmzFD3mOnbsWPHMGHCBPTq1QtNmjSBQqFAYmKixjYWFhZQKpUabc2bN8f/tXf/IKmFcRjHH/8gBM0tYYjk0uQ5k4sgLu6BQ0Y4OLiIe9MZggMmjo1ODg1NOugQQkNLgSAUCUK7gygO2XgaLjeudOOq92Zez/cD7/Ke97zv72wPL+e8p91uL71uIBDQwcGBnp6elp7jJ6/Xq/39fYXD4U+D6ePjowzD+Ou1AKwPAiCAjZVOp+Xz+XRxcfEl80ciEdVqNfV6Pd3d3en4+PhDiAqFQmq32xoMBu87dpZl6fLyUpZlqdfr6eHhQaVSaaG1U6mUbm9vP/S/vr6q2+3OtOfn56WfcTqdqtPpfOmB0wBWjwAIYGP5/X4VCgWdn5/r5eXln89frVY1Ho9lmqZOTk5ULBa1s7MzM6ZSqej6+lrBYPB9Fy2RSOjq6kqNRkPRaFTJZFL39/cLrZ3L5dRsNjWZTGb6+/2+DMOYafl8XtKPg6J/PYpmHvV6XXt7e4rH4wvdB2C9eRzHcb67CADA4tLptEzT1Onp6Vzjs9msPB7PzJfMfxKLxVQsFpXJZJasEsA6YgcQAP5T5XJZ29vbc411HEc3Nzc6Ozube/7hcKjDw0MdHR0tWyKANcUOIICNZ9u2bNv+7bV4PK5Wq7XiigDgexEAAWy80Wj06b9st7a2tLu7u+KKAOB7EQABAABchncAAQAAXIYACAAA4DIEQAAAAJchAAIAALgMARAAAMBlCIAAAAAuQwAEAABwGQIgAACAy7wBBR1XNJXDZnUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 650x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done   (Estas 3 figuras son las tpicas para justificar 'especificidad'.)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "try:\n",
        "    import tokenization_protocol as tp\n",
        "except Exception:\n",
        "    tp = None\n",
        "\n",
        "\n",
        "CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "TOKEN_A_STR  = \" Jones\"   # clean-consistent\n",
        "TOKEN_B_STR  = \" Smith\"   # corrupt-consistent\n",
        "\n",
        "# Wrong-source rule: source position is P+1 if possible else P-1 (same layer)\n",
        "def wrong_source_pos(P: int, T: int) -> int:\n",
        "    return (P + 1) if (P + 1 < T) else (P - 1)\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def single_token_id(bpe: BPETokenizer, token_str: str) -> int:\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(f\"{repr(token_str)} is not a single BPE token. Got {len(ids)} ids: {ids}\")\n",
        "    return int(ids[0])\n",
        "\n",
        "def score_from_last_logits(last_logits_1d: torch.Tensor, token_a_id: int, token_b_id: int) -> float:\n",
        "    # score = logit(B) - logit(A)\n",
        "    return float(last_logits_1d[token_b_id] - last_logits_1d[token_a_id])\n",
        "\n",
        "def restoration(score: float, score_clean: float, score_corr: float) -> float:\n",
        "    denom = (score_clean - score_corr)\n",
        "    if abs(denom) < 1e-12:\n",
        "        return float(\"nan\")\n",
        "    return (score - score_corr) / denom\n",
        "\n",
        "def decode_prompt_token_labels(bpe: BPETokenizer, text: str):\n",
        "    ids_1d = bpe(text)[0].tolist()\n",
        "    labels = []\n",
        "    for tid in ids_1d:\n",
        "        labels.append(bpe.decode(torch.tensor([int(tid)], dtype=torch.long)))\n",
        "    return labels\n",
        "\n",
        "device = get_device()\n",
        "print(\"Device:\", device)\n",
        "\n",
        "bpe = BPETokenizer()\n",
        "token_a_id = single_token_id(bpe, TOKEN_A_STR)\n",
        "token_b_id = single_token_id(bpe, TOKEN_B_STR)\n",
        "\n",
        "if tp is not None:\n",
        "    comp = tp.validate_pair(bpe=bpe, clean_text=CLEAN_TEXT, corrupt_text=CORRUPT_TEXT,\n",
        "                            require_same_length=True, require_one_token_diff=False)\n",
        "    print(tp.describe_pair(comp))\n",
        "\n",
        "idx_clean = bpe(CLEAN_TEXT).to(device)\n",
        "idx_corr  = bpe(CORRUPT_TEXT).to(device)\n",
        "\n",
        "if idx_clean.shape != idx_corr.shape:\n",
        "    raise ValueError(f\"Clean/corrupt length mismatch: clean {tuple(idx_clean.shape)} vs corrupt {tuple(idx_corr.shape)}\")\n",
        "\n",
        "T = int(idx_clean.shape[1])\n",
        "\n",
        "model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "n_layer = len(model.transformer.h)\n",
        "print(f\"Seq len T={T}, n_layers={n_layer}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    # CLEAN run: cache activations\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=True)\n",
        "    score_clean = score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "    # CORR baseline\n",
        "    _ = model(idx_corr)\n",
        "    score_corr = score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "print(\"\\nBaselines:\")\n",
        "print(f\"score_clean = {score_clean:.6f}\")\n",
        "print(f\"score_corr  = {score_corr:.6f}\")\n",
        "print(f\"gap(clean-corr) = {score_clean-score_corr:.6f}\")\n",
        "\n",
        "# Compute MATCH and WRONG-SOURCE matrices of SCORES\n",
        "match_scores = torch.empty((n_layer, T), dtype=torch.float32)\n",
        "ws_scores    = torch.empty((n_layer, T), dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for L in range(n_layer):\n",
        "        for P in range(T):\n",
        "            # MATCH\n",
        "            _ = model(idx_corr, layer_to_patch=L, position_to_patch=P, source_layer=L, source_position=P)\n",
        "            match_scores[L, P] = float(score_from_last_logits(model.last_logits[0], token_a_id, token_b_id))\n",
        "\n",
        "            # WRONG-SOURCE (pos shift)\n",
        "            srcP = wrong_source_pos(P, T)\n",
        "            _ = model(idx_corr, layer_to_patch=L, position_to_patch=P, source_layer=L, source_position=srcP)\n",
        "            ws_scores[L, P] = float(score_from_last_logits(model.last_logits[0], token_a_id, token_b_id))\n",
        "\n",
        "# Convert to normalized restoration R\n",
        "R_match = torch.empty_like(match_scores)\n",
        "R_ws    = torch.empty_like(ws_scores)\n",
        "for L in range(n_layer):\n",
        "    for P in range(T):\n",
        "        R_match[L, P] = restoration(float(match_scores[L, P]), score_clean, score_corr)\n",
        "        R_ws[L, P]    = restoration(float(ws_scores[L, P]), score_clean, score_corr)\n",
        "\n",
        "# Plots\n",
        "token_labels = decode_prompt_token_labels(bpe, CLEAN_TEXT)\n",
        "xticks = list(range(T))\n",
        "\n",
        "# (A) Heatmap: R_match\n",
        "plt.figure(figsize=(max(8, 0.35*T + 5), 6))\n",
        "plt.title(\"EXTRA 1  MATCH patch: normalized restoration R(L,P)\")\n",
        "plt.imshow(R_match.cpu().numpy(), aspect=\"auto\")\n",
        "plt.colorbar(label=\"R\")\n",
        "plt.xlabel(\"Token position\")\n",
        "plt.ylabel(\"Layer\")\n",
        "plt.xticks(xticks, [f\"{i}:{token_labels[i]}\" for i in xticks], rotation=90)\n",
        "plt.yticks(list(range(n_layer)))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# (B) Heatmap: R_wrong_source\n",
        "plt.figure(figsize=(max(8, 0.35*T + 5), 6))\n",
        "plt.title(\"EXTRA 1  WRONG-SOURCE patch (pos shift): normalized restoration R_ws(L,P)\")\n",
        "plt.imshow(R_ws.cpu().numpy(), aspect=\"auto\")\n",
        "plt.colorbar(label=\"R_ws\")\n",
        "plt.xlabel(\"Token position\")\n",
        "plt.ylabel(\"Layer\")\n",
        "plt.xticks(xticks, [f\"{i}:{token_labels[i]}\" for i in xticks], rotation=90)\n",
        "plt.yticks(list(range(n_layer)))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# (C) Scatter: R_match vs R_wrong_source\n",
        "x = R_match.flatten().cpu().numpy()\n",
        "y = R_ws.flatten().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(6.5, 6))\n",
        "plt.title(\"EXTRA 1  Specificity scatter: MATCH vs WRONG-SOURCE\")\n",
        "plt.scatter(x, y, s=10)\n",
        "# Diagonal y=x\n",
        "lo = float(min(x.min(), y.min()))\n",
        "hi = float(max(x.max(), y.max()))\n",
        "plt.plot([lo, hi], [lo, hi], linestyle=\"--\")\n",
        "plt.xlabel(\"R_match(L,P)\")\n",
        "plt.ylabel(\"R_wrong_source(L,P)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Done\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXTRA SECTION 2: Add an interpolation sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing interpolation_sweep.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile interpolation_sweep.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Sequence, Tuple\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "Coord = Tuple[int, int]  # (layer, position)\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Baselines:\n",
        "    clean_score: float\n",
        "    corrupt_score: float\n",
        "    token_a_id: int\n",
        "    token_b_id: int\n",
        "    seq_len: int\n",
        "    n_layer: int\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Curve:\n",
        "    coord: Coord\n",
        "    alphas: List[float]\n",
        "    scores: List[float]\n",
        "    restorations: List[float]\n",
        "    alpha50: Optional[float]\n",
        "\n",
        "\n",
        "def single_token_id(bpe, token_str: str) -> int:\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(f\"{repr(token_str)} is not a single BPE token. Got {len(ids)} ids: {ids}\")\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "def score_from_last_logits(last_logits_1d: torch.Tensor, token_a_id: int, token_b_id: int) -> float:\n",
        "    # score = logit(B) - logit(A)\n",
        "    return float(last_logits_1d[token_b_id] - last_logits_1d[token_a_id])\n",
        "\n",
        "\n",
        "def restoration_fraction(score: float, score_corr: float, score_clean: float) -> float:\n",
        "    denom = (score_clean - score_corr)\n",
        "    if abs(denom) < 1e-12:\n",
        "        return float(\"nan\")\n",
        "    return (score - score_corr) / denom\n",
        "\n",
        "\n",
        "def estimate_alpha50(alphas: Sequence[float], restorations: Sequence[float]) -> Optional[float]:\n",
        "    \"\"\"\n",
        "    Returns the smallest alpha where R(alpha) >= 0.5 using linear interpolation.\n",
        "    If never reaches 0.5 (or NaNs), returns None.\n",
        "    \"\"\"\n",
        "    xs = list(alphas)\n",
        "    ys = list(restorations)\n",
        "\n",
        "    # Filter NaNs but keep order\n",
        "    pairs = [(x, y) for x, y in zip(xs, ys) if (y is not None and not math.isnan(y))]\n",
        "    if len(pairs) < 2:\n",
        "        return None\n",
        "\n",
        "    for i in range(1, len(pairs)):\n",
        "        x0, y0 = pairs[i - 1]\n",
        "        x1, y1 = pairs[i]\n",
        "        if y0 >= 0.5:\n",
        "            return x0\n",
        "        if (y0 < 0.5) and (y1 >= 0.5) and (x1 != x0):\n",
        "            t = (0.5 - y0) / (y1 - y0)\n",
        "            return x0 + t * (x1 - x0)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_baselines(\n",
        "    model,\n",
        "    bpe,\n",
        "    clean_text: str,\n",
        "    corrupt_text: str,\n",
        "    token_a_str: str,\n",
        "    token_b_str: str,\n",
        "    *,\n",
        "    device: Optional[str] = None,\n",
        "    overwrite_cache: bool = True,\n",
        ") -> Baselines:\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    idx_clean = bpe(clean_text).to(device)\n",
        "    idx_corr = bpe(corrupt_text).to(device)\n",
        "\n",
        "    if idx_clean.shape[1] != idx_corr.shape[1]:\n",
        "        raise ValueError(\n",
        "            f\"Token length mismatch: clean T={idx_clean.shape[1]} vs corrupt T={idx_corr.shape[1]}. \"\n",
        "            \"They must match for activation patching.\"\n",
        "        )\n",
        "\n",
        "    token_a_id = single_token_id(bpe, token_a_str)\n",
        "    token_b_id = single_token_id(bpe, token_b_str)\n",
        "\n",
        "    # Clean run: cache activations\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=overwrite_cache)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits missing after clean run.\")\n",
        "    clean_score = score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "    # Corrupt baseline\n",
        "    _ = model(idx_corr)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits missing after corrupt run.\")\n",
        "    corrupt_score = score_from_last_logits(model.last_logits[0], token_a_id, token_b_id)\n",
        "\n",
        "    n_layer = len(model.transformer.h)\n",
        "    seq_len = int(idx_clean.shape[1])\n",
        "\n",
        "    return Baselines(\n",
        "        clean_score=clean_score,\n",
        "        corrupt_score=corrupt_score,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        seq_len=seq_len,\n",
        "        n_layer=n_layer,\n",
        "    )\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def full_patch_matrix(\n",
        "    model,\n",
        "    bpe,\n",
        "    corrupt_text: str,\n",
        "    baselines: Baselines,\n",
        "    *,\n",
        "    device: Optional[str] = None,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the standard heatmap scores for alpha=1 patching:\n",
        "      M[L, P] = score after patching (L,P) with clean (L,P).\n",
        "    Shape: (n_layer, seq_len)\n",
        "    \"\"\"\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    idx_corr = bpe(corrupt_text).to(device)\n",
        "\n",
        "    M = torch.empty((baselines.n_layer, baselines.seq_len), dtype=torch.float32)\n",
        "    for L in range(baselines.n_layer):\n",
        "        for P in range(baselines.seq_len):\n",
        "            _ = model(\n",
        "                idx_corr,\n",
        "                layer_to_patch=L,\n",
        "                position_to_patch=P,\n",
        "                patch_alpha=1.0,\n",
        "            )\n",
        "            score = score_from_last_logits(model.last_logits[0], baselines.token_a_id, baselines.token_b_id)\n",
        "            M[L, P] = score\n",
        "    return M\n",
        "\n",
        "\n",
        "def select_hotspots(\n",
        "    M: torch.Tensor,\n",
        "    baselines: Baselines,\n",
        "    *,\n",
        "    top_k: int = 3,\n",
        ") -> Tuple[List[Coord], Coord]:\n",
        "    \"\"\"\n",
        "    Picks:\n",
        "      - hotspots: top_k cells with highest restoration at alpha=1\n",
        "      - coldspot: cell with minimal |score - corrupt_score| (near-zero effect)\n",
        "    \"\"\"\n",
        "    n_layer, T = M.shape\n",
        "    R = torch.empty_like(M)\n",
        "    for L in range(n_layer):\n",
        "        for P in range(T):\n",
        "            R[L, P] = float(\n",
        "                restoration_fraction(float(M[L, P]), baselines.corrupt_score, baselines.clean_score)\n",
        "            )\n",
        "\n",
        "    # Flatten + sort by restoration descending (best restoration first)\n",
        "    flat = []\n",
        "    for L in range(n_layer):\n",
        "        for P in range(T):\n",
        "            r = float(R[L, P])\n",
        "            if not math.isnan(r):\n",
        "                flat.append(((L, P), r))\n",
        "\n",
        "    flat.sort(key=lambda x: x[1], reverse=True)\n",
        "    hotspots = [coord for coord, _ in flat[:top_k]]\n",
        "\n",
        "    # Coldspot: closest to corrupt baseline (small absolute effect)\n",
        "    best_cold = (0, 0)\n",
        "    best_dist = float(\"inf\")\n",
        "    for L in range(n_layer):\n",
        "        for P in range(T):\n",
        "            dist = abs(float(M[L, P]) - baselines.corrupt_score)\n",
        "            if dist < best_dist:\n",
        "                best_dist = dist\n",
        "                best_cold = (L, P)\n",
        "\n",
        "    return hotspots, best_cold\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def interpolation_curve(\n",
        "    model,\n",
        "    bpe,\n",
        "    corrupt_text: str,\n",
        "    baselines: Baselines,\n",
        "    coord: Coord,\n",
        "    alphas: Sequence[float],\n",
        "    *,\n",
        "    device: Optional[str] = None,\n",
        "    source_coord: Optional[Coord] = None,  # optional wrong-source + interpolation together\n",
        ") -> Curve:\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    idx_corr = bpe(corrupt_text).to(device)\n",
        "\n",
        "    L, P = coord\n",
        "    if source_coord is None:\n",
        "        srcL, srcP = L, P\n",
        "    else:\n",
        "        srcL, srcP = source_coord\n",
        "\n",
        "    scores: List[float] = []\n",
        "    restorations: List[float] = []\n",
        "    alphas_out: List[float] = []\n",
        "\n",
        "    for a in alphas:\n",
        "        a = float(a)\n",
        "        _ = model(\n",
        "            idx_corr,\n",
        "            layer_to_patch=L,\n",
        "            position_to_patch=P,\n",
        "            source_layer=srcL,\n",
        "            source_position=srcP,\n",
        "            patch_alpha=a,\n",
        "        )\n",
        "        sc = score_from_last_logits(model.last_logits[0], baselines.token_a_id, baselines.token_b_id)\n",
        "        r = restoration_fraction(sc, baselines.corrupt_score, baselines.clean_score)\n",
        "\n",
        "        alphas_out.append(a)\n",
        "        scores.append(sc)\n",
        "        restorations.append(r)\n",
        "\n",
        "    a50 = estimate_alpha50(alphas_out, restorations)\n",
        "\n",
        "    return Curve(\n",
        "        coord=coord,\n",
        "        alphas=alphas_out,\n",
        "        scores=scores,\n",
        "        restorations=restorations,\n",
        "        alpha50=a50,\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_restoration_curves(\n",
        "    curves: Sequence[Curve],\n",
        "    *,\n",
        "    out_path: str = \"extra2_interpolation_curves.png\",\n",
        "    title: str = \"EXTRA 2: Interpolation sweep (normalized restoration R(alpha))\",\n",
        ") -> str:\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure()\n",
        "    for c in curves:\n",
        "        L, P = c.coord\n",
        "        plt.plot(c.alphas, c.restorations, marker=\"o\", label=f\"(L={L}, P={P})\")\n",
        "\n",
        "    plt.axhline(0.5, linestyle=\"--\")\n",
        "    plt.xlabel(\"alpha\")\n",
        "    plt.ylabel(\"R(alpha)\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing extra2_interpolation_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra2_interpolation_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "import interpolation_sweep as isweep\n",
        "\n",
        "\n",
        "def parse_coords(s: str) -> List[Tuple[int, int]]:\n",
        "    # \"L:P,L:P\" -> [(L,P),...]\n",
        "    out = []\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return out\n",
        "    for part in s.split(\",\"):\n",
        "        Ls, Ps = part.strip().split(\":\")\n",
        "        out.append((int(Ls), int(Ps)))\n",
        "    return out\n",
        "\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--clean\", type=str, default=\"Michelle Jones was a top-notch student. Michelle\")\n",
        "    p.add_argument(\"--corrupt\", type=str, default=\"Michelle Smith was a top-notch student. Michelle\")\n",
        "    p.add_argument(\"--token_a\", type=str, default=\" Jones\")   # clean-consistent\n",
        "    p.add_argument(\"--token_b\", type=str, default=\" Smith\")   # corrupt-consistent\n",
        "    p.add_argument(\"--alphas\", type=str, default=\"0,0.25,0.5,0.75,1\")\n",
        "    p.add_argument(\"--top_k\", type=int, default=3)\n",
        "    p.add_argument(\"--coords\", type=str, default=\"\", help=\"Optional manual coords 'L:P,L:P,...' (skips hotspot search)\")\n",
        "    p.add_argument(\"--out\", type=str, default=\"extra2_interpolation_curves.png\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    args = parse_args()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    alphas = [float(x.strip()) for x in args.alphas.split(\",\") if x.strip()]\n",
        "\n",
        "    # 1) baselines + cache clean activations\n",
        "    base = isweep.compute_baselines(\n",
        "        model,\n",
        "        bpe,\n",
        "        clean_text=args.clean,\n",
        "        corrupt_text=args.corrupt,\n",
        "        token_a_str=args.token_a,\n",
        "        token_b_str=args.token_b,\n",
        "        device=device,\n",
        "        overwrite_cache=True,\n",
        "    )\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"score_clean  = {base.clean_score:.4f}\")\n",
        "    print(f\"score_corr   = {base.corrupt_score:.4f}\")\n",
        "    print(f\"Seq len T    = {base.seq_len}\")\n",
        "    print(f\"n_layer      = {base.n_layer}\")\n",
        "\n",
        "    manual_coords = parse_coords(args.coords)\n",
        "    if manual_coords:\n",
        "        hotspots = manual_coords\n",
        "        coldspot = manual_coords[-1]\n",
        "        print(\"\\nUsing manual coords:\", hotspots)\n",
        "    else:\n",
        "        # 2) compute alpha=1 patch matrix (standard heatmap values)\n",
        "        print(\"\\nComputing full alpha=1 patch matrix (for hotspot selection)...\")\n",
        "        M = isweep.full_patch_matrix(model, bpe, args.corrupt, base, device=device)\n",
        "\n",
        "        # 3) pick hotspots + coldspot\n",
        "        hotspots, coldspot = isweep.select_hotspots(M, base, top_k=args.top_k)\n",
        "        print(\"Hotspots:\", hotspots)\n",
        "        print(\"Coldspot:\", coldspot)\n",
        "\n",
        "    # 4) interpolation sweeps\n",
        "    curves = []\n",
        "    for c in hotspots:\n",
        "        curves.append(isweep.interpolation_curve(model, bpe, args.corrupt, base, c, alphas, device=device))\n",
        "    # add control curve\n",
        "    if coldspot not in hotspots:\n",
        "        curves.append(isweep.interpolation_curve(model, bpe, args.corrupt, base, coldspot, alphas, device=device))\n",
        "\n",
        "    print(\"\\n=== Curves (R(alpha)) ===\")\n",
        "    for cv in curves:\n",
        "        L, P = cv.coord\n",
        "        print(f\"\\nCoord (L={L}, P={P}) alpha50={cv.alpha50}\")\n",
        "        for a, s, r in zip(cv.alphas, cv.scores, cv.restorations):\n",
        "            print(f\"  alpha={a:>4.2f}  score={s:>8.4f}  R={r:>8.4f}\")\n",
        "\n",
        "    # 5) plot\n",
        "    out_path = isweep.plot_restoration_curves(curves, out_path=args.out)\n",
        "    print(f\"\\nSaved plot to: {out_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_extra2_interpolation.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_extra2_interpolation.py\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "\n",
        "\n",
        "def _make_tiny():\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"\n",
        "    cfg.vocab_size = 200\n",
        "    cfg.block_size = 32\n",
        "    model = GPT(cfg).eval()\n",
        "    return model, cfg\n",
        "\n",
        "\n",
        "def _make_clean_corrupt(cfg, T=12, changed_pos=3):\n",
        "    torch.manual_seed(0)\n",
        "    clean = torch.randint(0, cfg.vocab_size, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, changed_pos] = (corrupt[0, changed_pos] + 1) % cfg.vocab_size\n",
        "    return clean, corrupt, changed_pos\n",
        "\n",
        "\n",
        "def test_patch_alpha_bounds_enforced():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt, P = _make_clean_corrupt(cfg, T=10, changed_pos=3)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=P, patch_alpha=-0.1)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        with torch.no_grad():\n",
        "            _ = model(corrupt, layer_to_patch=0, position_to_patch=P, patch_alpha=1.1)\n",
        "\n",
        "\n",
        "def test_alpha0_is_noop_matches_corrupted_baseline_logits():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt, P = _make_clean_corrupt(cfg, T=12, changed_pos=3)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt)  # baseline\n",
        "        base_last = model.last_logits.clone()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, layer_to_patch=0, position_to_patch=P, patch_alpha=0.0)\n",
        "        patched_last = model.last_logits.clone()\n",
        "\n",
        "    assert torch.allclose(base_last, patched_last, rtol=1e-6, atol=1e-7)\n",
        "    assert model.last_patch_alpha == 0.0\n",
        "\n",
        "\n",
        "def test_alpha1_sets_activation_equal_to_clean_cache_at_that_cell():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt, P = _make_clean_corrupt(cfg, T=12, changed_pos=3)\n",
        "    L = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True, layer_to_patch=L, position_to_patch=P, patch_alpha=1.0)\n",
        "\n",
        "    patched_acts = model.last_activations\n",
        "    assert patched_acts is not None\n",
        "    assert torch.allclose(\n",
        "        patched_acts[L][P],\n",
        "        model.clean_activations[L][P],\n",
        "        rtol=1e-5,\n",
        "        atol=1e-6,\n",
        "    )\n",
        "    assert model.last_patch == (L, P)\n",
        "    assert model.last_patch_source == (L, P)\n",
        "    assert model.last_patch_alpha == 1.0\n",
        "\n",
        "\n",
        "def test_alpha_half_is_exact_convex_combination_of_clean_and_corrupted_vectors():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt, P = _make_clean_corrupt(cfg, T=12, changed_pos=3)\n",
        "    L = 0\n",
        "    alpha = 0.5\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    # Record corrupted activations (baseline)\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True)\n",
        "    base_acts = model.last_activations\n",
        "    assert base_acts is not None\n",
        "\n",
        "    # Patched run with alpha=0.5\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True, layer_to_patch=L, position_to_patch=P, patch_alpha=alpha)\n",
        "    patched_acts = model.last_activations\n",
        "    assert patched_acts is not None\n",
        "\n",
        "    expected = (alpha * model.clean_activations[L][P]) + ((1.0 - alpha) * base_acts[L][P])\n",
        "    assert torch.allclose(patched_acts[L][P], expected, rtol=1e-5, atol=1e-6)\n",
        "    assert model.last_patch_alpha == alpha\n",
        "\n",
        "\n",
        "def test_wrong_source_plus_interpolation_uses_clean_source_in_mixture():\n",
        "    model, cfg = _make_tiny()\n",
        "    clean, corrupt, P = _make_clean_corrupt(cfg, T=12, changed_pos=3)\n",
        "    L = 0\n",
        "    srcP = 0\n",
        "    alpha = 0.25\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(corrupt, record_activations=True)\n",
        "    base_acts = model.last_activations\n",
        "    assert base_acts is not None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _ = model(\n",
        "            corrupt,\n",
        "            record_activations=True,\n",
        "            layer_to_patch=L,\n",
        "            position_to_patch=P,\n",
        "            source_layer=L,\n",
        "            source_position=srcP,\n",
        "            patch_alpha=alpha,\n",
        "        )\n",
        "    patched_acts = model.last_activations\n",
        "    assert patched_acts is not None\n",
        "\n",
        "    expected = (alpha * model.clean_activations[L][srcP]) + ((1.0 - alpha) * base_acts[L][P])\n",
        "    assert torch.allclose(patched_acts[L][P], expected, rtol=1e-5, atol=1e-6)\n",
        "\n",
        "    assert model.last_patch == (L, P)\n",
        "    assert model.last_patch_source == (L, srcP)\n",
        "    assert model.last_patch_alpha == alpha\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean  = -4.1241\n",
            "score_corr   = 5.6562\n",
            "Seq len T    = 11\n",
            "n_layer      = 12\n",
            "\n",
            "Computing full alpha=1 patch matrix (for hotspot selection)...\n",
            "Hotspots: [(11, 10), (0, 1), (1, 1)]\n",
            "Coldspot: (0, 0)\n",
            "\n",
            "=== Curves (R(alpha)) ===\n",
            "\n",
            "Coord (L=11, P=10) alpha50=0.5127979048181796\n",
            "  alpha=0.00  score=  5.6562  R= -0.0000\n",
            "  alpha=0.25  score=  3.3084  R=  0.2401\n",
            "  alpha=0.50  score=  0.8930  R=  0.4870\n",
            "  alpha=0.75  score= -1.5861  R=  0.7405\n",
            "  alpha=1.00  score= -4.1241  R=  1.0000\n",
            "\n",
            "Coord (L=0, P=1) alpha50=0.5414549996037235\n",
            "  alpha=0.00  score=  5.6562  R= -0.0000\n",
            "  alpha=0.25  score=  3.8970  R=  0.1799\n",
            "  alpha=0.50  score=  1.2609  R=  0.4494\n",
            "  alpha=0.75  score= -1.7233  R=  0.7545\n",
            "  alpha=1.00  score= -4.0691  R=  0.9944\n",
            "\n",
            "Coord (L=1, P=1) alpha50=0.532609123057202\n",
            "  alpha=0.00  score=  5.6562  R= -0.0000\n",
            "  alpha=0.25  score=  3.7949  R=  0.1903\n",
            "  alpha=0.50  score=  1.1457  R=  0.4612\n",
            "  alpha=0.75  score= -1.7647  R=  0.7588\n",
            "  alpha=1.00  score= -4.0673  R=  0.9942\n",
            "\n",
            "Coord (L=0, P=0) alpha50=None\n",
            "  alpha=0.00  score=  5.6562  R= -0.0000\n",
            "  alpha=0.25  score=  5.6562  R= -0.0000\n",
            "  alpha=0.50  score=  5.6562  R= -0.0000\n",
            "  alpha=0.75  score=  5.6562  R= -0.0000\n",
            "  alpha=1.00  score=  5.6562  R= -0.0000\n",
            "\n",
            "Saved plot to: extra2_interpolation_curves.png\n"
          ]
        }
      ],
      "source": [
        "!python extra2_interpolation_driver.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                    [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 3.03s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q test_extra2_interpolation.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RUN EXTRA SECTION 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing interpolation_sweep_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile interpolation_sweep_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "import tokenization_protocol as tp  \n",
        "from baseline_utils import single_token_id  \n",
        "\n",
        "\n",
        "def parse_alphas(xs: List[str]) -> List[float]:\n",
        "    return [float(x) for x in xs]\n",
        "\n",
        "\n",
        "def score_from_last_logits(last_logits_1d: torch.Tensor, token_a_id: int, token_b_id: int) -> float:\n",
        "    # score = logit(B) - logit(A)\n",
        "    return float(last_logits_1d[token_b_id] - last_logits_1d[token_a_id])\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_once(\n",
        "    model: GPT,\n",
        "    idx: torch.Tensor,\n",
        "    *,\n",
        "    cache_clean: bool = False,\n",
        "    overwrite_cache: bool = False,\n",
        "    record_acts: bool = False,\n",
        "    layer_to_patch: Optional[int] = None,\n",
        "    position_to_patch: Optional[int] = None,\n",
        "    patch_alpha: Optional[float] = None,\n",
        ") -> Tuple[torch.Tensor, Optional[List[List[torch.Tensor]]]]:\n",
        "    logits, _ = model(\n",
        "        idx,\n",
        "        record_activations=record_acts,\n",
        "        cache_activations=cache_clean,\n",
        "        overwrite_cache=overwrite_cache,\n",
        "        layer_to_patch=layer_to_patch,\n",
        "        position_to_patch=position_to_patch,\n",
        "        patch_alpha=patch_alpha,\n",
        "    )\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits was not set.\")\n",
        "    acts = model.last_activations if record_acts else None\n",
        "    return model.last_logits[0].detach().clone(), acts\n",
        "\n",
        "\n",
        "def pick_best_layer_at_changed_pos(\n",
        "    model: GPT,\n",
        "    idx_corrupt: torch.Tensor,\n",
        "    token_a_id: int,\n",
        "    token_b_id: int,\n",
        "    *,\n",
        "    changed_pos: int,\n",
        "    score_corr: float,\n",
        ") -> int:\n",
        "    n_layer = len(model.transformer.h)\n",
        "    best_L = 0\n",
        "    best_restoration = -1e9\n",
        "\n",
        "    for L in range(n_layer):\n",
        "        last, _ = run_once(\n",
        "            model,\n",
        "            idx_corrupt,\n",
        "            layer_to_patch=L,\n",
        "            position_to_patch=changed_pos,\n",
        "            patch_alpha=1.0,\n",
        "        )\n",
        "        s = score_from_last_logits(last, token_a_id, token_b_id)\n",
        "        restoration = abs(s - score_corr)\n",
        "        if restoration > best_restoration:\n",
        "            best_restoration = restoration\n",
        "            best_L = L\n",
        "\n",
        "    return best_L\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--clean\", type=str, default=\"Michelle Jones was a top-notch student. Michelle\")\n",
        "    ap.add_argument(\"--corrupt\", type=str, default=\"Michelle Smith was a top-notch student. Michelle\")\n",
        "    ap.add_argument(\"--token_a\", type=str, default=\" Jones\")\n",
        "    ap.add_argument(\"--token_b\", type=str, default=\" Smith\")\n",
        "\n",
        "    ap.add_argument(\"--layer\", type=int, default=-1, help=\"Target layer L. If -1, auto-pick best L at changed token position.\")\n",
        "    ap.add_argument(\"--pos\", type=int, default=-1, help=\"Target position P. If -1, use changed token position.\")\n",
        "    ap.add_argument(\"--alphas\", nargs=\"+\", default=[\"0\", \"0.25\", \"0.5\", \"0.75\", \"1\"])\n",
        "\n",
        "    ap.add_argument(\"--device\", type=str, default=None)\n",
        "    ap.add_argument(\"--check_mixture\", action=\"store_true\", help=\"Also verify x_patched  x_clean+(1-)x_corr using recorded activations.\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    device = args.device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    # Tokenization validation\n",
        "    clean_rep = tp.build_report(bpe, args.clean)\n",
        "    corrupt_rep = tp.build_report(bpe, args.corrupt)\n",
        "    comp = tp.compare_clean_corrupt(clean_rep, corrupt_rep)\n",
        "\n",
        "    if not comp.same_length:\n",
        "        raise RuntimeError(f\"Token length mismatch: clean={clean_rep.seq_len}, corrupt={corrupt_rep.seq_len}\")\n",
        "    if comp.diff_count != 1:\n",
        "        raise RuntimeError(f\"Expected exactly 1 differing token position; got {comp.diff_count}: {comp.diff_positions}\")\n",
        "\n",
        "    changed_pos = int(comp.diff_positions[0])\n",
        "    print(f\"Seq len T={clean_rep.seq_len}, changed token position={changed_pos}\")\n",
        "\n",
        "    # Load model\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "\n",
        "    # Token ids for metric\n",
        "    token_a_id = single_token_id(bpe, args.token_a)\n",
        "    token_b_id = single_token_id(bpe, args.token_b)\n",
        "\n",
        "    # Build tensors\n",
        "    idx_clean = bpe(args.clean).to(device)\n",
        "    idx_corrupt = bpe(args.corrupt).to(device)\n",
        "\n",
        "    # Clean baseline (cache activations)\n",
        "    last_clean, _ = run_once(model, idx_clean, cache_clean=True, overwrite_cache=True)\n",
        "    score_clean = score_from_last_logits(last_clean, token_a_id, token_b_id)\n",
        "\n",
        "    # Corrupt baseline\n",
        "    last_corr, acts_corr = run_once(model, idx_corrupt, record_acts=args.check_mixture)\n",
        "    score_corr = score_from_last_logits(last_corr, token_a_id, token_b_id)\n",
        "\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"score_clean  = {score_clean:.6f}\")\n",
        "    print(f\"score_corr   = {score_corr:.6f}\")\n",
        "    print(f\"delta(corr-clean) = {score_corr - score_clean:.6f}\")\n",
        "\n",
        "    # Choose (L,P)\n",
        "    P = changed_pos if args.pos < 0 else int(args.pos)\n",
        "    if args.layer < 0:\n",
        "        L = pick_best_layer_at_changed_pos(model, idx_corrupt, token_a_id, token_b_id, changed_pos=P, score_corr=score_corr)\n",
        "        print(f\"\\nAuto-picked layer L={L} at position P={P}\")\n",
        "    else:\n",
        "        L = int(args.layer)\n",
        "        print(f\"\\nUsing provided (L,P)=({L},{P})\")\n",
        "\n",
        "    alphas = parse_alphas(args.alphas)\n",
        "\n",
        "    # Full patch score (alpha=1) used for endpoint check\n",
        "    last_full, _ = run_once(model, idx_corrupt, layer_to_patch=L, position_to_patch=P, patch_alpha=1.0)\n",
        "    score_full = score_from_last_logits(last_full, token_a_id, token_b_id)\n",
        "\n",
        "    # Sweep\n",
        "    print(\"\\n=== Interpolation sweep ===\")\n",
        "    print(\"alpha | score(alpha) | R_hat_vs_full | meta(last_patch,last_alpha)\")\n",
        "    print(\"-\"*78)\n",
        "\n",
        "    eps_score = 1e-5\n",
        "    base_denom = (score_full - score_corr)\n",
        "\n",
        "    clean_vec = model.clean_activations[L][P].to(device)\n",
        "\n",
        "    for a in alphas:\n",
        "        record = bool(args.check_mixture)\n",
        "        last_a, acts_a = run_once(\n",
        "            model,\n",
        "            idx_corrupt,\n",
        "            record_acts=record,\n",
        "            layer_to_patch=L,\n",
        "            position_to_patch=P,\n",
        "            patch_alpha=a,\n",
        "        )\n",
        "        s = score_from_last_logits(last_a, token_a_id, token_b_id)\n",
        "\n",
        "        # normalized w.r.t full patch (so endpoints are guaranteed to be 0 and 1 if correct)\n",
        "        if abs(base_denom) < 1e-12:\n",
        "            rhat = float(\"nan\")\n",
        "        else:\n",
        "            rhat = (s - score_corr) / base_denom\n",
        "\n",
        "        meta = (model.last_patch, model.last_patch_alpha)\n",
        "        print(f\"{a:>4.2f} | {s:>11.6f} | {rhat:>12.6f} | {meta}\")\n",
        "\n",
        "        # Mixture check (activation-level)\n",
        "        if args.check_mixture:\n",
        "            if acts_corr is None or acts_a is None:\n",
        "                raise RuntimeError(\"Mixture check requested but activations were not recorded.\")\n",
        "            x_corr = acts_corr[L][P].to(device)\n",
        "            x_pat = acts_a[L][P].to(device)\n",
        "            target = (a * clean_vec) + ((1.0 - a) * x_corr)\n",
        "            max_err = float((x_pat - target).abs().max().item())\n",
        "            if max_err > 1e-4:\n",
        "                raise RuntimeError(f\"Mixture check FAILED at alpha={a}: max|x_patched - mix| = {max_err:.6e}\")\n",
        "\n",
        "    # Endpoint checks\n",
        "    # alpha=0\n",
        "    last_0, _ = run_once(model, idx_corrupt, layer_to_patch=L, position_to_patch=P, patch_alpha=0.0)\n",
        "    score_0 = score_from_last_logits(last_0, token_a_id, token_b_id)\n",
        "\n",
        "    # alpha=1\n",
        "    last_1, _ = run_once(model, idx_corrupt, layer_to_patch=L, position_to_patch=P, patch_alpha=1.0)\n",
        "    score_1 = score_from_last_logits(last_1, token_a_id, token_b_id)\n",
        "\n",
        "    print(\"\\n=== Endpoint checks ===\")\n",
        "    print(f\"score(alpha=0) = {score_0:.6f}  vs score_corr = {score_corr:.6f}\")\n",
        "    print(f\"score(alpha=1) = {score_1:.6f}  vs score_full = {score_full:.6f}\")\n",
        "\n",
        "    if abs(score_0 - score_corr) > eps_score:\n",
        "        raise RuntimeError(\"FAILED endpoint check =0: score(0) != score_corr (patch should be a no-op).\")\n",
        "    if abs(score_1 - score_full) > eps_score:\n",
        "        raise RuntimeError(\"FAILED endpoint check =1: score(1) != score_full (must match standard patch).\")\n",
        "\n",
        "    print(\"\\n EXTRA 2 looks correct: endpoints match and sweep ran successfully.\")\n",
        "    if args.check_mixture:\n",
        "        print(\" Mixture check passed: activations match x_clean+(1-)x_corr at the patched coordinate.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Seq len T=11, changed token position=1\n",
            "number of parameters: 124.44M\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean  = -4.124077\n",
            "score_corr   = 5.656242\n",
            "delta(corr-clean) = 9.780319\n",
            "\n",
            "Auto-picked layer L=0 at position P=1\n",
            "\n",
            "=== Interpolation sweep ===\n",
            "alpha | score(alpha) | R_hat_vs_full | meta(last_patch,last_alpha)\n",
            "------------------------------------------------------------------------------\n",
            "0.00 |    5.656242 |    -0.000000 | ((0, 1), 0.0)\n",
            "0.25 |    3.897049 |     0.180887 | ((0, 1), 0.25)\n",
            "0.50 |    1.260918 |     0.451945 | ((0, 1), 0.5)\n",
            "0.75 |   -1.723251 |     0.758789 | ((0, 1), 0.75)\n",
            "1.00 |   -4.069115 |     1.000000 | ((0, 1), 1.0)\n",
            "\n",
            "=== Endpoint checks ===\n",
            "score(alpha=0) = 5.656242  vs score_corr = 5.656242\n",
            "score(alpha=1) = -4.069115  vs score_full = -4.069115\n",
            "\n",
            " EXTRA 2 looks correct: endpoints match and sweep ran successfully.\n",
            " Mixture check passed: activations match x_clean+(1-)x_corr at the patched coordinate.\n"
          ]
        }
      ],
      "source": [
        "!python interpolation_sweep_driver.py --check_mixture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Seq len T=11, changed token position=1\n",
            "number of parameters: 124.44M\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean  = -4.124077\n",
            "score_corr   = 5.656242\n",
            "delta(corr-clean) = 9.780319\n",
            "\n",
            "Using provided (L,P)=(5,1)\n",
            "\n",
            "=== Interpolation sweep ===\n",
            "alpha | score(alpha) | R_hat_vs_full | meta(last_patch,last_alpha)\n",
            "------------------------------------------------------------------------------\n",
            "0.00 |    5.656242 |    -0.000000 | ((5, 1), 0.0)\n",
            "0.25 |    3.700050 |     0.208917 | ((5, 1), 0.25)\n",
            "0.50 |    1.173576 |     0.478738 | ((5, 1), 0.5)\n",
            "0.75 |   -1.493301 |     0.763554 | ((5, 1), 0.75)\n",
            "1.00 |   -3.707260 |     1.000000 | ((5, 1), 1.0)\n",
            "\n",
            "=== Endpoint checks ===\n",
            "score(alpha=0) = 5.656242  vs score_corr = 5.656242\n",
            "score(alpha=1) = -3.707260  vs score_full = -3.707260\n",
            "\n",
            " EXTRA 2 looks correct: endpoints match and sweep ran successfully.\n",
            " Mixture check passed: activations match x_clean+(1-)x_corr at the patched coordinate.\n"
          ]
        }
      ],
      "source": [
        "!python interpolation_sweep_driver.py --layer 5 --pos 1 --alphas 0 0.25 0.5 0.75 1 --check_mixture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 124.44M\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean  = -4.124077\n",
            "score_corr   = 5.656242\n",
            "T            = 11\n",
            "n_layer      = 12\n",
            "\n",
            "Computing full alpha=1 patch matrix (for hotspot selection)...\n",
            "Hotspots: [(11, 10), (0, 1), (1, 1)]\n",
            "Coldspot: (0, 0)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Curves (table) ===\n",
            "\n",
            "Coord (L=11, P=10)  alpha50=0.5127979048181796\n",
            "  =0.00  score= 5.656242  R= -0.0000\n",
            "  =0.25  score= 3.308426  R=  0.2401\n",
            "  =0.50  score= 0.892990  R=  0.4870\n",
            "  =0.75  score=-1.586075  R=  0.7405\n",
            "  =1.00  score=-4.124077  R=  1.0000\n",
            "\n",
            "Coord (L=0, P=1)  alpha50=0.5414549996037235\n",
            "  =0.00  score= 5.656242  R= -0.0000\n",
            "  =0.25  score= 3.897049  R=  0.1799\n",
            "  =0.50  score= 1.260918  R=  0.4494\n",
            "  =0.75  score=-1.723251  R=  0.7545\n",
            "  =1.00  score=-4.069115  R=  0.9944\n",
            "\n",
            "Coord (L=1, P=1)  alpha50=0.532609123057202\n",
            "  =0.00  score= 5.656242  R= -0.0000\n",
            "  =0.25  score= 3.794891  R=  0.1903\n",
            "  =0.50  score= 1.145706  R=  0.4612\n",
            "  =0.75  score=-1.764702  R=  0.7588\n",
            "  =1.00  score=-4.067261  R=  0.9942\n",
            "\n",
            "Coord (L=0, P=0)  alpha50=None\n",
            "  =0.00  score= 5.656242  R= -0.0000\n",
            "  =0.25  score= 5.656242  R= -0.0000\n",
            "  =0.50  score= 5.656242  R= -0.0000\n",
            "  =0.75  score= 5.656242  R= -0.0000\n",
            "  =1.00  score= 5.656242  R= -0.0000\n",
            "\n",
            "Done   (Estas 2 figuras suelen ser suficientes para justificar el 'doseresponse'.)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "import interpolation_sweep as isweep\n",
        "\n",
        "CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "TOKEN_A_STR  = \" Jones\"\n",
        "TOKEN_B_STR  = \" Smith\"\n",
        "\n",
        "ALPHAS = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "TOP_K_HOTSPOTS = 3  \n",
        "OUT_DIR = \"artifacts/extra2\"\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "device = get_device()\n",
        "print(\"Device:\", device)\n",
        "\n",
        "bpe = BPETokenizer()\n",
        "model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "\n",
        "base = isweep.compute_baselines(\n",
        "    model, bpe,\n",
        "    clean_text=CLEAN_TEXT,\n",
        "    corrupt_text=CORRUPT_TEXT,\n",
        "    token_a_str=TOKEN_A_STR,\n",
        "    token_b_str=TOKEN_B_STR,\n",
        "    device=device,\n",
        "    overwrite_cache=True,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Baselines ===\")\n",
        "print(f\"score_clean  = {base.clean_score:.6f}\")\n",
        "print(f\"score_corr   = {base.corrupt_score:.6f}\")\n",
        "print(f\"T            = {base.seq_len}\")\n",
        "print(f\"n_layer      = {base.n_layer}\")\n",
        "\n",
        "print(\"\\nComputing full alpha=1 patch matrix (for hotspot selection)...\")\n",
        "M = isweep.full_patch_matrix(model, bpe, CORRUPT_TEXT, base, device=device)\n",
        "\n",
        "hotspots, coldspot = isweep.select_hotspots(M, base, top_k=TOP_K_HOTSPOTS)\n",
        "coords = list(hotspots)\n",
        "if coldspot not in coords:\n",
        "    coords.append(coldspot)\n",
        "\n",
        "print(\"Hotspots:\", hotspots)\n",
        "print(\"Coldspot:\", coldspot)\n",
        "\n",
        "curves = []\n",
        "for coord in coords:\n",
        "    cv = isweep.interpolation_curve(\n",
        "        model, bpe,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        baselines=base,\n",
        "        coord=coord,\n",
        "        alphas=ALPHAS,\n",
        "        device=device,\n",
        "        source_coord=None,  # MATCH source (L,P)\n",
        "    )\n",
        "    curves.append(cv)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.title(\"EXTRA 2  Interpolation sweep: normalized restoration R()\")\n",
        "for cv in curves:\n",
        "    L, P = cv.coord\n",
        "    label = f\"(L={L},P={P})\"\n",
        "    if cv.alpha50 is not None:\n",
        "        label += f\"  50{cv.alpha50:.2f}\"\n",
        "    plt.plot(cv.alphas, cv.restorations, marker=\"o\", label=label)\n",
        "\n",
        "plt.axhline(0.5, linestyle=\"--\")\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"R()\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.title(\"EXTRA 2  Interpolation sweep: score() with baselines\")\n",
        "for cv in curves:\n",
        "    L, P = cv.coord\n",
        "    plt.plot(cv.alphas, cv.scores, marker=\"o\", label=f\"(L={L},P={P})\")\n",
        "\n",
        "plt.axhline(base.clean_score, linestyle=\"--\", label=\"score_clean\")\n",
        "plt.axhline(base.corrupt_score, linestyle=\"--\", label=\"score_corr\")\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"score = logit(B)  logit(A)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== Curves (table) ===\")\n",
        "for cv in curves:\n",
        "    L, P = cv.coord\n",
        "    print(f\"\\nCoord (L={L}, P={P})  alpha50={cv.alpha50}\")\n",
        "    for a, s, r in zip(cv.alphas, cv.scores, cv.restorations):\n",
        "        print(f\"  ={a:>4.2f}  score={s:>9.6f}  R={r:>8.4f}\")\n",
        "\n",
        "print(\"\\nDone   (Estas 2 figuras suelen ser suficientes para justificar el 'doseresponse'.)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXTRA SECTION 3: Patch inside the block: after attention vs after MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing extra3_intrablock_sweep.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra3_intrablock_sweep.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Sequence, Tuple\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def _infer_device(model: torch.nn.Module) -> torch.device:\n",
        "    try:\n",
        "        return next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def single_token_id(bpe, token_str: str) -> int:\n",
        "    ids = bpe(token_str)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(\n",
        "            f\"Target token string must map to exactly 1 BPE token. \"\n",
        "            f\"Got {len(ids)} tokens for {repr(token_str)}: {ids}\"\n",
        "        )\n",
        "    return int(ids[0])\n",
        "\n",
        "\n",
        "def logit_diff_from_last_logits(last_logits_1d: torch.Tensor, *, token_a_id: int, token_b_id: int) -> float:\n",
        "    a = float(last_logits_1d[token_a_id])\n",
        "    b = float(last_logits_1d[token_b_id])\n",
        "    return b - a\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Extra3Result:\n",
        "    post_attn_matrix: torch.Tensor  # (n_layers, T) on CPU float32\n",
        "    post_mlp_matrix: torch.Tensor   # (n_layers, T) on CPU float32\n",
        "    n_layers: int\n",
        "    seq_len: int\n",
        "    clean_score: float\n",
        "    corrupt_score: float\n",
        "    token_a_str: str\n",
        "    token_b_str: str\n",
        "    token_a_id: int\n",
        "    token_b_id: int\n",
        "    clean_text: str\n",
        "    corrupt_text: str\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sweep_location_from_ids(\n",
        "    model,\n",
        "    idx_corrupt: torch.LongTensor,\n",
        "    *,\n",
        "    token_a_id: int,\n",
        "    token_b_id: int,\n",
        "    patch_location: str,\n",
        "    layers: Optional[Sequence[int]] = None,\n",
        "    positions: Optional[Sequence[int]] = None,\n",
        "    progress: bool = False,\n",
        ") -> torch.Tensor:\n",
        "    if idx_corrupt.ndim != 2 or idx_corrupt.shape[0] != 1:\n",
        "        raise ValueError(f\"Expected idx_corrupt shape (1,T). Got {tuple(idx_corrupt.shape)}\")\n",
        "\n",
        "    device = _infer_device(model)\n",
        "    idx_corrupt = idx_corrupt.to(device)\n",
        "\n",
        "    n_layers = len(model.transformer.h)\n",
        "    T = int(idx_corrupt.shape[1])\n",
        "\n",
        "    layers = list(range(n_layers)) if layers is None else list(layers)\n",
        "    positions = list(range(T)) if positions is None else list(positions)\n",
        "\n",
        "    it = [(L, P) for L in layers for P in positions]\n",
        "    if progress:\n",
        "        try:\n",
        "            from tqdm import tqdm  \n",
        "            it = tqdm(it, desc=f\"sweep({patch_location})\", total=len(it))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    mat = torch.empty((len(layers), len(positions)), dtype=torch.float32, device=\"cpu\")\n",
        "    layer_index = {L: i for i, L in enumerate(layers)}\n",
        "    pos_index = {P: j for j, P in enumerate(positions)}\n",
        "\n",
        "    for L, P in it:\n",
        "        _logits, _loss = model(\n",
        "            idx_corrupt,\n",
        "            layer_to_patch=int(L),\n",
        "            position_to_patch=int(P),\n",
        "            patch_location=patch_location,\n",
        "        )\n",
        "        if model.last_logits is None:\n",
        "            raise RuntimeError(\"model.last_logits was not set. Ensure forward() stores last_logits.\")\n",
        "        last = model.last_logits[0].detach()\n",
        "        score = logit_diff_from_last_logits(last, token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "        mat[layer_index[L], pos_index[P]] = float(score)\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run_extra3(\n",
        "    model,\n",
        "    bpe,\n",
        "    *,\n",
        "    clean_text: str,\n",
        "    corrupt_text: str,\n",
        "    token_a_str: str,\n",
        "    token_b_str: str,\n",
        "    overwrite_cache: bool = True,\n",
        "    progress: bool = True,\n",
        ") -> Extra3Result:\n",
        "    device = _infer_device(model)\n",
        "\n",
        "    idx_clean = bpe(clean_text).to(device)\n",
        "    idx_corr = bpe(corrupt_text).to(device)\n",
        "\n",
        "    if idx_clean.shape != idx_corr.shape:\n",
        "        raise ValueError(\n",
        "            f\"Clean/Corrupt token length mismatch: clean={tuple(idx_clean.shape)}, corrupt={tuple(idx_corr.shape)}. \"\n",
        "            \"They MUST have the same number of BPE tokens.\"\n",
        "        )\n",
        "\n",
        "    T = int(idx_clean.shape[1])\n",
        "    n_layers = len(model.transformer.h)\n",
        "\n",
        "    token_a_id = single_token_id(bpe, token_a_str)\n",
        "    token_b_id = single_token_id(bpe, token_b_str)\n",
        "\n",
        "    # 1) clean run: cache BOTH post_attn and post_mlp\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=overwrite_cache)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits missing after clean run.\")\n",
        "    clean_score = logit_diff_from_last_logits(model.last_logits[0], token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "\n",
        "    # 2) corrupted baseline\n",
        "    _ = model(idx_corr)\n",
        "    if model.last_logits is None:\n",
        "        raise RuntimeError(\"model.last_logits missing after corrupt run.\")\n",
        "    corrupt_score = logit_diff_from_last_logits(model.last_logits[0], token_a_id=token_a_id, token_b_id=token_b_id)\n",
        "\n",
        "    # 3) sweeps\n",
        "    post_attn = sweep_location_from_ids(\n",
        "        model,\n",
        "        idx_corr,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        patch_location=\"post_attn\",\n",
        "        progress=progress,\n",
        "    )\n",
        "    post_mlp = sweep_location_from_ids(\n",
        "        model,\n",
        "        idx_corr,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        patch_location=\"post_mlp\",\n",
        "        progress=progress,\n",
        "    )\n",
        "\n",
        "    return Extra3Result(\n",
        "        post_attn_matrix=post_attn,\n",
        "        post_mlp_matrix=post_mlp,\n",
        "        n_layers=n_layers,\n",
        "        seq_len=T,\n",
        "        clean_score=float(clean_score),\n",
        "        corrupt_score=float(corrupt_score),\n",
        "        token_a_str=token_a_str,\n",
        "        token_b_str=token_b_str,\n",
        "        token_a_id=token_a_id,\n",
        "        token_b_id=token_b_id,\n",
        "        clean_text=clean_text,\n",
        "        corrupt_text=corrupt_text,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing extra3_intrablock_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra3_intrablock_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "import tokenization_protocol as tp\n",
        "\n",
        "from extra3_intrablock_sweep import run_extra3\n",
        "from section10_visualization import (\n",
        "    HeatmapMeta,\n",
        "    decode_prompt_token_labels,\n",
        "    plot_logit_diff_heatmap,\n",
        "    save_figure_publication_quality,\n",
        "    save_heatmap_artifacts,\n",
        ")\n",
        "\n",
        "\n",
        "def get_device() -> str:\n",
        "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    set_seed(3407)\n",
        "    device = get_device()\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    CLEAN_TEXT = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "    CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "    TOKEN_A = \" Jones\"  # clean-consistent\n",
        "    TOKEN_B = \" Smith\"  # corrupt-consistent\n",
        "\n",
        "    # Load model + tokenizer\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    # Validate token constraints (recommended)\n",
        "    comp = tp.validate_pair(\n",
        "        bpe=bpe,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        require_same_length=True,\n",
        "        require_one_token_diff=True,\n",
        "    )\n",
        "    print(tp.describe_pair(comp))\n",
        "    print(\"Changed token position:\", comp.diff_positions[0])\n",
        "\n",
        "    # Run EXTRA 3\n",
        "    res = run_extra3(\n",
        "        model,\n",
        "        bpe,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        overwrite_cache=True,\n",
        "        progress=True,\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"clean score   = {res.clean_score:.4f}\")\n",
        "    print(f\"corrupt score = {res.corrupt_score:.4f}\")\n",
        "    print(f\"delta (corrupt-clean) = {res.corrupt_score - res.clean_score:.4f}\")\n",
        "\n",
        "    out_dir = Path(\"artifacts/extra3_intrablock\")\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    token_labels = decode_prompt_token_labels(bpe, CLEAN_TEXT)\n",
        "\n",
        "    # Save raw matrices for reproducibility\n",
        "    torch.save(\n",
        "        {\n",
        "            \"post_attn\": res.post_attn_matrix,\n",
        "            \"post_mlp\": res.post_mlp_matrix,\n",
        "            \"clean_score\": res.clean_score,\n",
        "            \"corrupt_score\": res.corrupt_score,\n",
        "            \"token_a\": res.token_a_str,\n",
        "            \"token_b\": res.token_b_str,\n",
        "            \"clean_text\": res.clean_text,\n",
        "            \"corrupt_text\": res.corrupt_text,\n",
        "            \"seq_len\": res.seq_len,\n",
        "            \"n_layers\": res.n_layers,\n",
        "        },\n",
        "        out_dir / \"extra3_matrices.pt\",\n",
        "    )\n",
        "    print(\"Saved:\", (out_dir / \"extra3_matrices.pt\").resolve())\n",
        "\n",
        "    title_attn = f\"EXTRA 3  post-attn patching: logit({repr(TOKEN_B)})  logit({repr(TOKEN_A)})\"\n",
        "    meta_attn = HeatmapMeta(\n",
        "        metric_title=title_attn,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        n_layers=res.n_layers,\n",
        "        seq_len=res.seq_len,\n",
        "        token_labels=token_labels,\n",
        "    )\n",
        "    save_heatmap_artifacts(out_dir=out_dir / \"post_attn\", matrix=res.post_attn_matrix, meta=meta_attn)\n",
        "    fig, _ = plot_logit_diff_heatmap(\n",
        "        res.post_attn_matrix,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=title_attn,\n",
        "        show_token_strings=True,\n",
        "        center_zero=True,\n",
        "        include_pos_in_label=True,\n",
        "    )\n",
        "    save_figure_publication_quality(fig, out_basepath=out_dir / \"post_attn\" / \"heatmap_post_attn\", formats=(\"png\", \"pdf\"))\n",
        "\n",
        "    title_mlp = f\"EXTRA 3  post-MLP patching: logit({repr(TOKEN_B)})  logit({repr(TOKEN_A)})\"\n",
        "    meta_mlp = HeatmapMeta(\n",
        "        metric_title=title_mlp,\n",
        "        clean_text=CLEAN_TEXT,\n",
        "        corrupt_text=CORRUPT_TEXT,\n",
        "        token_a_str=TOKEN_A,\n",
        "        token_b_str=TOKEN_B,\n",
        "        n_layers=res.n_layers,\n",
        "        seq_len=res.seq_len,\n",
        "        token_labels=token_labels,\n",
        "    )\n",
        "    save_heatmap_artifacts(out_dir=out_dir / \"post_mlp\", matrix=res.post_mlp_matrix, meta=meta_mlp)\n",
        "    fig, _ = plot_logit_diff_heatmap(\n",
        "        res.post_mlp_matrix,\n",
        "        token_labels=token_labels,\n",
        "        metric_title=title_mlp,\n",
        "        show_token_strings=True,\n",
        "        center_zero=True,\n",
        "        include_pos_in_label=True,\n",
        "    )\n",
        "    save_figure_publication_quality(fig, out_basepath=out_dir / \"post_mlp\" / \"heatmap_post_mlp\", formats=(\"png\", \"pdf\"))\n",
        "\n",
        "    print(\"\\n Done. Heatmaps saved under:\", out_dir.resolve())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_extra3_intrablock.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_extra3_intrablock.py\n",
        "import pytest\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "\n",
        "def make_tiny_model():\n",
        "    set_seed(123)\n",
        "    cfg = GPT.get_default_config()\n",
        "    cfg.model_type = \"gpt-nano\"   # tiny, no downloads\n",
        "    cfg.vocab_size = 101\n",
        "    cfg.block_size = 32\n",
        "    m = GPT(cfg).eval()\n",
        "    return m\n",
        "\n",
        "\n",
        "def make_pair(vocab_size: int, T: int = 12, changed_pos: int = 3):\n",
        "    set_seed(999)\n",
        "    clean = torch.randint(0, vocab_size, (1, T), dtype=torch.long)\n",
        "    corrupt = clean.clone()\n",
        "    corrupt[0, changed_pos] = (corrupt[0, changed_pos] + 1) % vocab_size\n",
        "    return clean, corrupt, changed_pos\n",
        "\n",
        "\n",
        "def test_caches_exist_for_both_locations_after_clean_cache():\n",
        "    m = make_tiny_model()\n",
        "    vocab = m.transformer.wte.num_embeddings\n",
        "    clean, _, _ = make_pair(vocab)\n",
        "\n",
        "    _ = m(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    assert m.clean_post_attn_activations is not None\n",
        "    assert m.clean_post_mlp_activations is not None\n",
        "    assert m.clean_activations is not None  # backward compatibility (post-MLP)\n",
        "\n",
        "    n_layers = len(m.transformer.h)\n",
        "    T = clean.shape[1]\n",
        "    assert len(m.clean_post_attn_activations) == n_layers\n",
        "    assert len(m.clean_post_attn_activations[0]) == T\n",
        "    assert len(m.clean_post_mlp_activations) == n_layers\n",
        "    assert len(m.clean_post_mlp_activations[0]) == T\n",
        "\n",
        "    # clean_activations should match post-MLP cache\n",
        "    assert torch.allclose(m.clean_activations[0][0], m.clean_post_mlp_activations[0][0])\n",
        "\n",
        "\n",
        "def test_patch_post_attn_changes_logits():\n",
        "    m = make_tiny_model()\n",
        "    vocab = m.transformer.wte.num_embeddings\n",
        "    clean, corrupt, p = make_pair(vocab)\n",
        "\n",
        "    _ = m(clean, cache_activations=True, overwrite_cache=True)\n",
        "    _ = m(corrupt)\n",
        "    base = m.last_logits.clone()\n",
        "\n",
        "    _ = m(corrupt, layer_to_patch=0, position_to_patch=p, patch_location=\"post_attn\")\n",
        "    assert m.last_patch_location == \"post_attn\"\n",
        "    assert m.last_patch == (0, p)\n",
        "    assert not torch.allclose(base, m.last_logits)\n",
        "\n",
        "\n",
        "def test_patch_post_mlp_changes_logits():\n",
        "    m = make_tiny_model()\n",
        "    vocab = m.transformer.wte.num_embeddings\n",
        "    clean, corrupt, p = make_pair(vocab)\n",
        "\n",
        "    _ = m(clean, cache_activations=True, overwrite_cache=True)\n",
        "    _ = m(corrupt)\n",
        "    base = m.last_logits.clone()\n",
        "\n",
        "    _ = m(corrupt, layer_to_patch=0, position_to_patch=p, patch_location=\"post_mlp\")\n",
        "    assert m.last_patch_location == \"post_mlp\"\n",
        "    assert m.last_patch == (0, p)\n",
        "    assert not torch.allclose(base, m.last_logits)\n",
        "\n",
        "\n",
        "def test_post_attn_and_post_mlp_patches_produce_different_outputs_typically():\n",
        "    m = make_tiny_model()\n",
        "    vocab = m.transformer.wte.num_embeddings\n",
        "    clean, corrupt, p = make_pair(vocab)\n",
        "\n",
        "    _ = m(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    _ = m(corrupt, layer_to_patch=1, position_to_patch=p, patch_location=\"post_attn\")\n",
        "    out_attn = m.last_logits.clone()\n",
        "\n",
        "    _ = m(corrupt, layer_to_patch=1, position_to_patch=p, patch_location=\"post_mlp\")\n",
        "    out_mlp = m.last_logits.clone()\n",
        "\n",
        "    # In a random network these should differ (very high probability).\n",
        "    assert not torch.allclose(out_attn, out_mlp)\n",
        "\n",
        "\n",
        "def test_invalid_patch_location_raises():\n",
        "    m = make_tiny_model()\n",
        "    vocab = m.transformer.wte.num_embeddings\n",
        "    clean, corrupt, p = make_pair(vocab)\n",
        "\n",
        "    _ = m(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with pytest.raises(ValueError):\n",
        "        _ = m(corrupt, layer_to_patch=0, position_to_patch=p, patch_location=\"after_unicorns\")\n",
        "\n",
        "\n",
        "def test_patch_and_cache_activations_is_forbidden():\n",
        "    m = make_tiny_model()\n",
        "    vocab = m.transformer.wte.num_embeddings\n",
        "    clean, corrupt, p = make_pair(vocab)\n",
        "\n",
        "    _ = m(clean, cache_activations=True, overwrite_cache=True)\n",
        "\n",
        "    with pytest.raises(RuntimeError):\n",
        "        _ = m(\n",
        "            corrupt,\n",
        "            layer_to_patch=0,\n",
        "            position_to_patch=p,\n",
        "            patch_location=\"post_mlp\",\n",
        "            cache_activations=True,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 69%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                          [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m103 passed\u001b[0m\u001b[32m in 44.80s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q test_extra3_intrablock.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EXTRA SECTION 3 RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting extra3_intrablock_check.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra3_intrablock_check.py\n",
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "TOKEN_A = \" Jones\"  \n",
        "TOKEN_B = \" Smith\"  \n",
        "\n",
        "def single_token_id(bpe: BPETokenizer, s: str) -> int:\n",
        "    ids = bpe(s)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(f\"{s!r} is not a single BPE token. Got ids={ids}\")\n",
        "    return int(ids[0])\n",
        "\n",
        "def score_from_last_logits(last_logits_1d: torch.Tensor, *, a_id: int, b_id: int) -> float:\n",
        "    return float(last_logits_1d[b_id] - last_logits_1d[a_id])\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    idx_clean = bpe(CLEAN_TEXT).to(device)\n",
        "    idx_corr  = bpe(CORRUPT_TEXT).to(device)\n",
        "\n",
        "    if idx_clean.shape != idx_corr.shape:\n",
        "        raise RuntimeError(f\"Token length mismatch: clean={idx_clean.shape}, corrupt={idx_corr.shape}\")\n",
        "\n",
        "    T = idx_clean.shape[1]\n",
        "    n_layers = len(model.transformer.h)\n",
        "    print(f\"Seq len T={T}, n_layers={n_layers}\")\n",
        "\n",
        "    a_id = single_token_id(bpe, TOKEN_A)\n",
        "    b_id = single_token_id(bpe, TOKEN_B)\n",
        "\n",
        "    # CLEAN run (this must create BOTH intra-block caches)\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=True)\n",
        "    print(\"Clean caches present?\",\n",
        "          \"post_attn:\", model.clean_post_attn_activations is not None,\n",
        "          \"| post_mlp:\", model.clean_post_mlp_activations is not None)\n",
        "\n",
        "    # Show cache dimensions (must be 12 x T for GPT-2 small)\n",
        "    print(\"clean_post_attn dims:\", len(model.clean_post_attn_activations), \"x\", len(model.clean_post_attn_activations[0]))\n",
        "    print(\"clean_post_mlp  dims:\", len(model.clean_post_mlp_activations),  \"x\", len(model.clean_post_mlp_activations[0]))\n",
        "\n",
        "    score_clean = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "\n",
        "    # CORR baseline (no patch)\n",
        "    _ = model(idx_corr)\n",
        "    score_corr = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"score_clean = {score_clean:.4f}\")\n",
        "    print(f\"score_corr  = {score_corr:.4f}\")\n",
        "    print(\"Expected (for this pair): score_clean < score_corr (often clean is negative, corrupt is positive).\")\n",
        "\n",
        "    # Choose a meaningful target: the changed-token position is usually 1 for this classic prompt,\n",
        "    # but well just test a couple positions safely.\n",
        "    test_L = 6\n",
        "    test_P = 1 if T > 1 else 0\n",
        "\n",
        "    # Patch at post-attn\n",
        "    _ = model(idx_corr,\n",
        "              layer_to_patch=test_L,\n",
        "              position_to_patch=test_P,\n",
        "              patch_location=\"post_attn\")\n",
        "    s_attn = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "    print(\"\\n=== Patch test (post_attn) ===\")\n",
        "    print(\"last_patch:\", model.last_patch, \"last_patch_location:\", model.last_patch_location)\n",
        "    print(f\"score_post_attn = {s_attn:.4f}  | delta_vs_corr = {s_attn - score_corr:+.4f}\")\n",
        "\n",
        "    # Patch at post-MLP\n",
        "    _ = model(idx_corr,\n",
        "              layer_to_patch=test_L,\n",
        "              position_to_patch=test_P,\n",
        "              patch_location=\"post_mlp\")\n",
        "    s_mlp = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "    print(\"\\n=== Patch test (post_mlp) ===\")\n",
        "    print(\"last_patch:\", model.last_patch, \"last_patch_location:\", model.last_patch_location)\n",
        "    print(f\"score_post_mlp  = {s_mlp:.4f}  | delta_vs_corr = {s_mlp - score_corr:+.4f}\")\n",
        "\n",
        "    # The key EXTRA 3 assertion: the two locations should not be identical everywhere.\n",
        "    print(\"\\n=== Intra-block location difference (single cell) ===\")\n",
        "    print(f\"abs(score_post_attn - score_post_mlp) = {abs(s_attn - s_mlp):.6f}\")\n",
        "    print(\"If this is exactly 0.0 for many tested cells, your patch_location may not be applied correctly.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "Seq len T=11, n_layers=12\n",
            "Clean caches present? post_attn: True | post_mlp: True\n",
            "clean_post_attn dims: 12 x 11\n",
            "clean_post_mlp  dims: 12 x 11\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean = -4.1241\n",
            "score_corr  = 5.6562\n",
            "Expected (for this pair): score_clean < score_corr (often clean is negative, corrupt is positive).\n",
            "\n",
            "=== Patch test (post_attn) ===\n",
            "last_patch: (6, 1) last_patch_location: post_attn\n",
            "score_post_attn = 5.6416  | delta_vs_corr = -0.0146\n",
            "\n",
            "=== Patch test (post_mlp) ===\n",
            "last_patch: (6, 1) last_patch_location: post_mlp\n",
            "score_post_mlp  = -3.1509  | delta_vs_corr = -8.8071\n",
            "\n",
            "=== Intra-block location difference (single cell) ===\n",
            "abs(score_post_attn - score_post_mlp) = 8.792526\n",
            "If this is exactly 0.0 for many tested cells, your patch_location may not be applied correctly.\n"
          ]
        }
      ],
      "source": [
        "!python extra3_intrablock_check.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting extra3_intrablock_sweep_driver.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra3_intrablock_sweep_driver.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "from mingpt.utils import set_seed\n",
        "\n",
        "# Reuse your plotting utilities (already in your project)\n",
        "from section10_visualization import (\n",
        "    decode_prompt_token_labels,\n",
        "    plot_logit_diff_heatmap,\n",
        "    save_figure_publication_quality,\n",
        ")\n",
        "\n",
        "CLEAN_TEXT   = \"Michelle Jones was a top-notch student. Michelle\"\n",
        "CORRUPT_TEXT = \"Michelle Smith was a top-notch student. Michelle\"\n",
        "TOKEN_A = \" Jones\"\n",
        "TOKEN_B = \" Smith\"\n",
        "\n",
        "def single_token_id(bpe: BPETokenizer, s: str) -> int:\n",
        "    ids = bpe(s)[0].tolist()\n",
        "    if len(ids) != 1:\n",
        "        raise ValueError(f\"{s!r} is not a single BPE token. Got ids={ids}\")\n",
        "    return int(ids[0])\n",
        "\n",
        "def score_from_last_logits(last_logits_1d: torch.Tensor, *, a_id: int, b_id: int) -> float:\n",
        "    return float(last_logits_1d[b_id] - last_logits_1d[a_id])\n",
        "\n",
        "@torch.no_grad()\n",
        "def main() -> None:\n",
        "    set_seed(3407)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    model = GPT.from_pretrained(\"gpt2\").to(device).eval()\n",
        "    bpe = BPETokenizer()\n",
        "\n",
        "    idx_clean = bpe(CLEAN_TEXT).to(device)\n",
        "    idx_corr  = bpe(CORRUPT_TEXT).to(device)\n",
        "    if idx_clean.shape != idx_corr.shape:\n",
        "        raise RuntimeError(f\"Token length mismatch: clean={idx_clean.shape}, corrupt={idx_corr.shape}\")\n",
        "\n",
        "    T = int(idx_clean.shape[1])\n",
        "    n_layers = len(model.transformer.h)\n",
        "    print(f\"Seq len T={T}, n_layers={n_layers}\")\n",
        "\n",
        "    a_id = single_token_id(bpe, TOKEN_A)\n",
        "    b_id = single_token_id(bpe, TOKEN_B)\n",
        "\n",
        "    # Clean cache (must populate both intra-block banks)\n",
        "    _ = model(idx_clean, cache_activations=True, overwrite_cache=True)\n",
        "    score_clean = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "\n",
        "    # Corrupt baseline\n",
        "    _ = model(idx_corr)\n",
        "    score_corr = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "\n",
        "    print(\"\\n=== Baselines ===\")\n",
        "    print(f\"score_clean = {score_clean:.4f}\")\n",
        "    print(f\"score_corr  = {score_corr:.4f}\")\n",
        "\n",
        "    out_dir = Path(\"artifacts/extra3_intrablock\")\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    token_labels = decode_prompt_token_labels(bpe, CLEAN_TEXT)\n",
        "\n",
        "    mats = {}\n",
        "    for loc in [\"post_attn\", \"post_mlp\"]:\n",
        "        print(f\"\\nSweeping patches at location: {loc}\")\n",
        "        mat = torch.empty((n_layers, T), dtype=torch.float32)\n",
        "\n",
        "        for L in range(n_layers):\n",
        "            for P in range(T):\n",
        "                _ = model(idx_corr,\n",
        "                          layer_to_patch=L,\n",
        "                          position_to_patch=P,\n",
        "                          patch_location=loc)\n",
        "                s = score_from_last_logits(model.last_logits[0], a_id=a_id, b_id=b_id)\n",
        "                mat[L, P] = float(s)\n",
        "\n",
        "        mats[loc] = mat.cpu()\n",
        "        torch.save(mat.cpu(), out_dir / f\"matrix_{loc}.pt\")\n",
        "        print(\"Saved:\", (out_dir / f\"matrix_{loc}.pt\").resolve())\n",
        "\n",
        "        title = f\"EXTRA 3  {loc}: logit({TOKEN_B!r})  logit({TOKEN_A!r})\"\n",
        "        fig, ax = plot_logit_diff_heatmap(\n",
        "            mat,\n",
        "            token_labels=token_labels,\n",
        "            metric_title=title,\n",
        "            show_token_strings=True,\n",
        "            center_zero=True,\n",
        "            include_pos_in_label=True,\n",
        "        )\n",
        "        save_figure_publication_quality(fig, out_basepath=out_dir / f\"heatmap_{loc}\", formats=(\"png\", \"pdf\"), dpi=300)\n",
        "        print(\"Saved heatmap figures for:\", loc)\n",
        "\n",
        "    # Key check: matrices should not be identical\n",
        "    diff = (mats[\"post_attn\"] - mats[\"post_mlp\"]).abs()\n",
        "    print(\"\\n=== EXTRA 3 matrix difference stats ===\")\n",
        "    print(\"max |post_attn - post_mlp| =\", float(diff.max()))\n",
        "    print(\"mean|post_attn - post_mlp| =\", float(diff.mean()))\n",
        "    print(\"If max is exactly 0.0, your intra-block split is not taking effect.\")\n",
        "\n",
        "    # Optional: show restoration deltas relative to corrupted baseline\n",
        "    # (patched - corrupt): negative means moving toward clean if clean < corrupt for your pair.\n",
        "    delta_attn = mats[\"post_attn\"] - float(score_corr)\n",
        "    delta_mlp  = mats[\"post_mlp\"]  - float(score_corr)\n",
        "    print(\"\\nDelta sanity (patched - corrupt):\")\n",
        "    print(\"post_attn: min=\", float(delta_attn.min()), \"max=\", float(delta_attn.max()))\n",
        "    print(\"post_mlp : min=\", float(delta_mlp.min()),  \"max=\", float(delta_mlp.max()))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "number of parameters: 124.44M\n",
            "Seq len T=11, n_layers=12\n",
            "\n",
            "=== Baselines ===\n",
            "score_clean = -4.1241\n",
            "score_corr  = 5.6562\n",
            "\n",
            "Sweeping patches at location: post_attn\n",
            "Saved: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/matrix_post_attn.pt\n",
            "Saved heatmap figures for: post_attn\n",
            "\n",
            "Sweeping patches at location: post_mlp\n",
            "Saved: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/matrix_post_mlp.pt\n",
            "Saved heatmap figures for: post_mlp\n",
            "\n",
            "=== EXTRA 3 matrix difference stats ===\n",
            "max |post_attn - post_mlp| = 9.767166137695312\n",
            "mean|post_attn - post_mlp| = 0.8032954335212708\n",
            "If max is exactly 0.0, your intra-block split is not taking effect.\n",
            "\n",
            "Delta sanity (patched - corrupt):\n",
            "post_attn: min= -3.4107208251953125 max= 0.04366302490234375\n",
            "post_mlp : min= -9.780319213867188 max= 0.0342254638671875\n"
          ]
        }
      ],
      "source": [
        "!python extra3_intrablock_sweep_driver.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 69%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                          [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m103 passed\u001b[0m\u001b[32m in 49.46s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing extra3_intrablock_heatmap.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile extra3_intrablock_heatmap.py\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Optional, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")  \n",
        "import matplotlib.pyplot as plt  \n",
        "from matplotlib.colors import TwoSlopeNorm  \n",
        "\n",
        "import torch  \n",
        "\n",
        "\n",
        "def _to_numpy(x: Any) -> np.ndarray:\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return x\n",
        "    if torch.is_tensor(x):\n",
        "        return x.detach().cpu().float().numpy()\n",
        "    return np.asarray(x, dtype=np.float32)\n",
        "\n",
        "\n",
        "def _extract_matrix_and_labels(obj: Any) -> Tuple[np.ndarray, Optional[List[str]], Optional[List[str]]]:\n",
        "    xlabels = None\n",
        "    ylabels = None\n",
        "\n",
        "    if torch.is_tensor(obj):\n",
        "        return _to_numpy(obj), None, None\n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "        candidates = [\"matrix\", \"values\", \"scores\", \"heatmap\", \"data\", \"arr\"]\n",
        "        mat = None\n",
        "        for k in candidates:\n",
        "            if k in obj and (torch.is_tensor(obj[k]) or isinstance(obj[k], (list, tuple, np.ndarray))):\n",
        "                mat = obj[k]\n",
        "                break\n",
        "\n",
        "        if mat is None:\n",
        "            for v in obj.values():\n",
        "                if torch.is_tensor(v) or isinstance(v, (list, tuple, np.ndarray)):\n",
        "                    arr = _to_numpy(v)\n",
        "                    if arr.ndim >= 2:\n",
        "                        mat = v\n",
        "                        break\n",
        "\n",
        "        if mat is None:\n",
        "            raise ValueError(\"No pude encontrar una matriz 2D dentro del .pt (dict).\")\n",
        "\n",
        "        M = _to_numpy(mat)\n",
        "\n",
        "        for tk in [\"tokens\", \"token_strs\", \"token_labels\", \"xlabels\"]:\n",
        "            if tk in obj and isinstance(obj[tk], (list, tuple)) and all(isinstance(t, str) for t in obj[tk]):\n",
        "                xlabels = list(obj[tk])\n",
        "                break\n",
        "\n",
        "        for lk in [\"layers\", \"layer_labels\", \"ylabels\"]:\n",
        "            if lk in obj and isinstance(obj[lk], (list, tuple)):\n",
        "                if all(isinstance(t, str) for t in obj[lk]):\n",
        "                    ylabels = list(obj[lk])\n",
        "                elif all(isinstance(t, (int, np.integer)) for t in obj[lk]):\n",
        "                    ylabels = [f\"L{int(t)}\" for t in obj[lk]]\n",
        "                break\n",
        "\n",
        "        return M, xlabels, ylabels\n",
        "\n",
        "    M = _to_numpy(obj)\n",
        "    if M.ndim < 2:\n",
        "        raise ValueError(f\"The loaded object does not seem to be a 2D matrix. ndim={M.ndim}\")\n",
        "    return M, None, None\n",
        "\n",
        "\n",
        "def _symmetric_norm(M: np.ndarray, *, eps: float = 1e-12) -> Optional[TwoSlopeNorm]:\n",
        "    mmin = float(np.nanmin(M))\n",
        "    mmax = float(np.nanmax(M))\n",
        "    v = max(abs(mmin), abs(mmax))\n",
        "    if not np.isfinite(v) or v < eps:\n",
        "        return None\n",
        "    return TwoSlopeNorm(vmin=-v, vcenter=0.0, vmax=+v)\n",
        "\n",
        "\n",
        "def plot_heatmap(\n",
        "    M: np.ndarray,\n",
        "    *,\n",
        "    title: str,\n",
        "    out_path: Path,\n",
        "    xlabel: str = \"Token position\",\n",
        "    ylabel: str = \"Layer\",\n",
        "    xlabels: Optional[List[str]] = None,\n",
        "    ylabels: Optional[List[str]] = None,\n",
        "    cbar_label: str = \"Value\",\n",
        ") -> None:\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if M.ndim > 2:\n",
        "        M = np.squeeze(M)\n",
        "    if M.ndim != 2:\n",
        "        raise ValueError(f\"I was waiting for 2D, I got shape={M.shape}\")\n",
        "\n",
        "    norm = _symmetric_norm(M)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    ax = plt.gca()\n",
        "\n",
        "    im = ax.imshow(M, aspect=\"auto\", interpolation=\"nearest\", norm=norm)\n",
        "    ax.set_title(title)\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "\n",
        "    n_layers, T = M.shape[0], M.shape[1]\n",
        "\n",
        "    if ylabels is not None and len(ylabels) == n_layers:\n",
        "        ax.set_yticks(np.arange(n_layers))\n",
        "        ax.set_yticklabels(ylabels)\n",
        "    else:\n",
        "        step = 1 if n_layers <= 16 else max(1, n_layers // 12)\n",
        "        yt = np.arange(0, n_layers, step)\n",
        "        ax.set_yticks(yt)\n",
        "        ax.set_yticklabels([str(int(i)) for i in yt])\n",
        "\n",
        "    if xlabels is not None and len(xlabels) == T:\n",
        "        step = 1 if T <= 16 else max(1, T // 12)\n",
        "        xt = np.arange(0, T, step)\n",
        "        ax.set_xticks(xt)\n",
        "        ax.set_xticklabels([xlabels[int(i)] for i in xt], rotation=45, ha=\"right\")\n",
        "    else:\n",
        "        step = 1 if T <= 16 else max(1, T // 12)\n",
        "        xt = np.arange(0, T, step)\n",
        "        ax.set_xticks(xt)\n",
        "        ax.set_xticklabels([str(int(i)) for i in xt])\n",
        "\n",
        "    cbar = plt.colorbar(im, ax=ax)\n",
        "    cbar.set_label(cbar_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(out_path, dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def main() -> int:\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\n",
        "        \"--artifact_dir\",\n",
        "        type=str,\n",
        "        default=\"artifacts/extra3_intrablock\",\n",
        "        help=\"Folder that contain matrix_post_attn.pt and matrix_post_mlp.pt\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--post_attn\",\n",
        "        type=str,\n",
        "        default=\"matrix_post_attn.pt\",\n",
        "        help=\"Name of the .pt for post_attn (inside artifact_dir)\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--post_mlp\",\n",
        "        type=str,\n",
        "        default=\"matrix_post_mlp.pt\",\n",
        "        help=\"Name of the .pt para post_mlp (inside artifact_dir)\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--out_dir\",\n",
        "        type=str,\n",
        "        default=\"artifacts/extra3_intrablock/heatmaps\",\n",
        "        help=\"Salida para los PNG\",\n",
        "    )\n",
        "    ap.add_argument(\n",
        "        \"--value_name\",\n",
        "        type=str,\n",
        "        default=\"Logit-diff score (or effect)\",\n",
        "        help=\"Label of the colorbar.\",\n",
        "    )\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    artifact_dir = Path(args.artifact_dir).expanduser().resolve()\n",
        "    out_dir = Path(args.out_dir).expanduser().resolve()\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    p_attn = artifact_dir / args.post_attn\n",
        "    p_mlp = artifact_dir / args.post_mlp\n",
        "\n",
        "    if not p_attn.exists():\n",
        "        raise FileNotFoundError(f\"It does not exist: {p_attn}\")\n",
        "    if not p_mlp.exists():\n",
        "        raise FileNotFoundError(f\"It does not exist: {p_mlp}\")\n",
        "\n",
        "    obj_attn = torch.load(str(p_attn), map_location=\"cpu\")\n",
        "    obj_mlp = torch.load(str(p_mlp), map_location=\"cpu\")\n",
        "\n",
        "    M_attn, xlabels_a, ylabels_a = _extract_matrix_and_labels(obj_attn)\n",
        "    M_mlp,  xlabels_m, ylabels_m = _extract_matrix_and_labels(obj_mlp)\n",
        "\n",
        "    xlabels = xlabels_a or xlabels_m\n",
        "    ylabels = ylabels_a or ylabels_m\n",
        "\n",
        "    if M_attn.shape != M_mlp.shape:\n",
        "        raise ValueError(f\"Shape mismatch: post_attn {M_attn.shape} vs post_mlp {M_mlp.shape}\")\n",
        "\n",
        "    M_delta = M_mlp - M_attn\n",
        "\n",
        "    plot_heatmap(\n",
        "        M_attn,\n",
        "        title=\"EXTRA 3  Patch location: post_attn\",\n",
        "        out_path=out_dir / \"extra3_post_attn_heatmap.png\",\n",
        "        xlabels=xlabels,\n",
        "        ylabels=ylabels,\n",
        "        cbar_label=args.value_name,\n",
        "    )\n",
        "\n",
        "    plot_heatmap(\n",
        "        M_mlp,\n",
        "        title=\"EXTRA 3  Patch location: post_mlp\",\n",
        "        out_path=out_dir / \"extra3_post_mlp_heatmap.png\",\n",
        "        xlabels=xlabels,\n",
        "        ylabels=ylabels,\n",
        "        cbar_label=args.value_name,\n",
        "    )\n",
        "\n",
        "    plot_heatmap(\n",
        "        M_delta,\n",
        "        title=\"EXTRA 3  Delta: (post_mlp - post_attn)\",\n",
        "        out_path=out_dir / \"extra3_post_mlp_minus_post_attn_heatmap.png\",\n",
        "        xlabels=xlabels,\n",
        "        ylabels=ylabels,\n",
        "        cbar_label=f\"({args.value_name})\",\n",
        "    )\n",
        "\n",
        "    print(f\" Saved heatmaps to: {out_dir}\")\n",
        "    print(f\" - {out_dir / 'extra3_post_attn_heatmap.png'}\")\n",
        "    print(f\" - {out_dir / 'extra3_post_mlp_heatmap.png'}\")\n",
        "    print(f\" - {out_dir / 'extra3_post_mlp_heatmap.png'}\")\n",
        "    print(f\" - {out_dir / 'extra3_post_mlp_minus_post_attn_heatmap.png'}\")\n",
        "    return 0\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    raise SystemExit(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved heatmaps to: /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/heatmaps\n",
            " - /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/heatmaps/extra3_post_attn_heatmap.png\n",
            " - /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/heatmaps/extra3_post_mlp_heatmap.png\n",
            " - /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/heatmaps/extra3_post_mlp_heatmap.png\n",
            " - /home/bledyx/UA/master-ia/TPLN/code/lvl1/lvl2/tpln-practice2/artifacts/extra3_intrablock/heatmaps/extra3_post_mlp_minus_post_attn_heatmap.png\n"
          ]
        }
      ],
      "source": [
        "!python extra3_intrablock_heatmap.py \\\n",
        "  --artifact_dir artifacts/extra3_intrablock \\\n",
        "  --out_dir artifacts/extra3_intrablock/heatmaps \\\n",
        "  --value_name \"logit(Smith) - logit(Jones)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m [ 69%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                          [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m103 passed\u001b[0m\u001b[32m in 49.46s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pytest -q"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "048b2b328d174740a7f4eb64fd2f8b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c789b9007024556915b3f9e3cabe35e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1209e810b3fc41808b444108a87afca1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ca502911134178a532cda1cf139ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ea57fda15f42d18d60048c165cb019": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0449079fc7a48a3a941c34c7cf2fdc9",
            "placeholder": "",
            "style": "IPY_MODEL_9a67d3d3a8744fd881b8a2d5359e78ab",
            "value": "model.safetensors: 100%"
          }
        },
        "260906d3854c4ff78c2cda042bae0a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048b2b328d174740a7f4eb64fd2f8b7f",
            "placeholder": "",
            "style": "IPY_MODEL_c033d8e19c084b90bd8a88a3e5bdb5b8",
            "value": " 124/124 [00:00&lt;00:00, 3.38kB/s]"
          }
        },
        "37af4bb362b94e87b7c128e6966534f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba0334c76344e0a824177d3572e6dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ca502911134178a532cda1cf139ca4",
            "placeholder": "",
            "style": "IPY_MODEL_ca37e879895f4707bb2e39d9229c65dd",
            "value": "generation_config.json: 100%"
          }
        },
        "3ce2905b2f8e41adbc9eb724aeb2f62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44854839f29f4de08577daf5c4db4c63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f6eb03404a425aabda1a87b86afe15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cbfa6b49da84ee781492abacea18884": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eec0e26428c4034867633d70b4b3915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "648a553be0bf49cba777f0eaaac741b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c789b9007024556915b3f9e3cabe35e",
            "placeholder": "",
            "style": "IPY_MODEL_f6620c81dc4e4285a332cc40b7655caf",
            "value": " 665/665 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "74d877d849d1498fbf87968a79b436d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d95517340925450d9544a147d0064f8f",
              "IPY_MODEL_795a4f3580c5469f86d0bcb96edc1f13",
              "IPY_MODEL_648a553be0bf49cba777f0eaaac741b2"
            ],
            "layout": "IPY_MODEL_37af4bb362b94e87b7c128e6966534f9"
          }
        },
        "784c12d3beb34f25a3c3387217b9a80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20ea57fda15f42d18d60048c165cb019",
              "IPY_MODEL_8f25e6d89124473688b788bf69c1bfba",
              "IPY_MODEL_bc9fe7054cc849e0ae9a0d69393de9d2"
            ],
            "layout": "IPY_MODEL_b858fc0c1caa4872b91ec7638d6dbf68"
          }
        },
        "795a4f3580c5469f86d0bcb96edc1f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cbfa6b49da84ee781492abacea18884",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9bcaec9f9c5467aa6e35316d3296302",
            "value": 665
          }
        },
        "80c335cb65a5408dae9ecd4ec9eda4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ba0334c76344e0a824177d3572e6dd7",
              "IPY_MODEL_eff3788657d8436e96a328e73cab52cc",
              "IPY_MODEL_260906d3854c4ff78c2cda042bae0a2e"
            ],
            "layout": "IPY_MODEL_aa21a3379eb44eb28a52028cc5a0590b"
          }
        },
        "8f25e6d89124473688b788bf69c1bfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a08a849c10e24dffb645cfe75c4bb66a",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efb3d94f64314da6a0e9b3e4d1e123e4",
            "value": 548105171
          }
        },
        "9a67d3d3a8744fd881b8a2d5359e78ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a08a849c10e24dffb645cfe75c4bb66a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d6ce4b456f4b6b872a832ffe858e06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa21a3379eb44eb28a52028cc5a0590b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b858fc0c1caa4872b91ec7638d6dbf68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9fe7054cc849e0ae9a0d69393de9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d6ce4b456f4b6b872a832ffe858e06",
            "placeholder": "",
            "style": "IPY_MODEL_52f6eb03404a425aabda1a87b86afe15",
            "value": " 548M/548M [00:04&lt;00:00, 122MB/s]"
          }
        },
        "c033d8e19c084b90bd8a88a3e5bdb5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca37e879895f4707bb2e39d9229c65dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0449079fc7a48a3a941c34c7cf2fdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95517340925450d9544a147d0064f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1209e810b3fc41808b444108a87afca1",
            "placeholder": "",
            "style": "IPY_MODEL_3ce2905b2f8e41adbc9eb724aeb2f62a",
            "value": "config.json: 100%"
          }
        },
        "efb3d94f64314da6a0e9b3e4d1e123e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eff3788657d8436e96a328e73cab52cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44854839f29f4de08577daf5c4db4c63",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5eec0e26428c4034867633d70b4b3915",
            "value": 124
          }
        },
        "f6620c81dc4e4285a332cc40b7655caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9bcaec9f9c5467aa6e35316d3296302": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
